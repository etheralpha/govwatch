{"rss":{"@version":"2.0","@xmlns:discourse":"http://www.discourse.org/","@xmlns:atom":"http://www.w3.org/2005/Atom","@xmlns:dc":"http://purl.org/dc/elements/1.1/","channel":{"title":"Ethereum Research - Latest topics","link":"https://ethresear.ch/latest","description":"Latest topics","lastBuildDate":"Sun, 14 Apr 2024 13:47:38 +0000","atom:link":{"@href":"https://ethresear.ch/latest.rss","@rel":"self","@type":"application/rss+xml"},"item":[{"title":"Trends in Voter Behaviour and Voting Power: A Comparative Study in Curve Finance and Polkadot","dc:creator":"dengwx11","category":"Economics","description":"<p>by <a href=\"https://twitter.com/dengwx11\" rel=\"noopener nofollow ugc\">Wenxuan Deng</a>, <a href=\"https://www.linkedin.com/in/tanishakatara?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=android_app\" rel=\"noopener nofollow ugc\">Tanisha Katara</a>, and <a href=\"https://www.linkedin.com/in/davidhamoui/\" rel=\"noopener nofollow ugc\">David Hamoui</a></p>\n<p><strong>Acknowledgements</strong><br>\nAdditional thanks to <a href=\"https://twitter.com/p_petertherock\" rel=\"noopener nofollow ugc\">Peter Liem</a> for his assistance with data fetching and to <a href=\"https://twitter.com/matrzeszowski\" rel=\"noopener nofollow ugc\">Mateusz Rzeszowski</a> for his insightful comments from a governance perspective.</p>\n<h2><a name=\"abstract-1\" class=\"anchor\" href=\"https://ethresear.ch#abstract-1\"></a>Abstract</h2>\n<p>This research examines the impact of financial incentives on voter behavior in two significant blockchain ecosystems, Curve Finance and Polkadot, through a user behavior study of all their voters. As the first comprehensive examination of voter behavior in Web3, the study suggests that when combined with governance, financial incentives lead to longer staking preferences among different voter personas and increased voter turnout. The research will establish the critical decision-making and governance strategies adopted by Curve Finance and Polkadot, which allow the community to agree on significant network changes collectively. However, even in the momentary celebration of collective decision-making, the evolving governance structures built must solve either some form of centralization or extremely low voter turnouts.</p>\n<h2><a name=\"introduction-2\" class=\"anchor\" href=\"https://ethresear.ch#introduction-2\"></a>Introduction</h2>\n<p>Blockchain technology has ushered in a new era of innovative governance mechanisms for decision-making. It shifts power from small, centralized groups to a broader community, democratizing and monetizing voting power. This transformation significantly boosts participation, enhances transparency, and secures the decision-making process within the community.</p>\n<p>A pivotal element of this new crypto-native governance model is the financial incentivization tied to voting. Drawing on economist Robin Hanson’s concept of Futarchy, where betting markets are used to aggregate market information efficiently, financial rewards for voting play a crucial role in aligning community interests and governance outcomes.</p>\n<p>As the fields of tokenomics and governance rapidly evolve, two protocols have emerged as particularly influential. Curve DAO pioneered the veToken model, introducing gauge voting and bribery mechanisms to decentralized finance (DeFi). Meanwhile, Polkadot’s governance system has been notable for its innovative approach to quorums, supported by a robust research framework. These protocols stand out as significant pioneers in enhancing governance conviction and shaping the future of decentralized systems.</p>\n<p>Governance conviction, often referred to as the lockup time multiplier, is a mechanism used in decentralized governance models to enhance the influence or voting power of token holders based on the duration for which they are willing to lock up their tokens. This system operates under the principle that the longer a participant commits their tokens, the more conviction they demonstrate towards the decisions being made within the network. As a result, their voting power is multiplied by a factor corresponding to the lockup period. This incentivizes longer-term commitment and stability within the governance process, aligning participants’ interests with the long-term health and success of the platform.</p>\n<p>Besides the implementation of governance conviction, both governance systems utilize permissionless on-chain execution. This means that decision-making is directly translated into canonical code, eliminating the need for an external authority or intermediary to implement changes voted on by token holders.</p>\n<p>However, there is a notable difference between the two governance systems in terms of token lock-up mechanisms. Curve Finance employs a governance mechanism that encourages participants to actively engage in decision-making processes by allowing them to gain financial rewards for locking their tokens.</p>\n<p>Let’s first briefly go over how these two governance systems work.</p>\n<p><strong>Curve Finance</strong> is a protocol that allows for the seamless exchange of ERC-20 tokens with minimal hassle and low costs. This is achieved through the use of Liquidity Pools, which require a sufficient number of tokens to ensure successful swaps and incentivize liquidity providers. Curve offers rewards to those who contribute, creating a win-win situation where users can easily exchange tokens while liquidity providers receive rewards.</p>\n<p>To vote, CRV token holders must possess veCRV. veCRV represents CRV tokens that are locked for a certain period (<a href=\"https://ethresear.ch#table1\">Table 1</a>). Users can lock their CRV for at least one week or up to a maximum of four years.</p>\n<ol>\n<li>\n<p><strong>Governance Proposals</strong> - Curve has to distinct types of proposals: Gauge proposals and Non-Gauge Proposals. Gauges and gauge weights determine how many rewards a liquidity pool gets. Therefore, a gauge proposal will have explicit financial consequences for some or all token holders. Non-gauge proposals, on the other hand, may or may not have economic consequences and may pertain to high-level maintenance and regular upgrades in the network. The impact of proposal types on voter behavior will be discussed more in this research paper.</p>\n</li>\n<li>\n<p><strong>Community Voting</strong> - A proposer must have a minimum balance of 2500 vote-escrowed CRV (veCRV) to create a Curve DAO proposal. Each proposal lasts for one week.</p>\n</li>\n</ol>\n<p><strong>Polkadot</strong> is a protocol that aims to connect different blockchains, also known as parachains, to enable seamless communication, interoperability, and scalability within its network. It facilitates the creation of interconnected blockchains to allow them to work more efficiently and experience shared security.</p>\n<ol>\n<li>\n<p><strong>Governance Proposals</strong> - Polkadot has two types of proposals: Treasury proposals and Non-Treasury proposals. According to Polkadot’s Governance V1, when a stakeholder wishes to propose spending from the Treasury, they must reserve a deposit of at least 5% of the proposed spending. The treasury proposal will have explicit financial consequences for the protocol, subject to governance, with the current default set to 24 days. On the other hand, non-treasury proposals may or may not have economic consequences and may pertain to high-level maintenance and regular upgrades in the network. The subject of how the type of proposals impacts voter behavior will be tackled in the “Proposals” section of this research paper.</p>\n</li>\n<li>\n<p><strong>Community Voting</strong> - To vote on proposals, DOT token holders must lock their tokens. The longer the DOT is locked, the more voting power is earned. The voting power of a DOT holder in Polkadot is calculated as DOT tokens held multiplied by the relevant multiplier (<a href=\"https://ethresear.ch#table2\">Table 2</a>), which increases as the locking period increases. The multipliers range from 0.1 for zero days to 6 for two hundred and twenty-four days.</p>\n</li>\n</ol>\n<p>For instance, if Alex has 100 tokens and locks them for 14 days, his voting power per the above formula is 100 (Dot Tokens Held) * 2 (Multiplier for 14 days, as mentioned in the above table) = 200. Therefore, Alex will have the voting power of 200 tokens.</p>\n<p>However, we are still in the early stages of this game-theoretical decentralized governance system, and many aspects of cryptoeconomic design remain unclear. Although innovation and iteration in governance cryptonomics are rapid and continue to accelerate, there are few rigorous and empirical studies from the game-theoretic perspective on voter personas. Therefore, in this research paper, we not only provide a comprehensive glance at the decentralized voting system but also construct a new playground methodology to delve deeply into voter personas.</p>\n<p>We will first discuss governance voter analysis (Section 2) and governance proposal analysis (Section 3). Then, we will try to understand the different voter personas in each system (Section 4). Finally, we will analyze voter behavior and seek to understand the governing principles of these complex environments. To do so, we will break down the types of market conditions and variations in voter behavior towards them. The objective is to provide valuable insights into the unique governance features of Curve Finance and Polkadot. To achieve this aim, we assess various factors such as voter turnout, proposal participation, voting power, and lock-up windows.</p>\n<h2><a name=\"voter-turnout-analysis-3\" class=\"anchor\" href=\"https://ethresear.ch#voter-turnout-analysis-3\"></a>Voter Turnout Analysis</h2>\n<p>We did a comprehensive analysis on voter turnout for governance voter engagement. The calculation of voter turnout metrics is based on the number of veCRV tokens and DOT tokens used for voting over time, relative to the total veCRV and DOT tokens locked over the same period.</p>\n<p><strong>Curve Finance:</strong> On average, 65% of the circulating CRV is locked as veCRV. Out of the 65% locked, an average of 38% tokens have been used for voting. This highlights that although a significant proportion of CRV is locked, a relatively low percentage is used for voting. Further investigation is required to determine the exact factors contributing to the low percentage of utilized tokens.</p>\n<p><strong>Polkadot:</strong> In contrast, only 54.5% of the circulating DOT is locked, and out of the 54.5% locked, only 0.11% tokens have been used for voting. This highlights a significant disparity in voter engagement between the two blockchain ecosystems, with DOT showing a much lower level of voter engagement than CRV. The low percentage of utilized tokens for voting in DOT could be attributed to several factors, such as a lack of financial incentives.</p>\n<p>The following graphs provide a visual representation of the amount of veCRV and DOT used for voting. Upon analyzing the data, it was observed that the average veCRV used for voting on Gauge proposals is significantly higher than the average veCRV used for Non-Gauge proposals. Conversely, the second graph shows that there is no notable difference between the amount of DOT locked for voting on treasury proposals and non-treasury proposals. These findings suggest that there are different financial incentives contributing to these variations. While Curve Finance incentivizes rewards through gauges, the incentives in Polkadot treasury proposals are limited to particular utilities.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/3/3b85e0424c2e287658f0ae6999d7b0d1c82108a3.png\" data-download-href=\"https://ethresear.ch/uploads/default/3b85e0424c2e287658f0ae6999d7b0d1c82108a3\" title=\"Screenshot 2024-04-03 at 6.25.37 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/3/3b85e0424c2e287658f0ae6999d7b0d1c82108a3_2_690x417.png\" alt=\"Screenshot 2024-04-03 at 6.25.37 PM\" data-base62-sha1=\"8uyZVlhhpFKS8xiz58W06Ef6yR5\" width=\"690\" height=\"417\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/3/3b85e0424c2e287658f0ae6999d7b0d1c82108a3_2_690x417.png, https://ethresear.ch/uploads/default/optimized/2X/3/3b85e0424c2e287658f0ae6999d7b0d1c82108a3_2_1035x625.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/3/3b85e0424c2e287658f0ae6999d7b0d1c82108a3_2_1380x834.png 2x\" data-dominant-color=\"DEE5EE\"></a></div><p></p>\n<p>The voter turnout metrics shed light on the extent to which token holders actively engage in voting in both the ecosystems. This sets the stage for a deeper exploration into the nature of governance proposals and their implications on decision-making dynamics within the Curve Finance and Polkadot communities. By examining the types and frequencies of proposals submitted in governance, we can gain further insights into the priorities and interests driving the respective ecosystems’ governance mechanisms.</p>\n<h2><a name=\"governance-proposals-breakdown-4\" class=\"anchor\" href=\"https://ethresear.ch#governance-proposals-breakdown-4\"></a>Governance Proposals Breakdown</h2>\n<p>Governance proposals play a crucial role in decision-making within any community. Our analysis of two ecosystems, Curve Finance and Polkadot, reveals that financial-centric proposals make up a significant portion of all proposals. Gauge proposals constitute approximately 70% of all proposals in Curve Finance, while Treasury proposals make up approximately 80% of all proposals in Polkadot.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/a/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f\" title=\"Screenshot 2024-04-01 at 9.33.00 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/a/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f_2_690x344.jpeg\" alt=\"Screenshot 2024-04-01 at 9.33.00 PM\" data-base62-sha1=\"oWZOJycUPwVH2u5vK5svy8Wjch9\" width=\"690\" height=\"344\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/a/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f_2_690x344.jpeg, https://ethresear.ch/uploads/default/optimized/2X/a/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f_2_1035x516.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/a/aedf73156bee5c77a8120b9e32f46b13d1dd6e5f_2_1380x688.jpeg 2x\" data-dominant-color=\"E0E4EF\"></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/8/8dde5255012e6c8f83ca3285cebaf1da9a34ad87.png\" data-download-href=\"https://ethresear.ch/uploads/default/8dde5255012e6c8f83ca3285cebaf1da9a34ad87\" title=\"Screenshot 2024-04-01 at 9.33.08 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/8/8dde5255012e6c8f83ca3285cebaf1da9a34ad87_2_689x351.png\" alt=\"Screenshot 2024-04-01 at 9.33.08 PM\" data-base62-sha1=\"kf1E05EXFSZTX1yTGC8H8jUo02H\" width=\"689\" height=\"351\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/8/8dde5255012e6c8f83ca3285cebaf1da9a34ad87_2_689x351.png, https://ethresear.ch/uploads/default/optimized/2X/8/8dde5255012e6c8f83ca3285cebaf1da9a34ad87_2_1033x526.png 1.5x, https://ethresear.ch/uploads/default/original/2X/8/8dde5255012e6c8f83ca3285cebaf1da9a34ad87.png 2x\" data-dominant-color=\"E1E3E6\"></a></div><p></p>\n<p>However, in Curve Finance, we found that most proposals are initiated by individuals associated with the <a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a> team (<a href=\"https://ethresear.ch#table3\">Table 3</a>), particularly two wallets linked to the founder, Michael Egorov. The top wallet, identified as the <a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a> deployer on the Arkham data platform, is notably active in both gauge and non-gauge proposal submissions. We have provided a table of top Curve Finance proposers, ranked in the order of participation.</p>\n<p>On the other hand, we did not observe such patterns in Polkadot. The most referenda submitted by a single author amounted to only 6% of the total proposals.</p>\n<p>Understanding the governance proposals and the voters who participate is important. Let’s dive deeper into the different types of voters.</p>\n<h2><a name=\"voter-personas-and-respective-patterns-5\" class=\"anchor\" href=\"https://ethresear.ch#voter-personas-and-respective-patterns-5\"></a>Voter Personas and Respective Patterns</h2>\n<p>The following research analyzes the behavior of voter personas and their respective patterns concerning token holdings. The voter personas are categorized based on the size of their token holdings, and the hierarchy is defined as follows: the top 1% is labeled as Whales, the next 5% as Sharks, the next 10% as Dolphins, the next 20% as Fishes, and the remaining as Shrimps.</p>\n<div> \n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>Token Holdings</th>\n<th>Voter Persona</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Top 1%</td>\n<td>Whales</td>\n</tr>\n<tr>\n<td>5%</td>\n<td>Sharks</td>\n</tr>\n<tr>\n<td>10%</td>\n<td>Dolphins</td>\n</tr>\n<tr>\n<td>20%</td>\n<td>Fishes</td>\n</tr>\n<tr>\n<td>Remaining</td>\n<td>Shrimps</td>\n</tr>\n</tbody>\n</table>\n</div></div>\n<p><strong>Curve Finance:</strong> In the context of Curve Finance governance, voter personas emerge vividly when we dissect them by the size of their veCRV token holdings. Over 58% of token holders choose to lock their tokens for four years. However, an intriguing trend surfaces among the different cohorts of holders.</p>\n<p>As shown in the graph below, the x-axis displays the initial lock-up windows, which range from 7 days to 4 years, and the y-axis displays the percentage of user personas who have locked their tokens. Our more giant holders, the Whales, Sharks, and Dolphins, show mild hesitation to commit for more extended lock periods. Conversely, they slightly prefer shorter commitments, particularly those under six months. Although the margin is slim, it is a telling divergence.</p>\n<p>It hints that more oversized holders may not need to lock up their tokens for extended periods to wield significant voting power. For them, the flexibility not to lock in for an extended time could be a strategic move to mitigate risk and maintain liquidity options.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/6/1/614ac8835fa6ee2259bdf475e94adde2095914b6.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/614ac8835fa6ee2259bdf475e94adde2095914b6\" title=\"Screenshot 2024-04-01 at 11.04.41 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/6/1/614ac8835fa6ee2259bdf475e94adde2095914b6_2_395x500.jpeg\" alt=\"Screenshot 2024-04-01 at 11.04.41 PM\" data-base62-sha1=\"dSGxiikAOF8braDLRJSn5haWAMm\" width=\"395\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/6/1/614ac8835fa6ee2259bdf475e94adde2095914b6_2_395x500.jpeg, https://ethresear.ch/uploads/default/optimized/3X/6/1/614ac8835fa6ee2259bdf475e94adde2095914b6_2_592x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/3X/6/1/614ac8835fa6ee2259bdf475e94adde2095914b6_2_790x1000.jpeg 2x\" data-dominant-color=\"ECF0F7\"></a></div><p></p>\n<p><strong>Polkadot:</strong> In the Polkadot ecosystem, analysis yielded a similar yet valuable correlation to Curve Finance. 4% of DOT holders initially choose to lock their tokens for a maximum of 224 days (roughly seven months). Holders with more significant positions prefer shorter lock-up periods, and this pattern is glaringly apparent. Particularly striking in the Polkadot ecosystem is that about 93% of whale and 98% of shark holders tend to lock up their tokens for 14 days or less. Contrastingly, shrimp holders display markedly different behavior, with approximately 30% opting for an 8-week lock-up and about 5% committing to a 32-week lock-up.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/9/5/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7.png\" data-download-href=\"https://ethresear.ch/uploads/default/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7\" title=\"image\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/9/5/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7_2_375x500.png\" alt=\"image\" data-base62-sha1=\"lkwVk0mVvjhwex7Miyvi130Eo6P\" width=\"375\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/9/5/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7_2_375x500.png, https://ethresear.ch/uploads/default/optimized/3X/9/5/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7_2_562x750.png 1.5x, https://ethresear.ch/uploads/default/original/3X/9/5/957fc95c9dade9db90e4b1116fe2e631d9f3b6a7.png 2x\" data-dominant-color=\"EDF1F8\"></a></div><p></p>\n<p>Among different holder categories, from Whales to Shrimps, there is an incremental increase in the preference for longer lock-ups as we move down the scale of holdings. The distinctions and preferences between prominent and smallholders are consistent within each protocol.</p>\n<p>However, there is a significant difference between the two protocols. As shown in the pie charts below, in Curve Finance, 67.2% of voters across all groups opt for a four-year lock-up, while in Polkadot, only 4% of the users choose the most extended lock-up window of 224 days. Even among the most minor stakeholders, the Shrimps, less than 5% chose the most prolonged lock-up period of 32 weeks.</p>\n<p>This divergence could be attributed to the fundamental differences in the underlying rewards and incentives of Curve Finance and Polkadot. Curve’s gauge weight voting system incentivizes users to boost their voting power by locking their tokens for extended periods. This indicates that sustained rewards are crucial in incentivizing token holders to stay longer.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/d/a/da6c26c56e463de04ea705995dfdc0b5c4d15030.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/da6c26c56e463de04ea705995dfdc0b5c4d15030\" title=\"Screenshot 2024-04-01 at 11.04.50 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/d/a/da6c26c56e463de04ea705995dfdc0b5c4d15030_2_534x500.jpeg\" alt=\"Screenshot 2024-04-01 at 11.04.50 PM\" data-base62-sha1=\"vafNIM8IPVnnIQyvpSCmzXwfV5K\" width=\"534\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/d/a/da6c26c56e463de04ea705995dfdc0b5c4d15030_2_534x500.jpeg, https://ethresear.ch/uploads/default/optimized/3X/d/a/da6c26c56e463de04ea705995dfdc0b5c4d15030_2_801x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/3X/d/a/da6c26c56e463de04ea705995dfdc0b5c4d15030_2_1068x1000.jpeg 2x\" data-dominant-color=\"F4E8EA\"></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/3/6/3670e083576cb33f40c59474c3c8aa50c125bcec.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/3670e083576cb33f40c59474c3c8aa50c125bcec\" title=\"Screenshot 2024-04-01 at 11.05.01 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/3/6/3670e083576cb33f40c59474c3c8aa50c125bcec_2_520x500.jpeg\" alt=\"Screenshot 2024-04-01 at 11.05.01 PM\" data-base62-sha1=\"7LBCwa5rDCJ5uKBMkzHxIYN4nj6\" width=\"520\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/3/6/3670e083576cb33f40c59474c3c8aa50c125bcec_2_520x500.jpeg, https://ethresear.ch/uploads/default/optimized/3X/3/6/3670e083576cb33f40c59474c3c8aa50c125bcec_2_780x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/3X/3/6/3670e083576cb33f40c59474c3c8aa50c125bcec_2_1040x1000.jpeg 2x\" data-dominant-color=\"F4F8EB\"></a></div><p></p>\n<p>With this understanding of voter personas and their lock-up behaviors, it is essential to dive into how they accumulate voting power in different market conditions.</p>\n<h2><a name=\"voting-power-accumulation-patterns-in-different-market-conditions-6\" class=\"anchor\" href=\"https://ethresear.ch#voting-power-accumulation-patterns-in-different-market-conditions-6\"></a>Voting Power Accumulation Patterns in Different Market Conditions</h2>\n<p>The study of voting power accumulation patterns and the associated dynamics between voters and their locked-up tokens are of paramount importance in understanding how voters use their tokens in upward and downward market conditions. In this regard, the two primary ways in which voters can augment their voting power (VP) are by purchasing additional tokens and locking them up, or by extending their lock-up period, resulting in an increased multiplier. VP calculation is derived from the multiplication of token balance and a multiplier based on the lock-up period.</p>\n<p><strong>Voting Power (VP) = token balance * multiplier based on lockup time</strong></p>\n<p>However, analyzing the behavior of voters in response to changes in token prices and market conditions presents a significant challenge. It is challenging to determine whether voter behavior is influenced by changes in token locked amounts and lock-up duration or whether they are affected by the daily routines of the average Externally Owned Account (EOA) wallet.</p>\n<p>To overcome this challenge, a robust and reliable quantitative methodology has been developed to simplify this complex analysis. This approach is based on a decomposition of the changes in voting power into its constituent factors. By quantifying the changes in voting power (<span class=\"math\">\\Delta vp</span>) over time, an analysis of the two constituent factors, changes in balance (<span class=\"math\">\\Delta b</span>) and changes in conviction (<span class=\"math\">\\Delta c</span>), can be made.</p>\n<p>The change in voting power between two consecutive time points, <span class=\"math\">t</span> and <span class=\"math\">t-1</span>, can be derived through arithmetic calculations as follows:</p>\n<p><span class=\"math\"> \\Delta vp = vp(t) - vp(t-1)</span></p>\n<p>This equation can be expanded as:</p>\n<p><span class=\"math\">\\Delta vp = b(t) \\cdot c(t) - b(t-1) \\cdot c(t-1) </span><br>\n<span class=\"math\">= b(t) \\cdot [c(t) - c(t-1)] + c(t-1) \\cdot [b(t) - b(t-1)] </span><br>\n<span class=\"math\">= b(t) \\cdot \\Delta c + c(t-1) \\cdot \\Delta b</span></p>\n<p>Here, <span class=\"math\">b(t)</span> and <span class=\"math\">c(t)</span> represent the balance and conviction at time <span class=\"math\">t</span>, respectively. The terms <span class=\"math\">\\Delta b</span> and <span class=\"math\">\\Delta c</span> denote the changes in balance and conviction from time <span class=\"math\">t-1</span> to <span class=\"math\">t</span>.</p>\n<p>For this study, each timestamp where a new transaction occurs on the blockchain is considered a discrete-time point. This approach captures the dynamic nature of voting power changes with high granularity. To represent the changes in voting power across different voters and time points, a matrix formulation is used. The matrix of changes in voting power (<span class=\"math\">\\Delta VP</span>) is defined as follows:</p>\n<p><span class=\"math\">\\Delta VP \\in \\mathbb{N}^{T  \\times W}</span></p>\n<p>Here, <span class=\"math\">T+1</span> represents the total number of time points, while <span class=\"math\">W</span> indicates the number of voters. The changes in voting power can be represented using the following formula:</p>\n<p><span class=\"math\">\\Delta VP = B \\odot \\Delta C + C(t-1) \\odot \\Delta B \\tag{1}</span></p>\n<p>The formula can be represented in matrix form as:</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/8/c/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0\" title=\"image\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/8/c/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0_2_690x302.jpeg\" alt=\"image\" data-base62-sha1=\"k3P5rLUDMAMVDjEXyaMRTwunUDm\" width=\"690\" height=\"302\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/8/c/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0_2_690x302.jpeg, https://ethresear.ch/uploads/default/optimized/3X/8/c/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0_2_1035x453.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/3X/8/c/8c9a23ab9d3fff35dc28705e4bc2387adb3703d0_2_1380x604.jpeg 2x\" data-dominant-color=\"F8F8F8\"></a></div><p></p>\n<p>The matrix <span class=\"math\">\\Delta VP</span> represents the change in voting power for each voter at each timestamp, while <span class=\"math\">B</span> represents the balance of each voter at time <span class=\"math\">t</span>, <span class=\"math\">\\Delta C</span> represents the change in conviction between <span class=\"math\">t</span> and <span class=\"math\">t-1</span> for each voter, and <span class=\"math\">C(t-1)</span> represents the conviction of each voter at time <span class=\"math\">t-1</span>. The matrices <span class=\"math\">\\Delta B</span> and <span class=\"math\">\\Delta C</span> represent the changes in balance and conviction, respectively, for each voter between <span class=\"math\">t</span> and <span class=\"math\">t-1</span>. The symbol <span class=\"math\">\\odot</span> represents the element-wise multiplication of matrices.</p>\n<p>If <span class=\"math\">\\Delta vp_{t, i}</span> is non-zero, the voting power of voter <span class=\"math\">i</span>'s wallet has been altered at time point <span class=\"math\">t</span>. A non-zero change in VP due to a change in conviction occurs because <span class=\"math\">b \\cdot \\Delta c</span> is non-zero. Conversely, a change in balance results in a non-zero value because <span class=\"math\">c(t-1) \\cdot \\Delta b</span> is non-zero. Typically, these two terms hold non-zero values simultaneously if the user changes the lock-up window and balance in the same transaction.</p>\n<p>Here, the notation <span class=\"math\">||_1</span> denotes the L1 norm, which essentially sums up the absolute values of all elements in the matrix.</p>\n<p>In summary, this methodology for governance conviction provides a more in-depth and comprehensive approach to analyzing voting power accumulation patterns in different market conditions. Through the matrix formulation, the changes in voting power across different voters and time points can be represented and analyzed with high granularity, providing valuable insights into voter behavior dynamics.</p>\n<p><strong>Accounting for Market Conditions in Curve and Polkadot</strong></p>\n<p>In this study, we aim to assess the impact of market conditions on how voters accumulate voting power. To achieve this, we analyze upward and downward trends in the market by employing a combination of short-term and long-term moving averages, namely the 7-day moving average (MA7) and the 30-day moving average (MA30). We define an upward trend when the MA7 exceeds the MA30 and a downward trend when the MA7 falls below the MA30.</p>\n<p>It is crucial to acknowledge that token behavior is circumstantial, and varying market conditions may elicit different responses from holders with varying stakes, thereby exhibiting diverse behavior patterns. Therefore, we adopt a nuanced approach, which considers these factors to provide a precise and insightful understanding of how balance and conviction impact the ebb and flow of voting power within the governance systems.<br>\n</p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/b/2/b2653381c4259361d9af8faaafcd5262b5c60eea.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/b2653381c4259361d9af8faaafcd5262b5c60eea\" title=\"Screenshot 2024-04-01 at 11.12.56 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/b/2/b2653381c4259361d9af8faaafcd5262b5c60eea_2_690x424.jpeg\" alt=\"Screenshot 2024-04-01 at 11.12.56 PM\" data-base62-sha1=\"ps9OmvQqMUzCkl1ZufUGbEUXhGi\" width=\"690\" height=\"424\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/b/2/b2653381c4259361d9af8faaafcd5262b5c60eea_2_690x424.jpeg, https://ethresear.ch/uploads/default/optimized/3X/b/2/b2653381c4259361d9af8faaafcd5262b5c60eea_2_1035x636.jpeg 1.5x, https://ethresear.ch/uploads/default/original/3X/b/2/b2653381c4259361d9af8faaafcd5262b5c60eea.jpeg 2x\" data-dominant-color=\"EAECF3\"></a></div><p></p>\n<p><img src=\"https://ethresear.ch/uploads/default/original/3X/2/f/2f9b6d4982d47acef83bb468edd2627272484aec.png\" alt=\"image\" data-base62-sha1=\"6N9rnX1m6JVFN2pAnRIakFYpRhy\" width=\"648\" height=\"387\"></p>\n<p>The charts presented above illustrate how the MA7-MA30 differential correlates with the token price. Our analysis leverages these definitions to explore how market trends affect voter behavior, specifically the influence of the token price and lock-up duration on the dynamic voting power within the governance frameworks of Curve Finance and Polkadot.</p>\n<p><strong>Findings: Voting Power Accumulation in Curve Finance and Polkadot</strong></p>\n<p><strong>Curve Finance:</strong> In the case of Curve Finance, we encountered a challenge when studying shrimp voters due to their high number exceeding 12,000 and the high computational complexity of our method. As a result, we adopted a sampling strategy, randomly selecting 2000 shrimp voters in each experiment, and repeated this process 500 times. We calculated the log ratio of conviction impact to balance impact in each experiment and grouped the results by upward and downward market trends. The grouped histograms below showed distinct patterns.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/6/0/60cb4c184739f3b14e40f153c60fb24816738583.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/60cb4c184739f3b14e40f153c60fb24816738583\" title=\"Screenshot 2024-04-01 at 11.18.38 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/6/0/60cb4c184739f3b14e40f153c60fb24816738583_2_690x326.jpeg\" alt=\"Screenshot 2024-04-01 at 11.18.38 PM\" data-base62-sha1=\"dOhoLGGeHii0voPnBguFr1fjt2r\" width=\"690\" height=\"326\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/6/0/60cb4c184739f3b14e40f153c60fb24816738583_2_690x326.jpeg, https://ethresear.ch/uploads/default/optimized/3X/6/0/60cb4c184739f3b14e40f153c60fb24816738583_2_1035x489.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/3X/6/0/60cb4c184739f3b14e40f153c60fb24816738583_2_1380x652.jpeg 2x\" data-dominant-color=\"DDD8EA\"></a></div><br>\nIn the grouped histograms, we noticed distinct patterns:<p></p>\n<p>During downward trends, the log ratio values were mainly concentrated between 0 and 0.5, displaying a distribution similar to a normal distribution. This suggests that shrimp behavior is more uniform in downward markets, and most log ratios exceeding 0 indicate a tendency among shrimp to increase their lock-up duration to alter their voting power.</p>\n<p>During upward trends, the scenario was notably more complex, as three peaks around -0.3, 0.5, and 1 indicate that shrimp behavior is inconsistent during upward markets. However, most shrimps preferred changing their lock-up window, a tendency that was even more pronounced than during the downward trends.</p>\n<p><strong>Polkadot:</strong> When analyzing Polkadot’s market trends, we observed a deviation from the typical pattern observed in Curve Finance. Instead of a normal distribution, there was a noticeable long tail in the data. Upon closer inspection, we discovered a fascinating insight: a particular group of shrimp voters in Polkadot had a strong inclination towards altering their lock-up window rather than increasing their balance during bullish market conditions. This behavior was particularly prominent and suggestive of a unique pattern among this subset of voters.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/3X/6/d/6d41b919645f052cfc71e44630b22377b3231595.png\" data-download-href=\"https://ethresear.ch/uploads/default/6d41b919645f052cfc71e44630b22377b3231595\" title=\"Screenshot 2024-04-01 at 11.20.53 PM\"><img src=\"https://ethresear.ch/uploads/default/optimized/3X/6/d/6d41b919645f052cfc71e44630b22377b3231595_2_690x321.png\" alt=\"Screenshot 2024-04-01 at 11.20.53 PM\" data-base62-sha1=\"fAwR1AbctkuEbXtqy7QNiTFxdrL\" width=\"690\" height=\"321\" srcset=\"https://ethresear.ch/uploads/default/optimized/3X/6/d/6d41b919645f052cfc71e44630b22377b3231595_2_690x321.png, https://ethresear.ch/uploads/default/optimized/3X/6/d/6d41b919645f052cfc71e44630b22377b3231595_2_1035x481.png 1.5x, https://ethresear.ch/uploads/default/original/3X/6/d/6d41b919645f052cfc71e44630b22377b3231595.png 2x\" data-dominant-color=\"EAE9F2\"></a></div><p></p>\n<h2><a name=\"conclusion-7\" class=\"anchor\" href=\"https://ethresear.ch#conclusion-7\"></a>Conclusion</h2>\n<p>The research examined voter personas, governance proposals, and voting power accumulation patterns to determine key trends and patterns in voter behavior.</p>\n<p>Firstly, the research highlights the importance of financial incentives in driving voter turnout, with Curve Finance exhibiting higher levels of voter turnout compared to Polkadot. Financial-centric proposals such as Gauge proposals and Treasury Proposals make up the majority of proposals in Curve Finance and Polkadot respectively. However, in Curve Finance, it was found that the majority of proposals are initiated by individuals linked to the <a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a> team.</p>\n<p>Additionally, the analysis reveals the presence of distinct voter personas with varying preferences and behaviors. Whales, Sharks, and Dolphins exhibited preferences for shorter lock-up windows. Furthermore, in Curve Finance, the majority of voters locked their tokens in the highest lock-up window. This trend stood in stark contrast with voters in Polkadot. Understanding these personas is crucial for designing effective governance mechanisms that cater to the diverse needs and motivations of token holders.</p>\n<p>Lastly, the study highlights the impact of market conditions on voter behavior. During upward trends, token holders in both Curve Finance and Polkadot exhibit a propensity to adjust their lock-up durations to maximize their voting power. Conversely, during downward trends, there is a more uniform tendency among voters to increase their lock-up durations.</p>\n<p>This research contributes to our understanding of decentralized governance in blockchain ecosystems and provides valuable insights for the design and optimization of governance mechanisms. Further research in this area will be crucial to ensuring the scalability and effectiveness of decision-making as the blockchain landscape evolves.</p>\n<h2><a name=\"appendix-8\" class=\"anchor\" href=\"https://ethresear.ch#appendix-8\"></a>Appendix</h2>\n<div> \n<p><a name=\"table1\" href=\"https://ethresear.ch\"></a><br>\nTable 1: veCRV amount by lock-up period</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>1 CRV is locked for</th>\n<th>The user is assigned</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>one week</td>\n<td>0 veCRV</td>\n</tr>\n<tr>\n<td>one month</td>\n<td>0.02 veCRV</td>\n</tr>\n<tr>\n<td>six months</td>\n<td>0.13 veCRV</td>\n</tr>\n<tr>\n<td>one year</td>\n<td>0.25 veCRV</td>\n</tr>\n<tr>\n<td>two years</td>\n<td>0.5 veCRV</td>\n</tr>\n<tr>\n<td>three years</td>\n<td>0.75 veCRV</td>\n</tr>\n<tr>\n<td>four years</td>\n<td>1 veCRV</td>\n</tr>\n</tbody>\n</table>\n</div></div>\n<div> \n<p><a name=\"table2\" href=\"https://ethresear.ch\"></a><br>\nTable 2: DOT conviction multiplier by democracy lock</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>1 DOT is locked for</th>\n<th>Multiplier</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>zero days</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>seven days</td>\n<td>1</td>\n</tr>\n<tr>\n<td>fourteen days</td>\n<td>2</td>\n</tr>\n<tr>\n<td>twenty eight days</td>\n<td>3</td>\n</tr>\n<tr>\n<td>fifty six days</td>\n<td>4</td>\n</tr>\n<tr>\n<td>one hundred and twelve days</td>\n<td>5</td>\n</tr>\n<tr>\n<td>two hundred and twenty four days</td>\n<td>6</td>\n</tr>\n</tbody>\n</table>\n</div></div>\n<p><a name=\"table3\" href=\"https://ethresear.ch\"></a><br>\nTable 3: Top Proposal Address Labels on <a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a></p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>Rank</th>\n<th>Proposer Address</th>\n<th>Count</th>\n<th>ID on Arkham</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0xbabe61887f1de2713c6f97e567623453d3c79f67</td>\n<td>55</td>\n<td><a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a> Deployer</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0x745748bcfd8f9c2de519a71d789be8a63dd7d66c</td>\n<td>28</td>\n<td><span class=\"mention\">@skellet0r</span> (<a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a>)</td>\n</tr>\n<tr>\n<td>3</td>\n<td>0x7a16ff8270133f063aab6c9977183d9e72835428</td>\n<td>28</td>\n<td>Michael Egorov (<a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a>)</td>\n</tr>\n<tr>\n<td>4</td>\n<td>0x0000000000e189dd664b9ab08a33c4839953852c</td>\n<td>22</td>\n<td>Charlie Watkins (<a href=\"http://Curve.fi\" rel=\"noopener nofollow ugc\">Curve.fi</a>)</td>\n</tr>\n<tr>\n<td>5</td>\n<td>0x71f718d3e4d1449d1502a6a7595eb84ebccb1683</td>\n<td>22</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>0x947b7742c403f20e5faccdac5e092c943e7d0277</td>\n<td>22</td>\n<td>Convex Finance Deployer</td>\n</tr>\n<tr>\n<td>7</td>\n<td>0x34d6dbd097f6b739c59d7467779549aea60e1f84</td>\n<td>17</td>\n<td></td>\n</tr>\n<tr>\n<td>8</td>\n<td>0xa1992346630fa9539bc31438a8981c646c6698f1</td>\n<td>14</td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>0xf7bd34dd44b92fb2f9c3d2e31aaad06570a853a6</td>\n<td>13</td>\n<td></td>\n</tr>\n<tr>\n<td>10</td>\n<td>0x52f541764e6e90eebc5c21ff570de0e2d63766b6</td>\n<td>13</td>\n<td>Stake Dao: Curve yCRV Voter</td>\n</tr>\n</tbody>\n</table>\n</div>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/trends-in-voter-behaviour-and-voting-power-a-comparative-study-in-curve-finance-and-polkadot/19295\">Read full topic</a></p>","link":"https://ethresear.ch/t/trends-in-voter-behaviour-and-voting-power-a-comparative-study-in-curve-finance-and-polkadot/19295","pubDate":"Sun, 14 Apr 2024 13:47:38 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19295"},"source":{"@url":"https://ethresear.ch/t/trends-in-voter-behaviour-and-voting-power-a-comparative-study-in-curve-finance-and-polkadot/19295.rss","#text":"Trends in Voter Behaviour and Voting Power: A Comparative Study in Curve Finance and Polkadot"}},{"title":"EIP-3074 AUTHCALL and phishing protection?","dc:creator":"miohtama","category":"Security","description":"<p>Happy to hear that EIP-3074 (“AUTHCALL”) is going forward.</p>\n<p>The question I have in mind is how EIP-3074 prevents phishing? I looked up some old AUTHCALL examples (likely outdated), and most of them seem to be a normal EIP-712 message.</p>\n<p>An example <a href=\"https://github.com/0xPolygon/account-abstraction-invoker/tree/master?tab=readme-ov-file\" rel=\"noopener nofollow ugc\">here</a>:</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/5/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c\" title=\"image\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/5/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c_2_470x500.jpeg\" alt=\"image\" data-base62-sha1=\"bTSiiEPCoLis6cmkrNtbrhcJZAE\" width=\"470\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/5/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c_2_470x500.jpeg, https://ethresear.ch/uploads/default/optimized/2X/5/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c_2_705x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/5/5368dc978cd0a5d9e4faeddc2d67c5ef3ff91d4c_2_940x1000.jpeg 2x\" data-dominant-color=\"F5F6F7\"></a></div><p></p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/112061eb401698e3860a7fb2b15b3dd864a04ed6.png\" data-download-href=\"https://ethresear.ch/uploads/default/112061eb401698e3860a7fb2b15b3dd864a04ed6\" title=\"image\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/112061eb401698e3860a7fb2b15b3dd864a04ed6_2_503x500.png\" alt=\"image\" data-base62-sha1=\"2rvuLipUXvpcfNXs8hrmjjohfSK\" width=\"503\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/112061eb401698e3860a7fb2b15b3dd864a04ed6_2_503x500.png, https://ethresear.ch/uploads/default/optimized/2X/1/112061eb401698e3860a7fb2b15b3dd864a04ed6_2_754x750.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/112061eb401698e3860a7fb2b15b3dd864a04ed6_2_1006x1000.png 2x\" data-dominant-color=\"F2F4F7\"></a></div><p></p>\n<p>If AUTH/AUTHCALL allows the user to delegate her wallet to any smart contract with a single signed message, isn’t this a large phishing risk? Or am I misunderstanding something here, and there are going to be some security measurements not signing arbitrary AUTH/AUTHCALLs?</p>\n<ul>\n<li>Currently Ethereum has ~600 wallets as listed on <a href=\"https://explorer.walletconnect.com/?type=wallet\" rel=\"noopener nofollow ugc\">WalletConnect website</a>, there are likely couple of hundreds more</li>\n<li>Phishing is the largest security problem <a href=\"https://twitter.com/realScamSniffer/status/1774963876968436156\" rel=\"noopener nofollow ugc\">in the Ethereum ecosystem, where approve(), permit() and Permit2 phishing cause $70M/month</a> losses to Ethereum users, causing more damage than hacks and rug pulls, or any other attack vector</li>\n<li>Legacy wallet dev teams do not have resources to build transaction simulators or other such security measurements to prevent new phishing vectors</li>\n<li>EIP-3074 specification does not discuss this problem, does not give any UX guidelines for wallet and Dapp developers, and so on, so it feels there might be a risk here</li>\n</ul>\n            <p><small>3 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/eip-3074-authcall-and-phishing-protection/19288\">Read full topic</a></p>","link":"https://ethresear.ch/t/eip-3074-authcall-and-phishing-protection/19288","pubDate":"Fri, 12 Apr 2024 16:29:49 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19288"},"source":{"@url":"https://ethresear.ch/t/eip-3074-authcall-and-phishing-protection/19288.rss","#text":"EIP-3074 AUTHCALL and phishing protection?"}},{"title":"Appointed Execution Proposers: Because the Proposer you know…","dc:creator":"The-CTra1n","category":"Block proposer","description":"<p><em>Thanks to <a class=\"mention\" href=\"https://ethresear.ch/u/swapnilraj\">@swapnilraj</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/linoscope\">@linoscope</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/barnabe\">@barnabe</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/julian\">@Julian</a>, and <a class=\"mention\" href=\"https://ethresear.ch/u/jcschlegel\">@jcschlegel</a> for detailed back-and-forth in crafting this article. Thanks also to Michal Zajac, <a class=\"mention\" href=\"https://ethresear.ch/u/quintuskilbourn\">@quintuskilbourn</a>,  and <a class=\"mention\" href=\"https://ethresear.ch/u/justindrake\">@JustinDrake</a> for their comments on the idea. This work was funded by Flashbots. The views expressed are my own, and do not necessarily reflect those of the reviewers or Flashbots.</em></p>\n<h1><a name=\"introduction-1\" class=\"anchor\" href=\"https://ethresear.ch#introduction-1\"></a>Introduction</h1>\n<p>This article introduces the concept of appointed execution proposers (AEPs), a proposer allocation protocol that allows validators in a committee-based consensus mechanism, e.g. proof-of-stake, to appoint specialized proposers to propose blocks on behalf of validators. AEPs joins a long line of protocols decoupling high-barrier requirements, e.g. execution-block building, large amounts of slashable stake, from low-barrier requirements e.g. beacon-block proposing, attesting. The protocols that we follow in this regard include <a href=\"https://ethereum.org/en/roadmap/pbs/\" rel=\"noopener nofollow ugc\">proposer-builder separation (PBS)</a>, <a href=\"https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710\">enshrined PBS</a>, <a href=\"https://ethresear.ch/t/execution-tickets/17944\">Execution Tickets</a>, and <a href=\"https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683\">Rainbow Staking</a>.</p>\n<p>AEPs can bootstrap onto any in-protocol proposer-market structure, e.g. Execution Tickets, ePBS, allowing validators to become opinionated about the entities responsible for proposing blocks. Through validator requirements, smaller market participants and users can be protected from the monopolization and malicious block-building practices that a free-market allows for, and/or incentivizes. This equates to <a href=\"https://competition-policy.ec.europa.eu/antitrust-and-cartels_en\" rel=\"noopener nofollow ugc\">antitrust</a> and quality control. As such, AEPs provides the tools for Ethereum validators to ensure long-term sustainability of the Ethereum block-proposal market, its users, and the ecosystem as a whole.</p>\n<p>Importantly, AEPs restricting the proposer market to the appointed set is conditional on the appointed set reaching a minimum size threshold. Below this threshold, AEPs reverts to the default permissionless proposer setting. By reaching this minimum size threshold, validators are deciding in no uncertain manner that they want to use the appointed proposer set. What’s more, even in AEPs’ default setting, the omnipresent threat of reaching the minimum size threshold serves as a deterrent for permissionless proposers from engaging in malicious activity; a nuclear non-proliferation agreement between validators and permissionless proposers (H/T <a class=\"mention\" href=\"https://ethresear.ch/u/julian\">@Julian</a>).</p>\n<p>AEPs builds on the status quo of permissionless-only block building on Ethereum. AEPs aligns the block-building process with the needs of the many (validators), channelling the previously unchecked desires of the few (competitive block-builders). By coupling AEPs with an in-protocol proposer market, Ethereum can improve on the benefits, and address the drawbacks of the free-market approach to block proposing. <a href=\"https://www.investopedia.com/articles/economics/08/free-market-regulation.asp\" rel=\"noopener nofollow ugc\">The parallel here with free-markets is that some oversight of free markets is typically beneficial</a>. Importantly, the regulators in AEPs are the permissionless validators who represent Ethereum, with scope for arbitrarily transparent and dynamic regulation.</p>\n<p>AEPs allow validators to express proposer preferences beyond slashable stake requirements and on-chain behaviour. Validators can identify and reward/punish non-attributable good/bad behaviour, such as censoring/non-censoring, or even the timely provision of <a href=\"https://ethresear.ch/t/based-preconfirmations/17353\">preconfirmations</a>/lack thereof. Given the potentially lucrative nature of block proposing, and the ability for validators to rescind appointments from proposers at any time, appointed proposers have a strong incentive to perform honestly and earn their appointment.</p>\n<h1><a name=\"terminology-2\" class=\"anchor\" href=\"https://ethresear.ch#terminology-2\"></a>Terminology</h1>\n<p><em>The protocol description omits specific numbers for key thresholds that are required to implement and deploy AEPs. We highlight these “gaps-to-be-filled” where they arise with a “<em>gap</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">”. These gaps stand as key to-dos for a technical specification of AEPs.</em></p>\n<p>Unless otherwise specified, we assume that the underlying blockchain protocol is <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/\" rel=\"noopener nofollow ugc\">Ethereum PoS</a>. We borrow a lot of <a href=\"https://ethresear.ch/t/execution-tickets/17944#definitions-2\">terminology from the Execution Tickets proposal</a> because that article’s target audience is ours too. Thanks for the cheese.</p>\n<ul>\n<li><strong>Slot:</strong> A single iteration of the consensus protocol.</li>\n<li><strong>Validators:</strong> Staked entities as per Ethereum. Validators are responsible for attesting to execution blocks, proposing and attesting to beacon chain blocks, specifying inclusion lists when elected as beacon proposers, and optionally voting to appoint execution proposers.</li>\n<li><strong>Beacon lottery:</strong> A random process by which the beacon proposers (and possibly attesters) are selected from the validator set.</li>\n<li><strong>Beacon round:</strong> The portion of the slot where the beacon block is proposed.</li>\n<li><strong>Beacon block:</strong> The <a href=\"https://github.com/ethereum/consensus-specs/blob/bf09b9a7c4a7b311e86823235815daf31b117574/specs/capella/beacon-chain.md#beaconblockbody\" rel=\"noopener nofollow ugc\">BeaconBlockBody</a> of today, sans the ExecutionPayload, but with an inclusion list.</li>\n<li><strong>Beacon proposer:</strong> The validator selected as the proposer for a given beacon round (same as today).</li>\n<li><strong>Inclusion lists:</strong> A list of transactions specified by the beacon proposer for inclusion in the execution block.</li>\n<li><strong>Execution round:</strong> The portion of the slot during which an execution block is proposed.</li>\n<li><strong>Execution block:</strong> The <a href=\"https://github.com/ethereum/consensus-specs/blob/bf09b9a7c4a7b311e86823235815daf31b117574/specs/bellatrix/beacon-chain.md#executionpayload\" rel=\"noopener nofollow ugc\">ExecutionPayload</a> of today. This includes the set of transactions that get included on-chain.</li>\n<li><strong>Execution proposer:</strong> The entity with the exclusive initial right to build and propose an execution block for consensus. Proposers may subsequently auction off the right to build blocks through a builder market such as <a href=\"https://boost.flashbots.net/\" rel=\"noopener nofollow ugc\">MEV-Boost</a> or enshrined PBS.</li>\n<li><strong>Block-builders:</strong> Entities who are delegated block-building rights by the execution proposer. The blockchain protocol requires the execution proposer to sign off on this delegation.</li>\n<li><strong>In-protocol appointed proposer requirements:</strong> The core in-protocol requirement is <em>for proposers to receive appointment from validators controlling a specific minimum % of stake</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">. In-protocol requirements can also include <em>minimum slashable stake for proposers</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">, or more generally, any on-chain attribute that can be verified by a smart contract.</li>\n<li><strong>Out-of-protocol appointed proposer requirements:</strong> These requirements are enforced out of protocol on appointed proposers, and can be arbitrarily strict or attributable.</li>\n<li><strong>Proposer Ejection:</strong> At any point in time, validators can collect votes on behalf of the validator set to remove a proposer from the appointed proposer set. These votes can be forced on-chain through the inclusion list, or directly onto the beacon chain operation. If the ejection threshold is met, the specified proposer is ejected from the proposer set.</li>\n<li><strong><em>Target/Minimum number of appointed proposers</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">:</strong> The target number of appointed proposers dictates how many proposers each validator is expected to appoint. The minimum number of appointed proposers must be reached for the appointed set of proposers to begin proposing blocks. Below this minimum threshold, the default proposer selection mechanism is used.</li>\n<li><strong>Appointed proposer:</strong> An entity who has met all in-protocol appointed proposer requirements. Given the minimum number of appointed proposers has been met, appointed proposers have the exclusive right to be selected as the execution proposer.</li>\n<li><strong>AEPs market:</strong> This is the AEPs market-structure protocol for deciding which of the appointed proposers is the execution-block proposer for a given Ethereum slot. Examples include first-price <a href=\"https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ\" rel=\"noopener nofollow ugc\">slot auctions</a> and lottery-based <a href=\"https://ethresear.ch/t/execution-tickets/17944\">execution tickets</a>.</li>\n</ul>\n<h2><a name=\"protocol-sketch-3\" class=\"anchor\" href=\"https://ethresear.ch#protocol-sketch-3\"></a>Protocol Sketch</h2>\n<p><strong></strong></p><div class=\"lightbox-wrapper\"><strong><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/c/c709045b46552fb358b2b832bc3cbf7e035f3aec.png\" data-download-href=\"https://ethresear.ch/uploads/default/c709045b46552fb358b2b832bc3cbf7e035f3aec\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/c/c709045b46552fb358b2b832bc3cbf7e035f3aec_2_602x211.png\" alt=\"\" data-base62-sha1=\"soKkNCQqIW0N2NKFHr4qVcuRiMc\" width=\"602\" height=\"211\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/c/c709045b46552fb358b2b832bc3cbf7e035f3aec_2_602x211.png, https://ethresear.ch/uploads/default/optimized/2X/c/c709045b46552fb358b2b832bc3cbf7e035f3aec_2_903x316.png 1.5x, https://ethresear.ch/uploads/default/original/2X/c/c709045b46552fb358b2b832bc3cbf7e035f3aec.png 2x\" data-dominant-color=\"F1EFEB\"></a></strong></div><p></p>\n<p><strong></strong></p><div class=\"lightbox-wrapper\"><strong><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/a/ae6181b7e01c2e93a6200299e2118ab581858d23.png\" data-download-href=\"https://ethresear.ch/uploads/default/ae6181b7e01c2e93a6200299e2118ab581858d23\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/a/ae6181b7e01c2e93a6200299e2118ab581858d23_2_602x211.png\" alt=\"\" data-base62-sha1=\"oSDZc7HPHhcgsZYJ7yJQcRL3Mll\" width=\"602\" height=\"211\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/a/ae6181b7e01c2e93a6200299e2118ab581858d23_2_602x211.png, https://ethresear.ch/uploads/default/optimized/2X/a/ae6181b7e01c2e93a6200299e2118ab581858d23_2_903x316.png 1.5x, https://ethresear.ch/uploads/default/original/2X/a/ae6181b7e01c2e93a6200299e2118ab581858d23.png 2x\" data-dominant-color=\"EDF0EE\"></a></strong></div><p></p>\n<p>AEPs introduces an appointed set of proposers who have the exclusive right to propose execution blocks. When the appointed set is below the minimum number of appointed proposers, a default execution proposer selection mechanism is used e.g. a second beacon-style lottery, a permissionless variation of the AEPs market.</p>\n<p>Membership in the appointed proposer set requires an appointment vote from validators controlling <em>some specified minimum amount of stake</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">. Votes are included on-chain through the inclusion list. <em>Validators can vote to appoint a specific number of proposers per validator</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">. On top of the stake-vote requirement, there needs to be an in-protocol sybil resistance mechanism for candidates to be considered for election, such as a <em>minimum proposer stake</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">. The blockchain protocol is responsible for choosing its own adequately decentralized validator set. Apart from voting to appoint block proposers, validators are responsible for block validation and censorship resistance (either directly through some form of inclusion lists or indirectly through appointing non-censoring proposers).</p>\n<p>Given inclusion in the appointed set, appointed proposers then participate in the AEPs market for the right to propose a block. <em>Some time before the desired block proposal time for a given slot</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">, the execution proposer for that slot is selected according to the AEPs market rules. <a href=\"https://ethresear.ch/t/execution-tickets/17944#design-3\">As in execution tickets</a>, inclusion lists can be specified by the beacon chain which must be adhered to by execution proposers for execution block validity.</p>\n<p>If <a href=\"https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054#builder-initiated-splitting-19\">equivocation</a>/liveness faults are observed in the appointed proposer set, validators can trigger an ejection procedure to eject an appointed proposer. This ejection procedure can be a message or set of messages force included on-chain through the inclusion list. Such a message could take the form of e.g. provable faults, or meeting <em>an ejection threshold of validator signatures</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">. If the <em>minimum number of appointed proposers threshold</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\"> is not met, the protocol falls back to the default proposer selection mechanism.</p>\n<h2><a name=\"protocol-considerations-4\" class=\"anchor\" href=\"https://ethresear.ch#protocol-considerations-4\"></a>Protocol Considerations</h2>\n<ul>\n<li>\n<p>As AEPs is agnostic to the exact market structure used for the AEPs market, we omit any details on proposer market implementation here. It is important to note that any on-chain market is non-trivial to implement. For example, the original execution tickets lack an exact specification of how/when entities enter the execution proposer market, and incentive analysis of the lottery mechanism on which it depends. For the purpose of AEPs’ intuition, one can envision a market based on a simple auction, a lottery, or a Harberger Tax based mechanism (such as proposed for block-building rights <a href=\"https://collective.flashbots.net/t/value-capturing-based-rollups-with-based-preconfirmations/2884\" rel=\"noopener nofollow ugc\">here</a> and adapted for AMM access <a href=\"https://arxiv.org/abs/2403.03367\" rel=\"noopener nofollow ugc\">here</a>). Access to the market (including or updating bids) is enforced through the inclusion list.</p>\n</li>\n<li>\n<p>The exact number of proposers that a validator can vote for appointment will depend on several factors. Some important ones are the desired target size of the appointed proposer set, and the lock-in of validators and/or validator votes (if validators can on-/off-board quickly, new validators may require a delay on when they unlock their vote).</p>\n</li>\n<li>\n<p><em>Proceeds from the AEPs market should be shared among validators</em> <img src=\"https://ethresear.ch/images/emoji/facebook_messenger/man_detective.png?v=12\" title=\":man_detective:\" class=\"emoji\" alt=\":man_detective:\" loading=\"lazy\" width=\"20\" height=\"20\">, through some combination of a share of proceeds for all validators, the validators who appointed the winning proposer, and a burn. It is important that whatever distribution mechanism is chosen incentivizes rational validators to appoint honestly and is resilient to off-chain agreements between validators and proposers.</p>\n<ul>\n<li>A naive implementation would be to share all proceeds paid by an appointed proposer back to the validators who voted for the proposer’s appointment. However, this may negatively impact the incentive for validators to appoint less competitive proposers.</li>\n<li>An alternative implementation would be to burn all proceeds from the AEPs auction. As long as there is a reasonably high vote requirement to be appointed (ensuring votes are required from some % of validators not colluding with the proposer), off-chain agreements/bribes should be ineffective.</li>\n</ul>\n</li>\n<li>\n<p>To keep the appointed proposer set competitive and to protect against monopolies, rate-limits on the % of blocks that a single proposer can propose over a given time frame can be enforced, e.g. through taxes proportional to % of blocks produced. With rate-limiting measures, AEPs can gradually reduce dominant proposer bids in slot auctions and allow alternative proposers to propose blocks. This ensures one proposer cannot produce all of the blocks, which would effectively remove competition, and then allow the monopolist to extract rents. This is possible in AEPss as a consequence of the sybil resistance that is enforced on the proposer set through delegation. Without sybil resistance of the proposer set (achieved through the vote requirement and a target size), it is not clear if any in-protocol protection against centralization can be enforced.</p>\n</li>\n<li>\n<p>For the ejection threshold, too low of a threshold, and this could be used as a griefing vector by a malicious minority of validators, too high and the threshold won’t be responsive enough to remove malicious proposers. A traffic light system, with a low threshold to pause a proposer, and a higher barrier to fully eject a proposer might be interesting, although this requires further research.</p>\n</li>\n<li>\n<p>Examples of out-of-protocol proposer requirements include geo-distribution, commitment to respond to data availability sampling requests (i.e., act as a DAS provider), commitment to provide permanent data storage beyond data availability, commitment to run trusted hardware, commitment to provide timely preconfirmations; the possibilities are endless. These requirements are reflected through in-protocol vote requirements.</p>\n</li>\n<li>\n<p>This first iteration of AEPs leans quite heavily on inclusion lists. While other mechanisms for forcing votes, ejections, and market actions on-chain may be possible, inclusion lists simplify the explanation of AEPs.</p>\n</li>\n</ul>\n<h1><a name=\"appointing-execution-proposers-vs-not-5\" class=\"anchor\" href=\"https://ethresear.ch#appointing-execution-proposers-vs-not-5\"></a>Appointing Execution Proposers vs. Not</h1>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/0/0c1b86abf0eb9d0fa83983413180c2ec079b35a0.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/0c1b86abf0eb9d0fa83983413180c2ec079b35a0\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/original/2X/0/0c1b86abf0eb9d0fa83983413180c2ec079b35a0.jpeg\" alt=\"\" data-base62-sha1=\"1J6HE1dGtGYcVfEDR5BMSiwScRa\" width=\"517\" height=\"345\" role=\"presentation\" data-dominant-color=\"3C3B40\"></a></div><p></p>\n<p>Validator inertia (doing nada) makes the AEPs protocol totally permissionless. If a minimum threshold of validators decides to appoint a proposer, this provides a clear signal that the validators prefer appointed proposers over permissionless proposers. This section explores why validators would choose one option over the other.</p>\n<h2><a name=\"why-would-validators-appoint-proposers-6\" class=\"anchor\" href=\"https://ethresear.ch#why-would-validators-appoint-proposers-6\"></a>Why would validators appoint proposers?</h2>\n<p><a href=\"https://www.investopedia.com/articles/economics/08/free-market-regulation.asp\" rel=\"noopener nofollow ugc\">Investopedia provides a nice introductory piece</a> on how some (validator) oversight can maintain healthy (proposer) markets that serve the public (blockchain users). To start this section, I quote the disadvantages of a totally permissionless “free market” as per the same article.</p>\n<blockquote>\n<ul>\n<li>A competitive environment creates an atmosphere of survival of the fittest, leading businesses to disregard the safety of the public to increase the <a href=\"https://www.investopedia.com/terms/b/bottomline.asp\" rel=\"noopener nofollow ugc\">bottom line</a>.</li>\n<li>Wealth is not distributed equally.</li>\n<li>Greed and overproduction cause the economy to have wild swings ranging from times of robust growth to cataclysmic <a href=\"https://www.investopedia.com/terms/r/recession.asp\" rel=\"noopener nofollow ugc\">recessions</a>.</li>\n</ul>\n</blockquote>\n<p>We now focus on blockchain-specific reasons why validators would appoint a proposer set. This section is split into primary and secondary reasons.</p>\n<h3><a name=\"primary-reasons-7\" class=\"anchor\" href=\"https://ethresear.ch#primary-reasons-7\"></a>Primary Reasons</h3>\n<ul>\n<li><strong>Ability to mitigate/prevent multi-slot MEV.</strong> If multi-slot MEV becomes profitable enough, we must assume that a permissionless set of actors will try to extract it. By appointing a set of distinct/accountable proposers, validators can either enforce rules on appointed proposers to propose blocks assuming they will not propose the proceeding block, or explicitly rotate out the proposer of slot <span class=\"math\">n</span> from consideration in the market for slot <span class=\"math\">n+1</span>.</li>\n<li><strong>Improved proposer reputation and assurances (generally).</strong> Having a set of appointed proposers provides the protocol and its users with higher guarantees of honest behaviour compared to a purely permissionless approach. Given the irrevocable effect that malicious behaviour can have on membership in the appointed set, proposers are strongly incentivized to propose blocks honestly/in an “aligned” manner.</li>\n<li><strong>Prevent uncontrolled centralization of the proposer market.</strong> In any primary on-chain market-based approach to delegating block proposing, secondary markets will likely emerge to allow proposers to outsource certain specialized proposing roles and remain competitive in the primary market. Unfortunately, these secondary markets have clear incentives to maximize their own take of block proposal profits. This profit-capturing tug-of-war between the primary and secondary markets is a one-sided affair when the primary market is permissionless.<br>\nWhen given the opportunity to propose a block, permissionless proposers must be expected to source bundles from secondary markets that maximize the total value of the block. If certain secondary markets/market participants emerge as dominant, these dominant participants can extract rent from the primary market, dictate the format of blocks being built, and even dictate which primary market actors can ultimately compete in the primary market.<br>\n<em>Example 1.</em> Although the provision of preconfirmations may appear to be a net benefit to all, preconfirmations may turn out to be a loss-maker for execution proposers, for example due to sophisticated pricing and infrastructure requirements. Validators may need to enforce preconfirmation provision among appointed proposers until a critical mass of preconfirmation value is achieved.<br>\n<em>Example 2.</em> It is conceivable that a CEX-DEX arbitrageur/market may become so dominant that access to the CEX-DEX arbitrage allows a proposer to create higher value blocks than any proposer not accessing the CEX. This enables permissioning of the proposer set by the CEX, outside of the control of the blockchain protocol. In such a scenario, the CEX would be able to dictate who proposes blocks in a permissionless block-market structure.</li>\n<li><strong>Threat of engaging the appointed set may be enough.</strong> We see the use of the appointed set as the most direct way to ensure a competitive proposer market long-term, while protecting against multi-block MEV and simplifying builder reputation-/-al benefits. However, these benefits may be outweighed by the desire of the community to keep the proposer market permissionless. AEPs effectively engages a nuclear non-proliferation agreement between validators and the proposer market, with the validators promising to keep the market permissionless if the proposers don’t engage in any/repeated malicious activity.</li>\n<li><strong>Bribes.</strong> Receiving an appointment is highly valuable given the exclusivity, reputation, and potential for earnings it brings. Rational permissionless validators who receive more from appointing a proposer than not appointing must be expected to appoint. The protocol and its incentives, including any revenue distribution mechanism from the AEPs market, should be constructed given this potential from off-chain bribes.</li>\n</ul>\n<h3><a name=\"secondary-reasons-8\" class=\"anchor\" href=\"https://ethresear.ch#secondary-reasons-8\"></a>Secondary Reasons</h3>\n<ul>\n<li><strong>Incentivization of non-attributable tasks.</strong> Given the existence of an appointed set, there is a large incentive to join the set to gain access to block proposing. With this incentive, appointment of some/all proposers can be conditioned on the performance of non-attributable non-block proposing tasks which benefit the ecosystem.</li>\n<li><strong>Simpler auction process.</strong> With a capped number of bidders and bidding demand, distributed auctions are simplified. <a href=\"https://arxiv.org/pdf/2301.12813.pdf\" rel=\"noopener nofollow ugc\">Sybil resistance is a thorn in the side of permissionless auctions.</a>. To paraphrase and simplify, auctions/lotteries may only be useful if there is a limited number of bidders/demand for bid inclusion is limited. Although censorship is still a concern in AEPs, the fixed number of bids with the added risk of attack attribution mitigates censorship concerns and simplfies the auction design space.</li>\n<li><strong>Validators are hardware poor, but alignment rich.</strong> It is possible that validatoors are perfect candidates to influence block proposing. Humans are still capable of doing things that machines and code cannot. If bad proposing practices emerge or are suspected, validators feel ideally placed to intervene on behalf of the protocol. This can take the form of reporting proposers for ejection, or appointing proposers more aligned with themselves/their vision for Ethereum.</li>\n</ul>\n<h2><a name=\"why-would-validators-maintain-a-permissionless-market-9\" class=\"anchor\" href=\"https://ethresear.ch#why-would-validators-maintain-a-permissionless-market-9\"></a>Why would validators maintain a permissionless market?</h2>\n<p>I start this section with the advantages of a completely free market as laid out in the Investopedia article quoted in the previous section.</p>\n<blockquote>\n<ul>\n<li>It contributes to political and civil freedom since everybody freely chooses what to produce or consume.</li>\n<li>It contributes to economic growth and transparency.</li>\n<li>It ensures competitive markets.</li>\n<li>Consumers determine what products or services are in demand.</li>\n<li>Supply and demand create competition and ensure that the best goods or services are provided to consumers at a fair price.</li>\n</ul>\n</blockquote>\n<ul>\n<li>\n<p><strong>Permissionless markets = more competition</strong>. This is true at any given instant in time. However, over a long enough time horizon, a totally permissionless market may actually reduce competition (<a href=\"https://www.economicliberties.us/big-tech-monopolies-2/\" rel=\"noopener nofollow ugc\">see the numerous ongoing big tech lawsuits on monopolization</a>). With more competition comes tighter profit margins and a brittleness of players to survive market shocks. It is not obvious that permissionless markets can replenish competitors following market shocks. Without competitors, there is no competition.</p>\n</li>\n<li>\n<p><strong>Validator strategies should only be encodable</strong>. It is possible that validators should only be assumed to be able to hard-code their logic to remove subjectivity from validator tasks. This would restrict validator enforceability to attributable tasks. The key open question here is whether or not hardcoded rules can adapt to defend a decentralized system as well as a majority of its stake-weighted users. When the games that are harming the system (<a href=\"https://www.coindesk.com/tech/2023/12/06/ethereums-censorship-problem-is-getting-worse/\" rel=\"noopener nofollow ugc\">censorship laws</a>, off-chain agreements, cartelization, monopolization) are being played off-chain, this is particularly unclear.</p>\n</li>\n<li>\n<p><strong>Maintaining no in-protocol proposer requirements is simple and easy.</strong> <a href=\"https://en.wikipedia.org/wiki/Occam%27s_razor\" rel=\"noopener nofollow ugc\">Occam’s Razor</a>.</p>\n</li>\n<li>\n<p><strong>If it ain’t broke, don’t fix it.</strong> It is possible that a permissionless proposer market best empowers the majority of users. At the very least, by creating big-node small-node separation, leveraging a decentralized small-node set regardless of the big node market structure should maintain/improve censorship resistance. This is the case made for execution tickets without AEPs.</p>\n</li>\n</ul>\n<h1><a name=\"food-for-thought-10\" class=\"anchor\" href=\"https://ethresear.ch#food-for-thought-10\"></a>Food for Thought</h1>\n<p><img src=\"https://ethresear.ch/uploads/default/original/2X/3/3d004a4ec53173d13719798bd9d660cbbc67547c.jpeg\" alt=\"\" data-base62-sha1=\"8HDKlIHbfxiv0HWzJIzSzyABR0g\" width=\"375\" height=\"375\" role=\"presentation\"><br>\n<em>Some will see AEPs’ optional restriction of block proposing to the appointed set as a no-go and a contradiction to the permissionless ideals of Ethereum.</em></p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/c/c794ab2f002f2180a1b658e0d4b7a52e57c9edba.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/c794ab2f002f2180a1b658e0d4b7a52e57c9edba\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/c/c794ab2f002f2180a1b658e0d4b7a52e57c9edba_2_517x249.jpeg\" alt=\"\" data-base62-sha1=\"stzxllawqVGgRrTUKyBsDpntANA\" width=\"517\" height=\"249\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/c/c794ab2f002f2180a1b658e0d4b7a52e57c9edba_2_517x249.jpeg, https://ethresear.ch/uploads/default/original/2X/c/c794ab2f002f2180a1b658e0d4b7a52e57c9edba.jpeg 1.5x, https://ethresear.ch/uploads/default/original/2X/c/c794ab2f002f2180a1b658e0d4b7a52e57c9edba.jpeg 2x\" data-dominant-color=\"514B48\"></a></div><p></p>\n<p><em>AEPs, like many others before, decouple validation from execution-block building and proposing. This protects the decentralization of the validator set. AEPs goes one step further, ensuring this decentralized set of protocol representatives can have a meaningful say in who should propose blocks, and what block-proposal standards should be adhered to. Making proposers accountable to the validators and users they represent might be as aligned as it gets.</em></p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/appointed-execution-proposers-because-the-proposer-you-know/19284\">Read full topic</a></p>","link":"https://ethresear.ch/t/appointed-execution-proposers-because-the-proposer-you-know/19284","pubDate":"Fri, 12 Apr 2024 07:38:27 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19284"},"source":{"@url":"https://ethresear.ch/t/appointed-execution-proposers-because-the-proposer-you-know/19284.rss","#text":"Appointed Execution Proposers: Because the Proposer you know…"}},{"title":"Introducing eoracle - the Ethereum Oracle","dc:creator":"0xNimrod","category":"Uncategorized","description":"<p>Thanks to <a class=\"mention\" href=\"https://ethresear.ch/u/eomatan\">@EOmatan</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/alonchayet\">@AlonChayet</a> , <a class=\"mention\" href=\"https://ethresear.ch/u/ittayeyal\">@IttayEyal</a> , <a class=\"mention\" href=\"https://ethresear.ch/u/obpeo\">@obpeo</a> and the all Lightblocks Labs team and a special thanks for <a class=\"mention\" href=\"https://ethresear.ch/u/sreeramkannan\">@sreeramkannan</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/justindrake\">@JustinDrake</a> and <a class=\"mention\" href=\"https://ethresear.ch/u/vbuterin\">@vbuterin</a> for the inspiration</p>\n<h1><a name=\"hello-world-1\" class=\"anchor\" href=\"https://ethresear.ch#hello-world-1\"></a>Hello world;</h1>\n<p>Ethereum and Bitcoin faced challenges that were overcome with a very cautious approach, resulting in an extraordinary case study for global human coordination. Adding real-world data through oracles as another layer on top of it is a very promising next step. However, so far, we have taken this step forward without the same caution that is fundamental to the journey toward a decentralized ecosystem. Perhaps we were <strong>too close to the problem</strong>, focusing only on the outcome - making data accessible - and not being mindful enough about the process allowing it.</p>\n<h3><a name=\"the-problem-with-the-problem-2\" class=\"anchor\" href=\"https://ethresear.ch#the-problem-with-the-problem-2\"></a>The problem with the problem</h3>\n<p>The term “oracle problem” is misleading as it conflates the problem with the solution. The actual problem is the inherent inability of blockchains to dynamically interact with mutable, external data sources, while the “oracle” refers to the proposed solution. That is, an oracle refers to the infrastructure that provides blockchains with real-world data in a trustless and secure manner.</p>\n<p>Naive solutions come with many problems of their own, including latency, accuracy, cost, and more. <strong>These are not the oracle problem, but problems of oracles, and we as an industry haven’t been very mindful about this distinction</strong>. As a result, we are now at the point where we have some very interesting solutions for the problems of oracles, but we don’t have a sufficient solution to the actual oracle problem.</p>\n<p>After shifting the perspective to the right problem, we need to recognize that the latest challenges we tackled as a community were derived directly from our vision to eliminate a central point of failure and power. Solving the oracle problem with this dedication in mind is a journey that must follow the same standards.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/e/edc61b3ee5c274d504b987765fd3c01878d111e8.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/edc61b3ee5c274d504b987765fd3c01878d111e8\" title=\"4 (1)\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/e/edc61b3ee5c274d504b987765fd3c01878d111e8_2_284x375.jpeg\" alt=\"4 (1)\" data-base62-sha1=\"xVrBip3HbK05NPbREn69Cz9Bj6w\" width=\"284\" height=\"375\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/e/edc61b3ee5c274d504b987765fd3c01878d111e8_2_284x375.jpeg, https://ethresear.ch/uploads/default/optimized/2X/e/edc61b3ee5c274d504b987765fd3c01878d111e8_2_426x562.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/e/edc61b3ee5c274d504b987765fd3c01878d111e8_2_568x750.jpeg 2x\" data-dominant-color=\"B6ABA8\"></a></div><p></p>\n<h3><a name=\"standards-introspection-3\" class=\"anchor\" href=\"https://ethresear.ch#standards-introspection-3\"></a>Standards Introspection</h3>\n<p>The Ethereum community holds itself to high standards for what we expect from a network.</p>\n<p>Let’s unpack this with a few examples of protocol standards that captured our mindshare recently as they touch some of the most agreeable underlying values of the community:</p>\n<ul>\n<li>It bothers us when there is a concentration of stake in a few operators.</li>\n<li>We talk about \"client diversity”, a topic not even on the radar for most projects.</li>\n<li>We see our home-stakers as incredibly valuable and cherish them as such.</li>\n</ul>\n<p>These are just a few examples of our standards.</p>\n<p>What we really want from a protocol is:</p>\n<ol>\n<li>It should <strong>work as long as the participants follow</strong> the rules.</li>\n<li>It should make a good case for <strong>why the participants will follow</strong> the rules.</li>\n<li>It should do that <strong>with <a href=\"https://ethresear.ch/t/proof-of-stake-basic-asssumption-risk/40/7\">minimal assumptions</a> about the participant’s behavior</strong> so that we can trust it to last even with different circumstances.</li>\n</ol>\n<p>We are very critical and uncompromising on that because we know—and we don’t let the day-to-day challenges cause us to deviate from our values—<strong>that our ultimate goal is to build a global, trust-minimized settlement layer.</strong></p>\n<p>To better understand the journey and challenges in finding a solution to the oracle problem, we should examine the significant work previously done in this field and how it aligns with our standards.</p>\n<h3><a name=\"previous-work-4\" class=\"anchor\" href=\"https://ethresear.ch#previous-work-4\"></a>Previous Work</h3>\n<p>There has been significant work in the oracle space, characterized by good intentions, progress, and innovation. Some solutions focus predominantly on user experience, treating the oracle as merely a feature that makes data accessible to smart contracts, thereby losing sight of the core properties of decentralized applications.</p>\n<p>Other solutions emphasize decentralization through their architecture, by distributing the process of fetching, verifying, and delivering data among multiple participants. This is a step in the right direction, but they have yet to convincingly overcome several challenges.</p>\n<ol>\n<li>Their network is operated by a selected, well-connected, and semi-internal permissioned set of nodes. That’s understandable - it’s hard to bootstrap a trustless system, but a good protocol needs to explain why it will pass the bootstrapping phase, not only why it will be good when it passes that.</li>\n<li>They retain centralized ownership of their smart contracts due to a lack of effective governance.</li>\n<li>The computation and incentives among the participants are not fully transparent or accessible to the public. So, their crypto-economic security hinges on the trust placed in the corporation that owns the oracle.</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/e/e53f91225a3c30719fcdf1747fb6b7effdc722d8.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/e53f91225a3c30719fcdf1747fb6b7effdc722d8\" title=\"Twitter post - 3 (1) (1)\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/e/e53f91225a3c30719fcdf1747fb6b7effdc722d8_2_517x291.jpeg\" alt=\"Twitter post - 3 (1) (1)\" data-base62-sha1=\"wI1wZYPBlYwUjblC4FEIk0IhZji\" width=\"517\" height=\"291\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/e/e53f91225a3c30719fcdf1747fb6b7effdc722d8_2_517x291.jpeg, https://ethresear.ch/uploads/default/optimized/2X/e/e53f91225a3c30719fcdf1747fb6b7effdc722d8_2_775x436.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/e/e53f91225a3c30719fcdf1747fb6b7effdc722d8_2_1034x582.jpeg 2x\" data-dominant-color=\"383D34\"></a></div><p></p>\n<p>Essentially, we’re at a point in DeFi where oracles are many protocols’ weakest link because we trust them based on reputation and history  in a striking contrast to blockchains, which we trust due to their inherent design.  Fortunately, although there were many oracle malfunction incidents with some causable losses for users - we haven’t suffered from an FTX kind of incident regarding oracles.</p>\n<p>For those of you who are comfortable with the way things are because of  the lack of such an incident, we would love to introduce you to another battle-tested, efficient product with a fantastic business model that hasn’t failed just <a href=\"https://en.wikipedia.org/wiki/Central_bank\" rel=\"noopener nofollow ugc\">yet</a>.</p>\n<p>Obviously this is not how we do things around here, we aren’t chickens. - What?!</p>\n<h3><a name=\"a-completely-unrelated-tale-5\" class=\"anchor\" href=\"https://ethresear.ch#a-completely-unrelated-tale-5\"></a><em>A completely  <s>Un</s>related tale</em></h3>\n<p><em>Once upon a time, on a farm far away, there was a chicken named Alice who lived what could only be described as the dream life. The farmer, a paragon of punctuality and care, ensured their food was always delivered on the dot, fresh, plentiful, and best of all, completely free of charge. What chicken could ask for more? Alice, having hatched into this utopia, soaked up every second of her idyllic existence. For 1000 blissful days, she enjoyed the unparalleled generosity of her human benefactor, but on day 1001, everything changed. The farmer, the very architect of her paradise, approached with a machete in hand and abruptly ended Alice’s life.</em></p>\n<p><em>Well, that was an unexpected ending to the story -  wasn’t it?</em></p>\n<p>This is akin to Hume’s ‘problem of induction’: We are told to trust oracle X to execute well tomorrow since it executed well yesterday. This is not the kind of reasoning we are looking for.</p>\n<h2><a name=\"trust-design-meme690x360-75upload7mwodsyq5iegbkznbqtcbb1wvxwjpeg-6\" class=\"anchor\" href=\"https://ethresear.ch#trust-design-meme690x360-75upload7mwodsyq5iegbkznbqtcbb1wvxwjpeg-6\"></a><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/3/369783344325b0eb0d4385cd1841d89c559708cc.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/369783344325b0eb0d4385cd1841d89c559708cc\" title=\"trust design meme\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/3/369783344325b0eb0d4385cd1841d89c559708cc_2_517x270.jpeg\" alt=\"trust design meme\" data-base62-sha1=\"7MWoDSYq5IegbkZNBqTcBB1wVxW\" width=\"517\" height=\"270\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/3/369783344325b0eb0d4385cd1841d89c559708cc_2_517x270.jpeg, https://ethresear.ch/uploads/default/optimized/2X/3/369783344325b0eb0d4385cd1841d89c559708cc_2_775x405.jpeg 1.5x, https://ethresear.ch/uploads/default/original/2X/3/369783344325b0eb0d4385cd1841d89c559708cc.jpeg 2x\" data-dominant-color=\"433D31\"></a></div></h2>\n<h1><a name=\"eoracle-foundations-7\" class=\"anchor\" href=\"https://ethresear.ch#eoracle-foundations-7\"></a>eoracle foundations</h1>\n<h3><a name=\"a-problems-first-approach-8\" class=\"anchor\" href=\"https://ethresear.ch#a-problems-first-approach-8\"></a>‘A Problems First’ Approach</h3>\n<p>In light of our standards reflection and the evident misalignment in previous work, we advocate for a first principle approach to tackling the oracle problem. This strategy zeroes in on solving the fundamental issue of blockchain’s interaction with external off-chain data in the most rigorous and demanding manner possible. By adhering strictly to the high standards we’ve set, this approach prioritizes addressing the core challenge of trustless data integration. Other challenges around data and implementation are crucial, respected, and important to solve, but they can’t be of any significance if countering the essence of oracles in a decentralized ecosystem. These problems should be solved on top of and not instead of the core solution.</p>\n<h3><a name=\"how-do-ethereum-values-translate-to-oracles-9\" class=\"anchor\" href=\"https://ethresear.ch#how-do-ethereum-values-translate-to-oracles-9\"></a>How do Ethereum values translate to oracles?</h3>\n<p>Armed with a new perspective, and laser-focused approach on the problem, we should now make a list of  guidelines our protocol should follow in order for it to align with Ethereum standards and be able to rise to its crucial and complex role.</p>\n<ol>\n<li><strong>Decentralized Ownership</strong> - Oracles as evolving protocols need a way to adapt in the face of industry changes. A fully immutable protocol is not practical, and a decentralized architecture is only worth doing with decentralized ownership.</li>\n<li><strong><a href=\"https://ethresear.ch/t/proof-of-stake-basic-asssumption-risk/40/7\">Minimal Trust Assumptions</a></strong> - The security model should avoid additional assumptions on the entities involved other than - ‘<em>they like making money and dislike losing it</em>’.</li>\n<li><strong>Permissionless Participation</strong> - All roles within the protocol should be entirely open for anyone to participate.</li>\n<li><strong>Maximum Visibility of the Process</strong> - To trust how data is being aggregated, we must provide an immutable and “accessible for all” layer for the process to occur on.</li>\n<li><strong>Transparent Incentive Mechanism</strong> - The positive and negative incentives should be known to all and tracked publicly, as they are the driving forces of a well-designed system.</li>\n<li><strong>Proper Bootstrapping Model</strong> - The design should present a compelling story about how the protocol will work in a fully decentralized way and how it will get there.</li>\n</ol>\n<h3><a name=\"justin-drakes-suggestion-for-enshrined-eth2-price-feeds-10\" class=\"anchor\" href=\"https://ethresear.ch#justin-drakes-suggestion-for-enshrined-eth2-price-feeds-10\"></a>Justin Drake’s Suggestion for Enshrined Eth2 Price Feeds</h3>\n<p>We came across <a class=\"mention\" href=\"https://ethresear.ch/u/justindrake\">@JustinDrake</a> <a href=\"https://ethresear.ch/t/enshrined-eth2-price-feeds/7391\">suggestion</a> about an enshrined Ethereum stakers’ oracle, which sparked our thinking. The suggestion is about, in essence, adding another field to <code>[BeaconBlockBody]</code> for price feeds. This original approach has some performance limitations. Most importantly as <a class=\"mention\" href=\"https://ethresear.ch/u/vbuterin\">@vbuterin</a> <a href=\"https://ethresear.ch/t/enshrined-eth2-price-feeds/7391/4\">pointed out</a>, it increases the workload and potentially raises the entry barrier for home stakers to take part, once again emphasizing Ethereum’s uncompromising approach to security and decentralization.</p>\n<p>On the other side, this suggestion spotlights a new, bright and refreshing approach - use the same group of stakers, that we already trust (under minimal assumptions) and have them be the trust quorum for delivering data on chain. This way we can minimize additional trust assumptions for this crucial task.</p>\n<p>There was a lot to do in order for it to become something practical but the good news is that we realized that the biggest downside of the suggestion might be solvable - we don’t actually need all stakers, just a permissionless diverse sub-set of stakers that are up for another “job”.</p>\n<h3><a name=\"enter-eigenlayer-the-trust-marketplace-11\" class=\"anchor\" href=\"https://ethresear.ch#enter-eigenlayer-the-trust-marketplace-11\"></a>Enter EigenLayer - The Trust Marketplace</h3>\n<p>The change from ‘work’ to ‘capital’ as a commitment guarantee introduces the PoS ecosystem with the benefits of the efficiency of money, one of its features being that you don’t have to consume it in order to create value with it.</p>\n<p>We will stop the hand waving here because we still struggle to explain to our moms the innovation of restaking in traditional finance terms.</p>\n<p>In the eyes of a protocol, which has some kind of decentralized security model, trust is in fact the <strong>set of individual entities coordinating</strong> and <strong>their  incentives to follow the process.</strong></p>\n<p>For this trust-seeking protocol, EigenLayer suggests a Trust Marketplace. Here, we have to ask - <strong>Is some trust better than others?</strong> The short answer is - Yes.</p>\n<p>We should think of two ways to evaluate trust:</p>\n<p><strong>Economic Trust</strong> -  amount of capital at stake = <strong>Quantity</strong></p>\n<p><strong>Diversity Of Trust</strong>  -  number of different nodes and their decorrelation = <strong>Quality</strong></p>\n<p>In order to achieve security and liveness in a decentralized way, a protocol will need a sufficient amount of economic trust and a diverse, well-balanced set of nodes to carry it.<br>\nAlthough it’s theoretically possible to achieve a decentralized trust quorum for a protocol, in reality, only Bitcoin and Ethereum have achieved a sufficient level of decentralization. This is despite numerous protocols attempting to do so. This struggle could be referred to as the challenge of proper bootstrapping. Some great oracles fall into this category of having the right idea, and have a good explanation of how they will operate once they get past bootstrapping but don’t have a compelling plan about how they’re going to get to there.</p>\n<p>We believe that EigenLayer and restaking is exactly the missing piece for a superior oracle design - that could actually get there.</p>\n<h3><a name=\"stepping-into-the-arena-12\" class=\"anchor\" href=\"https://ethresear.ch#stepping-into-the-arena-12\"></a>Stepping into the Arena</h3>\n<p>In creating the architecture for a fully decentralized oracle network, our design is guided towards system that is inherently aware of its operational dynamics. This necessitates a comprehensive tracking mechanism for participant actions, their incentives (both positive and negative), and the resulting outcomes, all within a framework that guarantees transparency and immutability. In the near future, it should be run and managed by users and not a central authority.</p>\n<p>Ideally the best oracle infrastructure is Ethereum itself, where we have a set of nodes that take some observations about off-chain data, declare (submit/post) it on-chain for a smart contract that applies some aggregation and verification logic on the votes and concludes the aggregated and hopefully (if built correctly) accurate and secure outcome for smart contracts to use. This simple architecture has everything we want as guidelines for the protocol. Unfortunately, this solution is infeasible, the cost and latency resulting in the recording of all this process on-chain would be way above what a useful oracle can allow. S<strong>o we needed to come up with a database that we could afford to offload the computation</strong> to in order to minimize the target chain activity.</p>\n<p>Does that sounds like a scaling problem? We think so.</p>\n<h3><a name=\"scaling-problem-scaling-solution-13\" class=\"anchor\" href=\"https://ethresear.ch#scaling-problem-scaling-solution-13\"></a>Scaling problem? → Scaling solution</h3>\n<p>We concluded that establishing another PoS blockchain as an independent data and settlement layer will allow us to build an oracle that is mindful of the process, fully transparent, and eventually completely decentralized and owned by the users. This PoS blockchain, that we named “eoracle chain”, together with the task of fetching data, will be operated by Eigen operators - Ethereum validators that are willing to restake their ETH on the protocol and secure the network and the data processes. eoracle chain will allow us to maintain decentralized incentives for the oracle operators and to have all the calculations on-chain instead of on the client’s software. To this end, we store all their relevant data submissions and the aggregation of their data, and either reward or punish them according to their behavior.</p>\n<p>After outlining our desired design, we’ll now address some of the challenges and opportunities associated with building an PoS based oracle with EigenLayer.</p>\n<hr>\n<h1><a name=\"challenges-and-improvements-14\" class=\"anchor\" href=\"https://ethresear.ch#challenges-and-improvements-14\"></a>Challenges and Improvements</h1>\n<h3><a name=\"who-said-reconfiguration-15\" class=\"anchor\" href=\"https://ethresear.ch#who-said-reconfiguration-15\"></a>Who said Reconfiguration?!</h3>\n<p>Changing the set of validators over time is classically known as <em>reconfiguration</em>. Known solutions basically involve agreeing on updates to the committee as part of the consensus process for new blocks. That is, the decision of a block <span class=\"math\">i</span> includes the details of the committee that will generate block <span class=\"math\">i+1</span>.</p>\n<p>However, the validators of our chain are not determined on our chain but rather on Ethereum through the restaking and unstaking operations there. Therefore, each block includes a reference (hash pointer) to the latest Ethereum block. This implicitly determines the committee for the next block: the set of restakers at that Ethereum block.</p>\n<p>This is where the problem diverges from classical instances: The committee defined in that Ethereum block is temporary, and becomes deprecated once its members unstake. If this occurs, our blockchain might remain without an active committee.</p>\n<p>We overcome this by introducing a novel design we call <em>Aegis,</em> the algorithm behind eoracle chain, that protects (like the mythical shield) a derivative chain (eoracle chain) using a primary one (Ethereum).</p>\n<p>Aegis relies on routine checkpoints between Ethereum and Aegis. If Aegis is unable to update due to asynchrony, we trigger a reset on both chains to maintain progress without violating other consensus properties.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/9535b02546a77ecb1d55a5e52bbf197664f9a794.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/9535b02546a77ecb1d55a5e52bbf197664f9a794\" title=\"Untitled\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/9535b02546a77ecb1d55a5e52bbf197664f9a794_2_690x157.jpeg\" alt=\"Untitled\" data-base62-sha1=\"lhYauBUR5vbF4aQyX1W0fhNzhMo\" width=\"690\" height=\"157\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/9535b02546a77ecb1d55a5e52bbf197664f9a794_2_690x157.jpeg, https://ethresear.ch/uploads/default/optimized/2X/9/9535b02546a77ecb1d55a5e52bbf197664f9a794_2_1035x235.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/9535b02546a77ecb1d55a5e52bbf197664f9a794_2_1380x314.jpeg 2x\" data-dominant-color=\"F2F2F2\"></a></div><p></p>\n<h3><a name=\"can-you-add-long-range-resistance-in-the-mix-16\" class=\"anchor\" href=\"https://ethresear.ch#can-you-add-long-range-resistance-in-the-mix-16\"></a>Can you add Long Range Resistance in the mix?</h3>\n<p>A central challenge of Proof of Stake blockchains is that of <em>Long-Range Attacks</em>. In a PoS blockchain, operators get to extend the chain based on their current staked tokens. This allows stakers from a long time ago to quickly produce a fictitious long branch of the blockchain. For a newly joining node, the validity of this branch is indistinguishable from the correct one generated over time by the network. Ethereum overcomes this by having a vast network of operators that monitor the blockchain and will discard such a fictitious branch. A newly joining node can always find a critical mass of reliable nodes to help with this.</p>\n<p>However, in a nascent PoS blockchain that does not yet have sufficiently many operators, long-range attacks are a concern. Aegis overcomes this by deriving its security from Ethereum itself. The checkpointing mechanism on Ethereum prevents an attacker from rolling back the Aegis (eoracle chain): they would need to roll back Ethereum itself to perform a long-range attack on Aegis.</p>\n<h3><a name=\"unbundling-token-utilities-17\" class=\"anchor\" href=\"https://ethresear.ch#unbundling-token-utilities-17\"></a>Unbundling Token Utilities</h3>\n<p>Decentralized oracle networks (DON) are protocols that act as a two-sided marketplace, hence a well-designed token design is a load barring for them. A design that doesn’t include a utility token will be much less efficient in aligning the interests of the different kinds of operators and users of the protocol. In addition, an oracle must have decentralized governance.</p>\n<p>However, although a token is fundamental for an oracle, the use of a native token for the security of the protocol comes with major risks. A native token suffers from two major disadvantages in relation to ETH when used for security. The first con is its fluctuating value that could cause major shifts in the oracle’s <em>Cost of Corruption.</em> The second weakness is its smaller market cap, resulting in a better ability for an attacker to extract additional gain by short selling, resulting in higher possible <em>Profit from Corruption.</em> These are very important factors from a cryptoeconomic security point of view.</p>\n<p>A dual token approach <a href=\"https://ethresear.ch/t/counter-proposal-to-enshrined-price-feeds-dual-token-oracles/7437\">as suggested by</a> <a class=\"mention\" href=\"https://ethresear.ch/u/vbuterin\">@vbuterin</a>, is to utilize ETH as the lion’s share of the security,  ensuring high ‘<em>Budget</em>’ for attacking  the protocol and a ‘C<em>ost’</em> of Attack based on the oracle native token.  In addition, the native token will be used for incentivizing positive behaviour, penalizing malicious actors and for decentralized ownership and governance. This way, we can enjoy stability, crypto-economic security, and flexibility of stake with ETH and alignment with the native token.</p>\n<h3><a name=\"nothing-at-stake-18\" class=\"anchor\" href=\"https://ethresear.ch#nothing-at-stake-18\"></a>“Nothing at stake”</h3>\n<p>To avoid oracles being manipulated and encourage honest behavior among data providers, we need a mechanism to detect and deter participants from submitting false data.</p>\n<p>Unlike well-defined protocol rules that can be programmatically verify based on information stored on-chain, real-world data seems to have a more subjective nature. For example, two operators could disagree on a piece of data without any malicious intent. They simply have different perceptions of what is “true”. Of course, resorting to a third-party ‘referee’ to settle such disagreements would contradict the goal of avoiding a central authority governing the protocol. How do we detect false reports in this subjective setting?</p>\n<p>We believe the first step towards a solution is to separate the aggregation from the basic task of securely introducing off-chain data into the blockchain. Traditionally, oracle operators fetch, aggregate, and publish data to the DON. We, however, adopt a different approach and divide this complex process into distinct phases.</p>\n<p>This approach brings several benefits. Firstly, specifying the task in detail (“submit event ‘E’ from source ‘XYZ’” instead of a general “submit data”) reduces the expected variance in submissions. This, in turn, enhances the robustness of fraud detection and our ability to measure “honesty” among data providers. Additionally, handling raw data, rather than aggregated data, provides more modularity and flexibility in the logic layer, as we’ll discuss next.</p>\n<h3><a name=\"modularity-and-the-problem-of-ever-changing-demand-19\" class=\"anchor\" href=\"https://ethresear.ch#modularity-and-the-problem-of-ever-changing-demand-19\"></a><strong>Modularity and the problem of ever changing demand</strong></h3>\n<p>Predicting short and long-term data demand is challenging. This includes determining the types of data needed for DApps, its usage, security requirements, and associated costs. Furthermore, each data field has its unique complexities. For instance, pricing data has distinctive properties and nuances compared to weather or RWA data. A well-designed oracle must support this flexibility and modularity requirement, ensuring that changes or adjustments in the logic layer do not compromise the system’s core security. We insisted on a fully transparent and immutable data process using the eoracle execution layer, with all raw data submissions on-chain. The result is a modular system that can accommodate any computation or data source users may require. The complexities and subtleties of different data types are crucial. With an oracle dedicated to continuous improvement of these solutions, we’ve created a system where flexibility and modularity are inherent. We encourage our users and the community to be meticulous and critical of this process, and to actively participate.</p>\n<hr>\n<h3><a name=\"eoracle-end-game-20\" class=\"anchor\" href=\"https://ethresear.ch#eoracle-end-game-20\"></a>eoracle End Game</h3>\n<p>The use and demand for off-chain data will change drastically in the next few years. New use cases will arise, different types of data will become relevant on-chain, and the vulnerabilities from this evolution will dictate new and complex security measures. The answer to the question of how some crucial piece of data is being aggregated, secured, priced, and incentivized is not a static one. A brilliant group of people could dedicate their career to analyze data demand, to establish algorithmic solutions for the right aggregation, and they could attract a specialized set of nodes to do the data provisioning. In the current state they will most definitely not be able to cover all the potential market needs. Instead, they will have to put a huge amount of effort in establishing the infrastructure to allow those algorithms.</p>\n<p>eoracle has a different plan in mind. We want to leverage the power of permissionless innovation and market dynamics to solve the oracle problem. We envision a perfect market for decentralized data and computation, deeply rooted in the belief that the complex oracle problem cannot be solved by a fixed product or algorithm. Instead, it requires a dynamic free market and a platform designed for permissionless innovation. Leveraging principles of <a href=\"https://en.wikipedia.org/wiki/Perfect_competition\" rel=\"noopener nofollow ugc\">perfect competition</a>, eoracle aims to create an ecosystem where supply and demand seamlessly meet. We are building a decentralized platform that serves as the coordination and settlement layer for innovation around bringing data and compute onto the blockchain.</p>\n<p>Our system will trustlessly act as a layer where operators could submit their raw observations on data. Smart contracts will be the algorithmic layer ensuring a fully transparent and immutable process of data aggregation and verification. Developers could request any kind of data with any kind of properties like security mechanisms or guarantees, insurance, latency, diversity, sourcing, and more.</p>\n<p>The use of EigenLayer operators as the active participants of the system is a natural choice, allowing a very flexible supply of work and stake - a crucial ingredient for a perfect competition marketplace.</p>\n<h3><a name=\"ending-but-essentially-just-the-beginning-21\" class=\"anchor\" href=\"https://ethresear.ch#ending-but-essentially-just-the-beginning-21\"></a>Ending - but essentially just the beginning</h3>\n<p>Guided by Ethereum’s foundational values and the trust marketplace enabled by EigenLayer, we seek to address the critical challenge of integrating off-chain data and compute without compromising on trust and decentralization. In addition, we envision the value paid by dapps using our oracle solution, will get paid directly to Ethereum validators who are providing the validation, keeping this value within the Ethereum ecosystem instead of going to the pockets of third party intermediaries. With the collective effort of the Ethereum community and the pursuit of solutions that adhere to core cypherpunk values, we hope to help build the next iteration of decentralized oracle networks and enable permissionless innovation through new use cases of decentralized applications, backed by Ethereum security.</p>\n            <p><small>6 posts - 3 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/introducing-eoracle-the-ethereum-oracle/19276\">Read full topic</a></p>","link":"https://ethresear.ch/t/introducing-eoracle-the-ethereum-oracle/19276","pubDate":"Wed, 10 Apr 2024 20:12:41 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19276"},"source":{"@url":"https://ethresear.ch/t/introducing-eoracle-the-ethereum-oracle/19276.rss","#text":"Introducing eoracle - the Ethereum Oracle"}},{"title":"Zero-knowledge proofs of identity using electronic passports","dc:creator":"turboblitz","category":"zk-s[nt]arks","description":"<h1><a name=\"zero-knowledge-proofs-of-identity-using-electronic-passports-1\" class=\"anchor\" href=\"https://ethresear.ch#zero-knowledge-proofs-of-identity-using-electronic-passports-1\"></a>Zero-knowledge proofs of identity using electronic passports</h1>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/a/ae85fbbbb938d295752b4f8fcb38f3fcab695885.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/ae85fbbbb938d295752b4f8fcb38f3fcab695885\" title=\"282155110-514ae671-3c02-434f-ac6a-31ce20eec24d\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/a/ae85fbbbb938d295752b4f8fcb38f3fcab695885_2_690x154.jpeg\" alt=\"282155110-514ae671-3c02-434f-ac6a-31ce20eec24d\" data-base62-sha1=\"oTU8xNH8BEQKw9C1kGydQCd2BXD\" width=\"690\" height=\"154\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/a/ae85fbbbb938d295752b4f8fcb38f3fcab695885_2_690x154.jpeg, https://ethresear.ch/uploads/default/optimized/2X/a/ae85fbbbb938d295752b4f8fcb38f3fcab695885_2_1035x231.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/a/ae85fbbbb938d295752b4f8fcb38f3fcab695885_2_1380x308.jpeg 2x\" data-dominant-color=\"624F5C\"></a></div><p></p>\n<p>Many applications need to verify their user’s identity online, whether it is nationality, age, or simply uniqueness. Today, this is hard. They are stuck between shady heuristics like tracking IP addresses and technologies like Worldcoin that need to deploy their infrastructure widely.</p>\n<p>Fortunately, UN countries in association with the International Civil Aviation Organization have built a great tool for us to piggyback on: electronic passports. They are issued by more than 172 countries and include an NFC chip with a signature of the person’s information, including name, date of birth, nationality and gender. Issuing countries make their public keys accessible in online registries, enabling the verification of signatures.</p>\n<h2><a name=\"a-circuit-for-passport-verification-2\" class=\"anchor\" href=\"https://ethresear.ch#a-circuit-for-passport-verification-2\"></a>A circuit for passport verification</h2>\n<p>For someone to prove their identity using a passport, they will have to do two things. First, read the content of their passport’s chip. This can be done easily with any NFC-enabled phone. Then, show a verifier that their passport has been correctly signed. Instead of sending all of their personal data for the verification to happen, they can generate a zero-knowledge proof that redacts some of their inputs.</p>\n<p>Our circuit will have to checks two things:</p>\n<ul>\n<li>The disclosed attributes have been signed correctly</li>\n<li>The corresponding public key is part of the public key registry of UN countries</li>\n</ul>\n<p>A simple circuit compliant with the electronic passport specs would look something like this:</p>\n<div>\n  <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/e/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e.png\" data-download-href=\"https://ethresear.ch/uploads/default/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e\" title=\"B1_4A2ZxC.png\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/e/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e_2_500x336.png\" data-base62-sha1=\"wIE0k9iREZTDIUOJGImJNLbxV7w\" width=\"500\" height=\"336\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/e/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e_2_500x336.png, https://ethresear.ch/uploads/default/optimized/2X/e/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e_2_750x504.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/e/e55186294a00f20a4e0fd0cdc8da1172a89d3e3e_2_1000x672.png 2x\" data-dominant-color=\"F8F4F3\"></a></div>\n</div>\n<p>Here is roughly what happens:</p>\n<ul>\n<li>Each datagroup stored in the passport contains some of the person’s information. The datagroups we are most interested in are the first one (nationality, age, etc) and the second one (photo). The circuit takes them as inputs along with the signing public key.</li>\n<li>Datagroups are hashed, concatenated and hashed again.</li>\n<li>The final result is formatted, hashed and signed by the country authority. We can use the public key to check this signature.</li>\n</ul>\n<p>This makes the following attributes disclosable: name, passport number, nationality, issuing state, date of birth, gender, expiry date, photo.<br>\nSome countries also provide additional data like place of birth, address, phone number, profession and a person to notify. Biometrics like fingerprint and iris are sometimes included but can’t be retrieved, as they require a special access key.</p>\n<p>In practice, we want our circuit to have a few other features:</p>\n<ul>\n<li>Instead of passing the country’s public key directly, we want the user to prove that the public key that signed their passport is part of the registry published by the ICAO. This can be done by passing a merkle proof of inclusion and having only the merkle root as a public input.</li>\n<li>To allow for selective disclosure of any attribute, we pass a bitmap as a public input that will redact some of the attributes.</li>\n<li>We want specific modules for age disclosure and nationality list inclusion. A range check can guarantee someone is above a certain age without disclosing the precise age, and an inclusion check can be done over a set of countries to prove someone is or is not a citizen of any country in a list.</li>\n<li>For applications like minting an SBT or voting, we want to check that the passport is not expired. This can be done by passing the current date and doing a range check over the date in the circuit. We can then check that the current date is correct using the block timestamp in a smart contract or server-side in offchain verification.</li>\n<li>For applications that need sybil-resistance, we want to store a nullifier that prevents using the same passport twice. The simplest approach involves storing a hash of the government’s signature, though this does not render the individual anonymous from the government’s perspective. There are other approaches, see <a href=\"https://ethresear.ch/t/privacy-preserving-nullifiers-for-proof-of-identity-applications/18551\">here</a> for a discussion of the tradeoffs.</li>\n</ul>\n<p>A map of a more complete circuit can be found <a href=\"https://hackmd.io/_uploads/rk9_ZaZeC.png\" rel=\"noopener nofollow ugc\">here</a>.</p>\n<p>One of the challenges is the <a href=\"https://hackmd.io/@TCEn_IDhTDWLjwyItiiBcQ/BJ4LX0m9p\" rel=\"noopener nofollow ugc\">number of signature algorithms used</a>. Most countries use common ones like RSA with SHA256, but the ICAO specifications are quite permissive and some countries chose to use hash functions like SHA512 or unusual padding formats. We currently support the most common one and we are working on <a href=\"https://github.com/zk-passport/proof-of-passport/issues/38\" rel=\"noopener nofollow ugc\">adding support for more</a>.</p>\n<h2><a name=\"applications-3\" class=\"anchor\" href=\"https://ethresear.ch#applications-3\"></a>Applications</h2>\n<p>Applications roughly fall into three categories: proof of humanity, selective disclosure and authentication.</p>\n<p>Proof of humanity can be used in general for sybil resistance. This includes voting, fair airdrops, quadratic funding and helping social media fight bots. If passports can’t be construed as a general solution today, they can be integrated into wider systems like Gitcoin Passport or Zupass.</p>\n<p>Selective disclosure has applications like privacy preserving age check. Some countries restrict buying alcohol, drugs or entering casinos for minors, and zk could help bringing better privacy to those controls.</p>\n<p>Another example of selective disclosure is proving one is not a citizen of any country in a set of forbidden countries. This could help creating an intermediate level of compliance between KYC-gated traditional finance and fully permissionless DeFi.</p>\n<p>Using passport signatures for authentication, one can build a ERC-4337 recovery module that asks for a proof from a specific passport as one of the conditions for recovery. Some passports also support Active Authentication, meaning they have their own private key and the ability to sign data. This would make them suitable for direct transaction signing, either for small transactions or in a multisig setup with other signers.</p>\n<h2><a name=\"limitations-4\" class=\"anchor\" href=\"https://ethresear.ch#limitations-4\"></a>Limitations</h2>\n<p>The most obvious limitations of using passport signatures are the following:</p>\n<ul>\n<li>The passport does not do any kind of biometric check when the chip is read. Therefore there is no straightforward way to know if the passport has not been borrowed or stolen.</li>\n<li>Most of the world population does not have a passport. Even in the US, only around 50% of the population owns a passport.</li>\n<li>Issuing authorities can create an arbitrary number of passports and cheat in systems that require passports for sybil resistance.</li>\n<li>Passports can be lost or revoked. Some countries allow citizen to keep their previous passport when they are issued a new one. Some people have dual citizenship. All those cases are hard to mitigate, as the signatures stay valid.</li>\n</ul>\n<p>Those limitations are all quite fundamental to the way passports work today. They can be addressed by aggregating attestations from multiple sources, which will be covered in a future post.</p>\n<h2><a name=\"current-state-5\" class=\"anchor\" href=\"https://ethresear.ch#current-state-5\"></a>Current state</h2>\n<p>Proof of Passport is <a href=\"https://github.com/zk-passport/proof-of-passport\" rel=\"noopener nofollow ugc\">fully open source</a>, from mobile app to circuits. If you are interested in contributing, please check <a href=\"https://github.com/zk-passport/proof-of-passport/issues\" rel=\"noopener nofollow ugc\">open issues</a>.</p>\n<p>While performance would have been a bottleneck a few years ago, work from teams like Polygon ID, arkworks and mopro have made client-side proving on smartphones quite fast. Generating a proof with the current circuit takes ~4 seconds on a recent iPhone.</p>\n<p>We are currently focused on shipping the mobile app for the first integrations. It allows users to mint an Soulbound Token disclosing <a href=\"https://testnets.opensea.io/fr/assets/goerli/0x64bfeff18335e3cac8cf8f8e37ac921371d9c5aa/0\" rel=\"noopener nofollow ugc\">only specific attributes they chose</a>, or none at all other than the validity of their passport. <a href=\"https://t.me/FlorentTavernier\" rel=\"noopener nofollow ugc\">Contact us</a> to try out the beta release.</p>\n<p>Thanks to <a href=\"https://github.com/remicolin\" rel=\"noopener nofollow ugc\">Rémi</a>, <a href=\"https://twitter.com/AndyGuzmanEth\" rel=\"noopener nofollow ugc\">Andy</a>, <a href=\"https://twitter.com/yush_g\" rel=\"noopener nofollow ugc\">Aayush</a>, <a href=\"https://github.com/yssf-io\" rel=\"noopener nofollow ugc\">Youssef</a> and <a href=\"https://twitter.com/viv_boop\" rel=\"noopener nofollow ugc\">Vivek</a> for contributing ideas and helping build this technology!</p>\n            <p><small>7 posts - 4 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/zero-knowledge-proofs-of-identity-using-electronic-passports/19263\">Read full topic</a></p>","link":"https://ethresear.ch/t/zero-knowledge-proofs-of-identity-using-electronic-passports/19263","pubDate":"Tue, 09 Apr 2024 20:32:22 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19263"},"source":{"@url":"https://ethresear.ch/t/zero-knowledge-proofs-of-identity-using-electronic-passports/19263.rss","#text":"Zero-knowledge proofs of identity using electronic passports"}},{"title":"Analysis on ''Correlated Attestation Penalties''","dc:creator":"Nerolation","category":"Economics","description":"<h1><a name=\"analysis-on-correlated-attestation-penalties-1\" class=\"anchor\" href=\"https://ethresear.ch#analysis-on-correlated-attestation-penalties-1\"></a>Analysis on ‘‘Correlated Attestation Penalties’’</h1>\n<p>This is a quick quantitative analysis on anti-correlation penalties looking into its potential impact on staking operators and CL clients. Before getting into it, make sure to check out <a href=\"https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116/12\">Vitalik’s recent proposal</a> on anti-correlation incentives in his latest blog post.</p>\n<h2><a name=\"anti-correlation-penalties-2\" class=\"anchor\" href=\"https://ethresear.ch#anti-correlation-penalties-2\"></a>Anti-correlation Penalties</h2>\n<p>In the current landscape, stakers benefit from economies of scale: enhanced network connectivity, superior hardware reliability, and the expertise of devs managing the infra all improve with scale. Consequently, economies of scale act as a strong force towards centralization within blockchain networks.</p>\n<p><strong>To strengthen decentralization</strong>, it is essential to architect mechanisms that counteract the advantages of economies of scale.</p>\n<p>Fortunately, <strong>economies of scale are intrinsically linked with correlation effects</strong>: When a single operator runs many validators on one machine and experiences downtime, all those validators are affected at once. Thus, leveraging economies of scale comes with correlation effects. This results in a correlated risk and anti-correlation penalties punish those who leverage economies of scale to their advantage.</p>\n<blockquote>\n<p>In this context, the distinction between “anti-correlation incentives” and “correlation penalties” is minimal, as both strategies aim towards the same objective of promoting decentralization.</p>\n</blockquote>\n<p>It is important to note that the <strong>beacon chain lacks awareness of validator clusters</strong>. It perceives only individual validators, which appear largely indistinguishable from one another. Hence, anti-correlation incentives target the “hidden” connections among validators. While not guaranteeing improved decentralization in <strong>every</strong> instance, anti-correlation penalties may contribute positively to the broader objective of reducing centralization forces.</p>\n<h2><a name=\"vitaliks-initial-proposal-3\" class=\"anchor\" href=\"https://ethresear.ch#vitaliks-initial-proposal-3\"></a>Vitalik’s initial proposal</h2>\n<p>The initial proposal introduces the formula <span class=\"math\">p[i] = \\frac{misses[i]}{\\sum_{j=i-32}^{i-1} misses[j]}</span> and caps it at p = 4.</p>\n<p>This means, to determine the penalties of a specific slot, we maintain a moving average on the number of missed attestations over 32 slots and then compare it with the number of missed attestations for the current slot. In the case that the number of missed attestations in a slot is higher than the moving average, <span class=\"math\">p &gt; 1</span>, a correlated penalty is applied.</p>\n<p>This might look like the following example (assuming a moving avg. of 3 validators):</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/d/d6b39ff27167b40ba20e8a57952415c9d06c1b05.png\" data-download-href=\"https://ethresear.ch/uploads/default/d6b39ff27167b40ba20e8a57952415c9d06c1b05\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/original/2X/d/d6b39ff27167b40ba20e8a57952415c9d06c1b05.png\" alt=\"\" data-base62-sha1=\"uDl1quqM8b0xn3V6Pn67vwEhjiB\" role=\"presentation\" width=\"690\" height=\"432\" data-dominant-color=\"F1F0EF\"></a></div><p></p>\n<p>In the illustration above, validators missing their attestations in slots <span class=\"math\">n</span> and <span class=\"math\">n+2</span> benefit because few others missed theirs at the same time<br>\nFor slot <span class=\"math\">n+1</span>, a correlation penalty applies due to the number of missed attestations exceeding the moving average threshold of 3 per slot.</p>\n<h2><a name=\"analysis-4\" class=\"anchor\" href=\"https://ethresear.ch#analysis-4\"></a>Analysis</h2>\n<p>First, for reproduciability, the dataset I’m using contains all attestations between epoch 263731 (Feb-16-2024) and 272860 (Mar-28-2024).<br>\nThese are <strong>&gt;40 days of attestations</strong>, amounting to a total number of <strong>~9,3 billion observations</strong>.</p>\n<p>In the following, we simulate having implemented the formula that Vitalik suggested (see above) and determine the impact it would have had on attestation penalties. Furthermore, we compare it to the status quo to see what would change.</p>\n<h3><a name=\"staking-operators-5\" class=\"anchor\" href=\"https://ethresear.ch#staking-operators-5\"></a>Staking Operators</h3>\n<p>First, let’s look at the sum of all penalties for 4 clusters containing multiple different entities. While the large size cluster contains entities such as Lido, Coinbase or Kiln, the small size cluster is composed of solo stakers and rocket pool stakers. The mid-size cluster is everything in between.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/1c67834034e6473ad683d0422260830f4f3c4604.png\" data-download-href=\"https://ethresear.ch/uploads/default/1c67834034e6473ad683d0422260830f4f3c4604\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/1c67834034e6473ad683d0422260830f4f3c4604_2_690x276.png\" alt=\"\" data-base62-sha1=\"43h8VWxWhl46L3T3RUjUqv83XkU\" role=\"presentation\" width=\"690\" height=\"276\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/1c67834034e6473ad683d0422260830f4f3c4604_2_690x276.png, https://ethresear.ch/uploads/default/original/2X/1/1c67834034e6473ad683d0422260830f4f3c4604.png 1.5x, https://ethresear.ch/uploads/default/original/2X/1/1c67834034e6473ad683d0422260830f4f3c4604.png 2x\" data-dominant-color=\"EADDE3\"></a></div><p></p>\n<ul>\n<li>The large-size cluster would have had a higher penalty compared to the status quo. The same applied to the mid-size cluster although the effect is less strong.</li>\n<li>The small-size cluster would have profited by ending up with less penalties.</li>\n<li>The “unidentified” category comprises around 15% of all validators and definitely contains a large number of solo stakers that weren’t correctly classified as such because my solo-staker-classifier is highly conservative.</li>\n</ul>\n<p><strong>This initially confirms the expectation that there exist correlations that cause individual validators to either not miss or miss together with other validators run by the same entity.</strong><br>\n → <em>Check the Appendix I for the same graph showing the individual entities.</em></p>\n<p><strong>Let’s look at the cumulative impact anti-correlation penalties would have:</strong></p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/d/df1285f3fa454538f545ec50ccd3e219316bdcd5.png\" data-download-href=\"https://ethresear.ch/uploads/default/df1285f3fa454538f545ec50ccd3e219316bdcd5\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/d/df1285f3fa454538f545ec50ccd3e219316bdcd5_2_690x164.png\" alt=\"\" data-base62-sha1=\"vPoa1Xdb0F7SOuFCtVTBKdQ0mIR\" role=\"presentation\" width=\"690\" height=\"164\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/d/df1285f3fa454538f545ec50ccd3e219316bdcd5_2_690x164.png, https://ethresear.ch/uploads/default/optimized/2X/d/df1285f3fa454538f545ec50ccd3e219316bdcd5_2_1035x246.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/d/df1285f3fa454538f545ec50ccd3e219316bdcd5_2_1380x328.png 2x\" data-dominant-color=\"F5F3F3\"></a></div><p></p>\n<ul>\n<li>As expected, for <strong>large entities</strong> (<em>left</em>), we can see a drift of the “anti-correlation penalty”-line from the status quo. This means that those entities categorized as “large-size” would have had higher penalties.</li>\n<li>For <strong>mid-size clusters</strong> (<em>mid</em>), this effect is the opposite, even though it’s very not very significant.</li>\n<li>For <strong>small-size clusters</strong> (<em>right</em>), we see an improvement compared to the status quo. Those entities would have had smaller penalties with anti-correlation penalties in place.</li>\n</ul>\n<h3><a name=\"cl-clients-6\" class=\"anchor\" href=\"https://ethresear.ch#cl-clients-6\"></a>CL Clients</h3>\n<p>We can basically do the same for CL clients. The expectation is that there is a correlation in validators running the same client. Anti-correlation penalties should thus be higher for validators running majority clients.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/ff6792e1d47905fc1785b65d056f3f98412e648e.png\" data-download-href=\"https://ethresear.ch/uploads/default/ff6792e1d47905fc1785b65d056f3f98412e648e\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/ff6792e1d47905fc1785b65d056f3f98412e648e_2_690x431.png\" alt=\"\" data-base62-sha1=\"ArpEXNHJXTuq0uxjA3relkAgGe2\" role=\"presentation\" width=\"690\" height=\"431\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/ff6792e1d47905fc1785b65d056f3f98412e648e_2_690x431.png, https://ethresear.ch/uploads/default/original/2X/f/ff6792e1d47905fc1785b65d056f3f98412e648e.png 1.5x, https://ethresear.ch/uploads/default/original/2X/f/ff6792e1d47905fc1785b65d056f3f98412e648e.png 2x\" data-dominant-color=\"EADDE3\"></a></div><p></p>\n<p>Small deviations from the “<em>current situation</em>” bar are generally a good sign as it points towards the non-existance of “hidden” client bugs that cause validators missing out to attest - at least for the analysed time frame. Although, we do see some deviations from the status quo for all clients, the effects are rather negligible for Teku and Prysm.<br>\nLighthouse validators would improve their position while Lodestar validators would be worse-off with anti-correlation penalties.</p>\n<p>Notable, the result shown in the above chart is heavily depended on staking operators: e.g. if a single large staking operator who is using Lodestar goes offline because of network problems, it directly increases the correlation penalties for the client at the same time, even though the client software might be totally fine.</p>\n<h1><a name=\"conclusion-7\" class=\"anchor\" href=\"https://ethresear.ch#conclusion-7\"></a>Conclusion</h1>\n<p>Implementing anti-correlation penalties is a great way to counter economies of scale without requiring the protocol to differentiate between individual validators.<br>\nWhile this analysis looked and staking operators and CL client, there are many more properties to analyse. This includes, for example, hardware setup, EL client, geographical location, ISP provider, etc.</p>\n<p>Finally, anti-correlation penalties are a great way to improve decentralization and the Ethereum community should definitely consider it in future updates.</p>\n<h2><a name=\"appendix-8\" class=\"anchor\" href=\"https://ethresear.ch#appendix-8\"></a>Appendix</h2>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/5/55ad2ff43ec81339eb797a4a87f4937cffbdd970.png\" data-download-href=\"https://ethresear.ch/uploads/default/55ad2ff43ec81339eb797a4a87f4937cffbdd970\" title=\"correlation_penalty_entity (10)\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/5/55ad2ff43ec81339eb797a4a87f4937cffbdd970_2_409x500.png\" alt=\"correlation_penalty_entity (10)\" data-base62-sha1=\"cdVDv3tvYsdXR7S69MOccr6ds9W\" width=\"409\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/5/55ad2ff43ec81339eb797a4a87f4937cffbdd970_2_409x500.png, https://ethresear.ch/uploads/default/optimized/2X/5/55ad2ff43ec81339eb797a4a87f4937cffbdd970_2_613x750.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/5/55ad2ff43ec81339eb797a4a87f4937cffbdd970_2_818x1000.png 2x\" data-dominant-color=\"DECCD5\"></a></div><p></p>\n            <p><small>20 posts - 11 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244\">Read full topic</a></p>","link":"https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244","pubDate":"Tue, 09 Apr 2024 08:23:06 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19244"},"source":{"@url":"https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244.rss","#text":"Analysis on ''Correlated Attestation Penalties''"}},{"title":"Zero-Knowledge Proof Vulnerability Analysis and Security Auditing","dc:creator":"Mirror","category":"zk-s[nt]arks","description":"<p>Zero-Knowledge Proof (ZKP) technology marks a revolutionary advancement in the field of cryptography, enabling the verification of certain information ownership without revealing any specific details. This technology, with its paradoxical yet powerful characteristics, provides a solid foundation for a wide range of applications, especially in enhancing the privacy and security of blockchain technology and other cryptographic systems. As ZKP technology increasingly becomes a part of the blockchain infrastructure, its importance for security and integrity becomes more pronounced. However, the complexity of ZKP implementation and the rapid iteration of the technology introduce various vulnerabilities, challenging the privacy and security it aims to offer.</p>\n<p>This study bases on the integrity, soundness, and zero-knowledge properties of ZKP to meticulously classify existing vulnerabilities and deeply explores multiple categories of vulnerabilities, including integrity issues, soundness problems, information leakage, and non-standardized cryptographic implementations. Furthermore, we propose a set of defense strategies that include a rigorous security audit process and a robust distributed network security ecosystem. This audit strategy employs a divide-and-conquer approach, segmenting the project into different levels, from the application layer to the platform-nature infrastructure layer, using threat modeling, linear code checking, and internal cross-review, among other means, aimed at comprehensively identifying vulnerabilities in ZKP circuits, revealing design flaws in ZKP applications, and accurately identifying inaccuracies in the integration process of ZKP primitives.</p>\n<p><strong>Read More</strong><br>\n<a href=\"https://eprint.iacr.org/2024/514\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://eprint.iacr.org/2024/514</a></p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/zero-knowledge-proof-vulnerability-analysis-and-security-auditing/19241\">Read full topic</a></p>","link":"https://ethresear.ch/t/zero-knowledge-proof-vulnerability-analysis-and-security-auditing/19241","pubDate":"Tue, 09 Apr 2024 02:46:56 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19241"},"source":{"@url":"https://ethresear.ch/t/zero-knowledge-proof-vulnerability-analysis-and-security-auditing/19241.rss","#text":"Zero-Knowledge Proof Vulnerability Analysis and Security Auditing"}},{"title":"Fraud Proofs Are Broken","dc:creator":"GCdePaula","category":"Layer 2","description":"<h1><a name=\"fraud-proofs-are-broken-1\" class=\"anchor\" href=\"https://ethresear.ch#fraud-proofs-are-broken-1\"></a>Fraud Proofs Are Broken</h1>\n<p><em>… but we can fix them.</em></p>\n<p>Optimistic rollups aim to inherit Ethereum’s security through fraud proofs. The reasoning is straightforward: a single honest validator can prove all dishonest validators are liars, and thus enforce the truth. Since anyone can be a validator (including you), securing any optimistic rollup is just a matter of setting up a node to run on your laptop. No need to trust anyone.</p>\n<p>The underlying assumption is that these fraud proof algorithms are permissionless. We know of three algorithms that aim for permissionless interactive fraud proofs. In no particular order: Cartesi’s <em>Permissionless Refereed Tournaments</em> (PRT), Arbitrum’s <em>Bounded Liquidity Delay</em> (BoLD), and <em>OP Stack’s Fault Proof System</em> (OPFP).</p>\n<p>They all have issues. <strong>They’re vulnerable, in different ways, to <a href=\"https://doi.org/10.1007%2F3-540-45748-8_24\" rel=\"noopener nofollow ugc\">Sybil attacks</a> that undermine the safety, settlement speed and/or decentralization of the fraud proof system.</strong></p>\n<p>Our discussion focuses on the theoretical properties of the proposed algorithms, rather than the current development stages of any specific protocol that may or may not have training wheels. If the underlying algorithm isn’t resistant to Sybil attacks, the training wheels can never be safely removed. Now, fraud proofs with a permissioned set of validators are certainly much better than no fraud proofs at all; it’s quite acceptable as an intermediary stage. However, we need to keep researching better algorithms.</p>\n<p>I’m a contributor in the Cartesi ecosystem, which provides an optimistic rollups solution. I’m part of the team developing the next iteration of our fraud proof protocol, mentioned above.</p>\n<p>This post has three purposes:</p>\n<ul>\n<li><strong>Establish a set of criteria to analyze fraud proofs.</strong> Quoting Vitalik, <a href=\"https://vitalik.eth.limo/general/2024/03/28/blobs.html\" rel=\"noopener nofollow ugc\">the ecosystem’s standards need to become stricter</a>.</li>\n<li><strong>Articulate why none of the candidates put forth so far meet these criteria.</strong> Including ours.</li>\n<li><strong>Call for open and public research collaboration between the optimistic rollups teams.</strong> This is a personal frustration of mine. Our attempts at public communication with these teams haven’t been successful at eliciting substantive academic discourse on the vulnerabilities and tradeoffs for existing fraud proof algorithms.</li>\n</ul>\n<p>This post is <em>not</em> about providing a solution to Sybil attacks in fraud proofs, nor is it about proposing a new algorithm. Furthermore, this post is concerned only with <em>interactive</em> fraud proofs; non-interactive fraud proofs have different challenges and criteria.</p>\n<h1><a name=\"criteria-2\" class=\"anchor\" href=\"https://ethresear.ch#criteria-2\"></a>Criteria</h1>\n<p>Optimistic rollups generally operate under two key assumptions: the base layer works (but can be arbitrarily censored for up to a week) and the presence of at least one honest validator. Under these assumptions, we need to design a protocol that allows anyone to participate while being resistant to Sybil attacks. Sybil attacks are the antagonist of this story, an ever-present adversary any permissionless protocol must face.</p>\n<p>We propose three properties for analyzing permissionless interactive fraud proofs: safety, promptness and decentralization. These properties should be viewed as spectra rather than binary. Loosely, a permissionless algorithm is:</p>\n<ul>\n<li><strong>Safe</strong> if it can reject all false states under the original assumptions;</li>\n<li><strong>Prompt</strong> if settlement cannot be delayed substantially (or indefinitely);</li>\n<li><strong>Decentralized</strong> if validating doesn’t require a lot of resources like hardware and funds.</li>\n</ul>\n<p>In an ideal world, we want the honest validator to win any dispute in a timely manner using nothing more than a toaster.</p>\n<p>We’ll assume the reader is generally familiar with fraud proofs. We’ll call the set of honest validators the <strong><em>hero</em></strong> (worst case scenario is just one validator), and the set of dishonest validators working in tandem the <strong><em>adversary</em></strong>. We’ll use the terms <em>validator</em> and <em>player</em> interchangeably.</p>\n<h2><a name=\"whats-at-stake-3\" class=\"anchor\" href=\"https://ethresear.ch#whats-at-stake-3\"></a>What’s at stake</h2>\n<p>A dispute puts the total value locked (TVL) of a rollup at stake. An incorrect states that gets accepted can be extraordinarily profitable for the adversary. However, the same is not true for the hero – the hero gets nothing of the TVL by winning.</p>\n<p>This financial imbalance puts the hero at an incredible disadvantage. At the limit, the adversary should be willing to burn a TVL’s worth of resources. What’s worse, different attackers may trustlessly coordinate through smart contracts and pool their resources.</p>\n<p>We cannot assume the hero can match a TVL’s worth of resources, not even when teaming up with others. We must assume the adversary has significantly more resources than the hero, given what’s at stake. It’s a lot harder to design good algorithms under these constraints.</p>\n<h1><a name=\"canetti-et-al-4\" class=\"anchor\" href=\"https://ethresear.ch#canetti-et-al-4\"></a>Canetti et al.</h1>\n<p>Traditional fraud proof protocols are based on the <a href=\"https://doi.org/10.1016/j.ic.2013.03.003\" rel=\"noopener nofollow ugc\">work of Canetti</a>. We’ll highlight a few important concepts. The basic idea is quite simple.</p>\n<p>Consider a setup with only two players. First, these players agree upon an initial state and a state-transition function (STF). They’ll run the computation on their machine by successively applying the STF to the initial state, and propose a final state to the blockchain. These proposals are called <em>claims</em>; they’re a commitment to the final state of a computation. If the players agree, all is well. If not, the system starts a verification game. A verification game consists of two phases: the <em>bisection phase</em> and the <em>one-step proof phase</em>. The bisection phase is an interactive binary search over the whole computation, trying to find where the players first disagree. This disagreement is called the <em>divergence</em>. Once the divergence is found, the blockchain applies the STF once (a <em>step</em>), and eliminates the adversary.</p>\n<p>Now consider a setup with many players. Naively extending the algorithm described above, there’s an attack where the adversary posts the honest claim but lose the game on purpose by playing dishonestly. This makes evident the fragility of Canetti with respect to Sybils: it doesn’t reveal lies, it reveals liars. We can’t group players with the same claim into teams. Each player must represent themselves and only themselves for all parts of the dispute, even when there are others with the same claim. Players’ signatures have to be part of the message.</p>\n<p>Canetti proposes a few ways to make verification games with many players, taking this fragility into consideration. Unfortunately, none of those approaches scale well on the number of players. This makes the algorithm unsuited for permissionless fraud proofs since they’d be susceptible to Sybil attacks.</p>\n<p>For example, the first fraud proof protocols of Cartesi and Arbitrum (based on Canetti) would fail the promptness property if made permissionless without further changes. Ed Felten wrote a <a href=\"https://research.arbitrum.io/t/solutions-to-delay-attacks-on-rollups/692\" rel=\"noopener nofollow ugc\">post</a> describing delay attacks, which are a type of Sybil attacks that compromises the promptness of the protocol. In short, there’s an attack where settlement is delayed linearly on the number of Sybils, which can be a very long time indeed.</p>\n<p>We need to design algorithms that can scale on the number of players, and thus be resistant to Sybil attacks. Otherwise, we won’t be able to make protocols permissionless.</p>\n<h1><a name=\"permissionless-refereed-tournaments-prt-5\" class=\"anchor\" href=\"https://ethresear.ch#permissionless-refereed-tournaments-prt-5\"></a>Permissionless Refereed Tournaments (PRT)</h1>\n<p>The PRT algorithm was developed by Cartesi. The paper can be found <a href=\"https://arxiv.org/abs/2212.12439\" rel=\"noopener nofollow ugc\">here</a>. The algorithm is focused on application-specific rollups, which have different requirements when compared to shared chains. This has influenced the design of PRT: it’s important that anyone can validate a rollup in a laptop with minimal stakes. (We’d argue this is also true for shared chains; ideally, the hero shouldn’t need a supercomputer or a gazillion dollars.)</p>\n<p>The key contribution of PRT is <em>computation hashes</em>. It addresses the fragility of Canetti described above, allowing players to be grouped into teams. This enables a more efficient tournament structure.</p>\n<h2><a name=\"computation-hashes-6\" class=\"anchor\" href=\"https://ethresear.ch#computation-hashes-6\"></a>Computation hashes</h2>\n<p>Claims in PRT are a stronger kind of commitment. Instead of a commitment just to a final state, claims are a commitment to the entire path of the computation (<em>i.e.</em> a <em>computation hash</em>). A computation hash is Merkle tree where each leaf is a hash representing the state at every state transition along the computation.</p>\n<p>Bisections in PRT require a valid Merkle proof that the intermediary state is consistent with the computation hash. This way, an adversary that posts the honest computation hash cannot lose the game on purpose (except by inaction). As such, PRT can allow anyone to bisect any claim, since the Merkle proofs guarantee the bisection is honest. There’s a fundamental shift: PRT can reveal lies, instead of just liars. Players’ signatures need no longer be part of the message.</p>\n<p>Therefore players can be grouped into teams and fight together. With this property, PRT creates a bracket-style tournament between claims, matching them pairwise and eliminating half the Sybils at each bracket level. <strong>This means the amount of work required of the hero is logarithmic in the number of Sybils</strong>; PRT scales well on the number of players.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba\" title=\"have you tried logarithms?\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba_2_296x303.jpeg\" alt=\"have you tried logarithms?\" data-base62-sha1=\"3QIuMPbCrMSET7MALq1tkrPqmN4\" width=\"296\" height=\"303\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba_2_296x303.jpeg, https://ethresear.ch/uploads/default/optimized/2X/1/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba_2_444x454.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/1afc14e3db541a2c67ed0bf8b0221edcf44c96ba_2_592x606.jpeg 2x\" data-dominant-color=\"E5E3E3\"></a></div><p></p>\n<hr>\n<p>To make a claim, players need to post a stake. After a claim is made, there’s no need to post further stakes. Bisections are free, except for gas costs. Since the adversary needs to deposit one stake to create one Sybil, and half the Sybils are eliminated at each iteration, launching a Sybil attack is exponentially expensive.</p>\n<p>The hero needs only fight one match at a time, which means they’ll only ever need one computer. Furthermore, they need to deposit only a single stake. This means the decentralization property of PRT is great. Additionally, given the assumptions of optimistic rollups, the correct claim will always be enforced, which means PRT is safe.</p>\n<p>On promptness, delay grows logarithmically on the number of Sybils, which is nice since logarithms grow very slowly. Unfortunately, this logarithmic delay has high constants: each single match still takes about a week to complete. The logarithm of Sybils multiplied by a week is quite slow. It’s not fatally slow, but it’s still quite slow.</p>\n<p>At this point, PRT has reached a trilemma of safety, promptness and decentralization. A rollup can choose:</p>\n<ul>\n<li><strong>promptness and safety</strong> by increasing stakes (harming decentralization);</li>\n<li><strong>promptness and decentralization</strong> by reducing the maximum base layer censorship (harming safety);</li>\n<li><strong>safety and decentralization</strong> by making stakes small and keeping the maximum base layer censorship at seven days (harming promptness).</li>\n</ul>\n<p>Ideally, we’d want to have the three properties at the same time, but for PRT something will have to give. We believe the second option is acceptable for chains that don’t have a lot of TVL. But since the other algorithms were designed with high TVL in mind, for this comparison we’ll pick the third option.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">PRT</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Safety</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Promptness</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Decentralization</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n</tbody>\n</table>\n</div><h2><a name=\"multi-stage-disputes-7\" class=\"anchor\" href=\"https://ethresear.ch#multi-stage-disputes-7\"></a>Multi-stage disputes</h2>\n<p>The PRT paper describes two setups: single-stage and multi-stage. In practice, <em>if the state-transition function is a single virtual machine (VM) step</em>, the single-stage setup is prohibitive for large computations. Generating a computation hash with every state transition in a computation is extremely slow. We introduced the multi-stage setup to address this issue.</p>\n<p>The idea is to make the initial computation hash sparse, where the number of state transitions between each Merkle leaf is greater than one. This means we can’t resolve the divergence between two sparse computation hashes. The blockchain would need to perform too many state-transition functions.</p>\n<p>However, we can reduce the search space to the sparseness of that commitment. With a smaller search space, we have reduced the dispute to a smaller computation; we can recursively use the same method, but with a denser computation hash since the computation smaller. The base case is a fully dense computation hash that can be resolved normally. Players still need to post a stake at every nested tournament they wish to submit a claim, otherwise generating a Sybils would be cheap.</p>\n<p>This technique is clever, but introduces delays. In a two-stage setup, there’s a strategy where the adversary can delay settlement for the logarithm <em>squared</em> of the number of Sybils, making it strictly worse than the single-stage setup.</p>\n<p>The description and analysis of PRT above consider the faster single-stage setup. Although prohibitive if the state-transition function is a single virtual machine step, we can leverage ZK proofs and change the state-transition function from one VM step to several VM steps. This makes the single-stage setup possible in practice. Note that this is still an interactive fraud proof; it’s just a change to its state-transition function.</p>\n<p>Check <a href=\"https://twitter.com/stskeeps\" rel=\"noopener nofollow ugc\">Carsten Munk</a>’s presentation <a href=\"https://youtu.be/leCd5kyDTR8\" rel=\"noopener nofollow ugc\">here</a> about proving the execution of our virtual machine in ZK, using RISC Zero. Our benchmarks with low-end hardware are promising. This increases the hardware requirements from one laptop to one laptop with one GPU. Our <a href=\"https://github.com/cartesi/dave\" rel=\"noopener nofollow ugc\">ongoing implementation</a> (called Dave) currently uses the multi-stage setup. We’re moving to the single-stage setup because it has better promptness. We’re also engaging in more research to create an algorithm that achieves all three properties simultaneously.</p>\n<h1><a name=\"bounded-liquidity-delay-bold-8\" class=\"anchor\" href=\"https://ethresear.ch#bounded-liquidity-delay-bold-8\"></a>Bounded Liquidity Delay (BoLD)</h1>\n<p>In December 2022, Arbitrum <a href=\"https://research.arbitrum.io/t/solutions-to-delay-attacks-on-rollups/692\" rel=\"noopener nofollow ugc\">announced</a> their protocol was vulnerable to delay attacks in a permissionless setting. In the same post, they announced they had a solution, and that they’d post it soon. In August 2023, they released a <a href=\"https://github.com/OffchainLabs/bold/blob/main/docs/research-specs/BOLDChallengeProtocol.pdf\" rel=\"noopener nofollow ugc\">preliminary paper</a>, along with an <a href=\"https://github.com/OffchainLabs/bold\" rel=\"noopener nofollow ugc\">implementation</a>, naming it BoLD. The full paper is yet to be released. (One of the motivations of this text is also a call for teams to prioritize these discussions.) We look forward to the full release; we believe it will benefit the ecosystem as a whole.</p>\n<p>BoLD was developed independently from PRT (PRT was published first), but both algorithms reached similar techniques. In particular, BoLD also uses computation hashes and the recursive disputes technique with sparse computation hashes. We’ve described these two techniques in the PRT section above. We highlight that players need to post a stake to enter a challenge in BoLD.</p>\n<p>Unlike PRT, instead of setting up a tournament with brackets, in BoLD all claims fight each other simultaneously. Because of this and a novel clock technique, the settlement time is constant, regardless of the number of Sybils. The current implementation has a <a href=\"https://x.com/dzack23/status/1737864854059335905\" rel=\"noopener nofollow ugc\">16 day settlement time</a>. As such, the promptness property of BoLD is great. But there are trade-offs.</p>\n<p>The core issue of BoLD is safety, compromised by an attack we call <strong><em>proof of whale</em></strong>. It’s a kind of Sybil attack where a better funded adversary can win the dispute against the hero by exhausting the hero’s resources until they have no more resources to keep playing the game.</p>\n<p>Reiterating, winning a dispute is extraordinarily profitable for the adversary, but not for the hero. At the limit, the adversary should be willing to burn resources approaching the TVL of the rollup. It’s reasonable to assume the attacker is significantly better funded than the hero.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/2e390d880e5a7c2b330739c88e01e3550641a3a8.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/2e390d880e5a7c2b330739c88e01e3550641a3a8\" title=\"poor seal\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/2e390d880e5a7c2b330739c88e01e3550641a3a8_2_368x368.jpeg\" alt=\"poor seal\" data-base62-sha1=\"6AUckhfvPz10FsTcN6hAbhY1uZi\" width=\"368\" height=\"368\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/2e390d880e5a7c2b330739c88e01e3550641a3a8_2_368x368.jpeg, https://ethresear.ch/uploads/default/optimized/2X/2/2e390d880e5a7c2b330739c88e01e3550641a3a8_2_552x552.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/2e390d880e5a7c2b330739c88e01e3550641a3a8_2_736x736.jpeg 2x\" data-dominant-color=\"A8A8A8\"></a></div><p></p>\n<p>The hero needs to spend three different kinds of resource throughout a dispute: compute, blockspace, and stakes. Since each of these can be acquired with money, <em>proof of whale</em> can be seen as exhausting the hero <em>financially</em>. However, these resources are on different dimensions, and will be analyzed separately.</p>\n<p>We’ll describe three variants to <em>proof of whale</em>, each exhausting a different resource.</p>\n<h2><a name=\"variant-one-zerg-rush-the-heros-servers-9\" class=\"anchor\" href=\"https://ethresear.ch#variant-one-zerg-rush-the-heros-servers-9\"></a>Variant one: Zerg Rush the hero’s servers</h2>\n<p>The first variant is an attack on the computational resources of the hero. The worst-case work required of honest parties is linear in the number of Sybils. Since the time is constant (one week) but the work is linear on the number of Sybils, hardware requirements grow linearly with the number of stakes the adversary is willing to burn.</p>\n<p>This attack is hard to defend against, because the hero must be able to scale his computational power dynamically, or always dimension it with the worst case scenario in mind. Furthermore, the adversary needs no extra computers to pull this off since they can completely fabricate the states without turning on a VM.</p>\n<p>Nevertheless, the adversary still has to burn one stake to create one Sybil. If the cost of stakes is irrelevant, then this attack is trivial to pull off. Increasing the stake to just match the cost of renting one laptop makes this attack as costly for the adversary as it is for the hero. In this case, if the adversary has more stakes than the hero has computers, then a wrong claim will win. Further increasing the stake increases the hero’s advantage.</p>\n<p>Increasing the stake as to dominate the cost of hardware does mitigate this attack. However, it’s harder for players to participate when stakes are higher, compromising the decentralization of the algorithm.</p>\n<h2><a name=\"variant-two-zerg-rush-the-heros-access-to-blockspace-10\" class=\"anchor\" href=\"https://ethresear.ch#variant-two-zerg-rush-the-heros-access-to-blockspace-10\"></a>Variant two: Zerg Rush the hero’s access to blockspace</h2>\n<p>The second variant is an attack on the hero’s access to blockspace. Blockspace can be acquired by expending funds (think paying ether for transaction costs), but it’s not the only way. If a player is a block producer in the base layer (or has a generous friend who is), they will have blockspace access without expending funds for transaction costs. In any case, blockspace is not free; players have a limited amount of it. As such, instead of modeling access to blockspace as funds, it’s better to think about blockspace as a total budget for transactions that each player consume along a dispute. This attack is <em>not</em> about denying the hero’s access to blockspace (<em>i.e.</em> censorship), but forcing the hero to use up their budget.</p>\n<p>All Sybils created by the adversary must be fought simultaneously by the hero. Each Sybil that eagerly participates in the bisection phase forces the hero to respond in kind. Playing the bisection phase to its completion, each eager Sybil forces both the adversary and the hero to include a number of transactions equal to the logarithm of the size of the computation. These transactions consume the budget of both adversary and hero.</p>\n<p>If the adversary has more blockspace access than the hero, then the adversary might be able to exhaust the hero’s blockspace access, depending on how many stakes the adversary is willing to burn. If the cost of stakes is irrelevant and the adversary has access to more blockspace than the hero, then a wrong claim will win.</p>\n<p>Increasing the stake to just match the cost of blockspace access gives the hero a two-fold advantage; the adversary has to pay one additional stake plus blockspace (the equivalent of two stakes), whereas the hero has to pay only one additional blockspace (the equivalent of one stake). Further increasing the stake-to-blockspace ratio increases the hero’s advantage, to the point where the advantage about equals this ratio.</p>\n<p>Increasing the stake as to dominate the cost of transaction fees does mitigate this attack. However, it’s harder for players to participate when stakes are higher, compromising the decentralization of the algorithm.</p>\n<p>It’s difficult to defend against this attack for several reasons. The adversary can use smart contracts to submit many claims and bisections at the same time, making their use of blockspace more efficient than the hero’s. Furthermore, depending on the magnitude of the whale, fees may skyrocket as blockspace becomes scarce, reducing the hero’s access to blockspace. Finally, if the adversary has the support of a block producer in the base layer, they can include transactions without having to pay (possibly skyrocketing) fees.</p>\n<h2><a name=\"variant-three-zerg-rush-the-heros-funds-11\" class=\"anchor\" href=\"https://ethresear.ch#variant-three-zerg-rush-the-heros-funds-11\"></a>Variant three: Zerg Rush the hero’s funds</h2>\n<p>If the stake is large, dominating both the cost of hardware and the cost of transaction fees, the adversary should use the third variant of <em>proof of whale</em>. The third variant hinges on the multi-level challenge setup that we described on previous sections. BoLD is set to use three levels of nested challenges.</p>\n<p>Reiterating, players need to post a stake at every challenge they wish to submit a claim, otherwise it would be cheap to generate Sybils. Every claim made at a non-leaf challenge may potentially spawn a sub-challenge. Take a two-stage setup: if the adversary launches a Sybil attack posting <code>N</code> claims at the first challenge, BoLD will have to spawn <code>N</code> second-level sub-challenges. This means the hero will have to submit <code>N</code> claims in the second level, one claim for each spawned sub-challenge. Posting <code>N</code> claims requires <code>N</code> stakes. Therefore, if the adversary has more stakes than the hero, then the adversary will win.</p>\n<hr>\n<p>Note that using the strategy described in the third variant also triggers the first and second variants. That is, <strong><em>proof of whale</em> forces the hero to have simultaneously more hardware <em>and</em> more blockspace <em>and</em> more stakes than the adversary has stakes.</strong> Otherwise, the hero will lose the dispute. This makes the system behave not unlike majority token voting, though possibly biased towards the hero depending on the setup. We’ll go into more details about the hero’s advantage in the next section.</p>\n<p><em>Proof of whale</em> is extremely hard to defend against because of the financial imbalance between hero and adversary. To make things worse, different attackers may trustlessly coordinate through smart contracts and pool their resources.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">BoLD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Safety</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/no_entry.png?v=12\" title=\":no_entry:\" class=\"emoji only-emoji\" alt=\":no_entry:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Promptness</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Decentralization</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n</tbody>\n</table>\n</div><h2><a name=\"the-heros-advantage-12\" class=\"anchor\" href=\"https://ethresear.ch#the-heros-advantage-12\"></a>The hero’s advantage</h2>\n<p>The <em>proof of whale</em> issue was touched on this <a href=\"https://research.arbitrum.io/t/bold-question-about-number-of-defender-s-stake/9445\" rel=\"noopener nofollow ugc\">post</a> at Arbitrum’s research forum. In it, Arbitrum researchers mention a behavior of the protocol not described in the preliminary paper: BoLD has sub-challenges requiring a “mini-stake” instead of a full stake. We take their comment to mean the hero still needs stakes linear on the number of Sybils, but the constant significantly favors the hero. This constant is defined by the ratio between the stakes of each challenge level.</p>\n<p>However, the protocol setup has three levels of challenge (according to the preliminary paper). If the mini-stakes of the two final levels are the same, then we’re back to the original attack, shifted down one level: the adversary joins the root challenge once – paying a single full stake – and then joins the second challenge in earnest – paying one mini-stake for each Sybil. The hero must match the number of mini-stakes on the third level.</p>\n<p>It seems the optimal strategy for BoLD is to chose the same ratio between levels one and two, and levels two and three. This ratio should be as high as possible to foil <em>proof of whale</em> variant three. Furthermore, the smallest stake should to be high enough to foil <em>proof of whale</em> variants one and two.</p>\n<p>Let’s try some numbers. Suppose we want the hero to have an ten-fold resource advantage over the adversary. As such, we should choose a ratio of <code>10</code> between the stakes of each level. Suppose <code>$1,000</code> is just enough to cover for hardware costs and block access fees for any challenge. To keep the ten-fold advantage, we should set the smaller stake to about <code>$1,000 * 10</code>, otherwise the <em>proof of whale</em> variants one and two give the adversary a better advantage than the target of ten. This means the stakes for the top challenge should be set to <code>($1,000 * 10) * 10 * 10</code>, which is <code>$1,000,000</code>. This makes the system quite centralized, since few would be able to participate.</p>\n<p>Nevertheless, BoLD is still unsafe. Large shared chains have several billion dollars in TVL; that’s what at stake here. If the adversary is willing to burn one billion dollars to win several billion, then the hero needs to have resources in the hundred millions (one tenth of one billion), sitting in the bank just to protect against whales. Ten is way too small of an advantage considering what’s at stake.</p>\n<p>However, if we increase the advantage, we significantly hurt decentralization. For example, if we set the advantage to one hundred (which may not even be safe enough), the first level stake becomes <code>($1,000 * 100) * 100 * 100</code>, which is <code>$1,000,000,000</code>. We believe there’s no choice of parameters that makes the system reasonable.</p>\n<h2><a name=\"an-improvement-on-bold-13\" class=\"anchor\" href=\"https://ethresear.ch#an-improvement-on-bold-13\"></a>An improvement on BoLD</h2>\n<p>We suggest an improvement on BoLD: leveraging ZK proofs at the state-transition function to eliminate the use of sub-challenges, in the same way PRT is moving towards. This eliminates <em>proof of whale</em> variant three. Nevertheless, ZK is a huge engineering effort that has trade-offs of its own that must be considered carefully. Let’s call this improvement BoLD++.</p>\n<p>BoLD++ settles in constant time like BoLD, so it has great promptness. Furthermore, the hero only ever needs one stake, addressing the third variant of the <em>proof of whale</em> attack.</p>\n<p>However, BoLD++ is still susceptible to variants one and two of the <em>proof of whale</em> attack. Setting the stake high makes this attack prohibitively expensive, but unfortunately it compromises decentralization. In this setup, BoLD++ is quite centralized but not fatally so.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">BoLD++</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Safety</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Promptness</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Decentralization</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n</tbody>\n</table>\n</div><h1><a name=\"op-stacks-fault-proof-system-opfp-14\" class=\"anchor\" href=\"https://ethresear.ch#op-stacks-fault-proof-system-opfp-14\"></a>OP Stack’s Fault Proof System (OPFP)</h1>\n<p>The Optimism specs can be found <a href=\"https://specs.optimism.io\" rel=\"noopener nofollow ugc\">here</a>. In particular, the fault proof system is described <a href=\"https://specs.optimism.io/experimental/fault-proof/stage-one/fault-dispute-game.html\" rel=\"noopener nofollow ugc\">here</a>. The implementation is <a href=\"https://github.com/ethereum-optimism/optimism\" rel=\"noopener nofollow ugc\">here</a>. It has just been deployed to testnet.</p>\n<p>In the traditional conception of fraud proofs, dishonest players can say the correct thing but lose on purpose. Both PRT and BoLD use computation hashes to address this. OPFP has a different approach. It allows claims to be bisected multiple times by anyone, introducing a directed acyclic graph (DAG) of claims in which anyone can add more vertices. Claims are added by bisecting an existing claim in the DAG.</p>\n<p>Disputes in OPFP are comprised of many games that anyone can create and play. All games are played simultaneously, which makes the dispute finish in constant time. Each game has its own DAG, starting with a root claim that asserts the result of the rollup. There are two main ways honest validators will play these games:</p>\n<ul>\n<li><strong>Protect the game with the correct root claim.</strong> There’s only one game with the correct root claim.</li>\n<li><strong>Expose all other games as faulty.</strong></li>\n</ul>\n<p>A game is played by countering claims. But since claims are countered mainly by adding child claims to the DAG, we’re entering the territory of countering counters all the way down to the one-step proof. Countering a counter uncounters the original claim. In the end, in order for a claim to be considered uncountered, all of its children must be countered. To consider a claim countered, it’s enough that a single one of its children is uncountered. The hero protects the correct game by countering the faulty claims that have countered the correct claims. The hero exposes faulty games by countering its root claims, and countering all the counters to their counters.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/d/d57ff7c4e33092f6f1019e4ac46c6ff36e583570.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/d57ff7c4e33092f6f1019e4ac46c6ff36e583570\" title=\"I bet the Optimism developers play mono blue in MtG\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/d/d57ff7c4e33092f6f1019e4ac46c6ff36e583570_2_500x350.jpeg\" alt=\"I bet the Optimism developers play mono blue in MtG\" data-base62-sha1=\"usHS0kVDSAYsYlZbtUTNCvEwDWE\" width=\"500\" height=\"350\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/d/d57ff7c4e33092f6f1019e4ac46c6ff36e583570_2_500x350.jpeg, https://ethresear.ch/uploads/default/optimized/2X/d/d57ff7c4e33092f6f1019e4ac46c6ff36e583570_2_750x525.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/d/d57ff7c4e33092f6f1019e4ac46c6ff36e583570_2_1000x700.jpeg 2x\" data-dominant-color=\"959C9C\"></a></div><p></p>\n<p>It’s clever, though a tad convoluted. We recommend reading OPFP’s specs, where this is explained in more details. A detail we should highlight is that posting a claim (through bisections or otherwise) requires posting a bond. This bond starts small, and grows exponentially as claims get closer to the leaf. The final value of this bond was set to cover the worst-case cost of a one-step proof.</p>\n<h2><a name=\"h-_proof-of-whale-2-electric-boogaloo_-15\" class=\"anchor\" href=\"https://ethresear.ch#h-_proof-of-whale-2-electric-boogaloo_-15\"></a><em>Proof of Whale 2: Electric Boogaloo</em></h2>\n<p>OPFP, however, suffers from a similar <em>proof of whale</em> attack as the original BoLD.</p>\n<p>The attack is straightforward. The adversary creates a script that bisects the correct claim in earnest. This can be improved by creating a smart contract that bisects many times, amortizing the base cost of an Ethereum transaction. This can be further improved by choosing the bisections in a way that the hero has to always compute a new state (in the worst case, the adversary can force the hero to post the entire computation on-chain). From time to time, the adversary also creates a new game by posting a faulty root claim. The hero has to counter all moves of either kind if they want to win.</p>\n<hr>\n<p>Since countering a claim requires compute, blockspace and bonds, <strong><em>proof of whale</em> forces the hero to have simultaneously more hardware <em>and</em> more blockspace <em>and</em> more bonds than the adversary has bonds.</strong> Otherwise, the hero will lose the dispute. This makes the system behave not unlike majority token voting.</p>\n<p>Unlike BoLD, we believe it’s not possible to tune the parameters to give an advantage to the hero. The hero has no relevant advantage over the adversary; if the adversary is somewhat better funded than the hero, the adversary will win. It’s reasonable to assume the attacker is significantly better funded than the hero given what’s at stake.</p>\n<p>Furthermore, we believe a winning adversary can recover both their bonds and the hero’s bonds, since the adversary’s claim will resolve correctly and the hero’s incorrectly. This makes a <em>proof of whale</em> even more profitable for the adversary.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">OPFP</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Safety</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/no_entry.png?v=12\" title=\":no_entry:\" class=\"emoji only-emoji\" alt=\":no_entry:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Promptness</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Decentralization</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n</tbody>\n</table>\n</div><h1><a name=\"conclusion-16\" class=\"anchor\" href=\"https://ethresear.ch#conclusion-16\"></a>Conclusion</h1>\n<p>Some algorithms perform better than others, but it’s clear we’re not in an ideal situation. Reiterating, the ecosystem’s standards need to become stricter. Here’s the tally:</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Algorithm</th>\n<th style=\"text-align:center\">Safety</th>\n<th style=\"text-align:center\">Promptness</th>\n<th style=\"text-align:center\">Decentralization</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">PRT</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">BoLD</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/no_entry.png?v=12\" title=\":no_entry:\" class=\"emoji only-emoji\" alt=\":no_entry:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">BoLD++</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">OPFP</td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/no_entry.png?v=12\" title=\":no_entry:\" class=\"emoji only-emoji\" alt=\":no_entry:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/white_check_mark.png?v=12\" title=\":white_check_mark:\" class=\"emoji only-emoji\" alt=\":white_check_mark:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n<td style=\"text-align:center\"><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/warning.png?v=12\" title=\":warning:\" class=\"emoji only-emoji\" alt=\":warning:\" loading=\"lazy\" width=\"20\" height=\"20\"></td>\n</tr>\n</tbody>\n</table>\n</div><p>This is a call for collaboration. As a community, we need to fix fraud proofs. Furthermore, our individual implementations will be beneficial to all of us in a multi-prover future.</p>\n<p>We have a couple of promising ideas that attempt to improve fraud proofs. We’ll publish them soon as a public good to the ecosystem, and we hope it can start a conversation.</p>\n<p>Let’s nurture the <em>Infinite Garden</em> together. It all starts with openness. The ecosystem can only benefit from collaboration.</p>\n<h1><a name=\"afterword-17\" class=\"anchor\" href=\"https://ethresear.ch#afterword-17\"></a>Afterword</h1>\n<p>I’ve been supported by a remarkable group of people in the creation of this article.<br>\nI extend my deepest gratitude to:</p>\n<ul>\n<li><a href=\"https://w3.impa.br/~augusto/\" rel=\"noopener nofollow ugc\">Augusto Teixeira</a> and <a href=\"https://w3.impa.br/~diego/\" rel=\"noopener nofollow ugc\">Diego Nehab</a>, for their crucial collaboration in writing the article.</li>\n<li><a href=\"https://twitter.com/PedroArgento8\" rel=\"noopener nofollow ugc\">Pedro Argento</a> and <a href=\"https://github.com/stephenctw\" rel=\"noopener nofollow ugc\">Stephen Chen</a>, my co-conspirators in developing the fraud proof system.</li>\n<li><a href=\"https://twitter.com/ERC_Brandon\" rel=\"noopener nofollow ugc\">Brandon Isaacson</a>, <a href=\"https://twitter.com/stskeeps\" rel=\"noopener nofollow ugc\">Carsten Munk</a>, <a href=\"https://twitter.com/felipeargento\" rel=\"noopener nofollow ugc\">Felipe Argento</a>, <a href=\"https://github.com/guidanoli\" rel=\"noopener nofollow ugc\">Guilherme Dantas</a> and <a href=\"https://github.com/miltonjonat\" rel=\"noopener nofollow ugc\">Milton Jonathan</a>, for their insightful feedback and thorough review.</li>\n<li><a href=\"https://twitter.com/donnoh_eth\" rel=\"noopener nofollow ugc\">Donnoh</a> and <a href=\"https://twitter.com/WillemOlding1\" rel=\"noopener nofollow ugc\">Willem Olding</a>, for their gracious involvement in reviewing our work.</li>\n</ul>\n<p>I also extend my gratitude to <a href=\"https://cartesi.io\" rel=\"noopener nofollow ugc\">Cartesi</a> for funding the research and for providing the environment where the development could take place. We invite the reader to join us on <a href=\"https://discord.gg/pfXMwXDDfW\" rel=\"noopener nofollow ugc\">our Discord</a>, where we continuously engage in public research and debate these topics constantly.</p>\n            <p><small>13 posts - 5 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/fraud-proofs-are-broken/19234\">Read full topic</a></p>","link":"https://ethresear.ch/t/fraud-proofs-are-broken/19234","pubDate":"Mon, 08 Apr 2024 14:21:29 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19234"},"source":{"@url":"https://ethresear.ch/t/fraud-proofs-are-broken/19234.rss","#text":"Fraud Proofs Are Broken"}},{"title":"Block-auction ePBS versus Execution Ticket","dc:creator":"terence","category":"Block proposer","description":"<h1><a name=\"block-auction-epbs-versus-execution-ticket-1\" class=\"anchor\" href=\"https://ethresear.ch#block-auction-epbs-versus-execution-ticket-1\"></a>Block-auction ePBS versus Execution Ticket</h1>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/92a53090dcf5ab40d39f98af4bb57e513407add8.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/92a53090dcf5ab40d39f98af4bb57e513407add8\" title=\"DALL·E 2024-04-07 15.26.59 - Design an image featuring the exact text &amp;#39;ePBS vs ET&amp;#39; in a clear, bold font against a deep space background. The background should showcase the beauty\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/92a53090dcf5ab40d39f98af4bb57e513407add8_2_500x500.jpeg\" alt=\"DALL·E 2024-04-07 15.26.59 - Design an image featuring the exact text 'ePBS vs ET' in a clear, bold font against a deep space background. The background should showcase the beauty\" data-base62-sha1=\"kVhCW3S3uXC6W90Tw4R2FvGKcxq\" width=\"500\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/92a53090dcf5ab40d39f98af4bb57e513407add8_2_500x500.jpeg, https://ethresear.ch/uploads/default/optimized/2X/9/92a53090dcf5ab40d39f98af4bb57e513407add8_2_750x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/92a53090dcf5ab40d39f98af4bb57e513407add8_2_1000x1000.jpeg 2x\" data-dominant-color=\"394454\"></a></div><p></p>\n<p>This writeup compares ePBS and ET in their current sppec forms. It outlines their similarities and differences, including a table below for reference. First and foremost, it presents some disclaimers, related work, and relevant acronyms.</p>\n<h3><a name=\"disclaimers-2\" class=\"anchor\" href=\"https://ethresear.ch#disclaimers-2\"></a>Disclaimers</h3>\n<ul>\n<li>Enshrined proposer builder  (ePBS) referenced below primarily refers to block auction ePBS. There are various forms of PBS that people will discuss, such as slot auction PBS and others. The comparison below focuses mainly on block auction ePBS versus ET.</li>\n<li>Execution tickets (ET) referenced below are from the post in related work. It’s important to remember this was the first post on execution ticket design. The design is volatile, and nothing is final, including ePBS. It is highly subject to change in the coming months.</li>\n<li>The views expressed in this post are my personal views and do not reflect those of my team or company.</li>\n</ul>\n<h4><a name=\"related-work-3\" class=\"anchor\" href=\"https://ethresear.ch#related-work-3\"></a>Related work</h4>\n<p><a href=\"https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054\">Payload-timeliness committee (PTC) – an ePBS design</a> By Mike - July, 2023<br>\n<a href=\"https://ethresear.ch/t/execution-tickets/17944\">Execution Tickets</a> By Mike and Justin - Dec, 2023<br>\n<a href=\"https://ethresear.ch/t/minimal-epbs-beacon-chain-changes/18653\">Minimal ePBS Beacon Chain Changes</a> By Terence - Feb, 2024<br>\n<a href=\"https://ethresear.ch/t/epbs-design-constraints/18728/1\">ePBS Design Constraints</a> By Potuz - Feb, 2024<br>\n<a href=\"https://ethresear.ch/t/payload-boosts-in-epbs/18769\">Payload Boost</a> By Potuz - Feb, 2024<br>\n<a href=\"https://github.com/potuz/consensus-specs/pull/2/files\" rel=\"noopener nofollow ugc\">ePBS Consensus Spec</a> By Potuz (still work in progress)</p>\n<h4><a name=\"acronyms-abbreviations-4\" class=\"anchor\" href=\"https://ethresear.ch#acronyms-abbreviations-4\"></a>Acronyms &amp; abbreviations</h4>\n<p>ePBS - enshrined proposer builder separation<br>\nET - execution ticket<br>\nPTC - payload timeliness committee</p>\n<h4><a name=\"thanks-5\" class=\"anchor\" href=\"https://ethresear.ch#thanks-5\"></a>Thanks</h4>\n<p>Many thanks to <a href=\"https://twitter.com/barnabemonnot\" rel=\"noopener nofollow ugc\">Barnabé</a>, <a href=\"https://twitter.com/mikeneuder\" rel=\"noopener nofollow ugc\">Mike</a>, and <a href=\"https://twitter.com/potuz_eth\" rel=\"noopener nofollow ugc\">Potuz</a> for the comments on the draft.</p>\n<h2><a name=\"epbs-vs-et-similarities-6\" class=\"anchor\" href=\"https://ethresear.ch#epbs-vs-et-similarities-6\"></a>ePBS Vs ET Similarities</h2>\n<p>Both designs directly address our main issue: the relayer as a choking point. Today, a trustless path exists to allocate the execution proposing rights to yourself, that’s local building. ePBS creates a trustless path for the beacon proposer to allocate execution proposing rights to <em>someone else</em>. ET achieves this by excluding the execution proposer role from the consensus validator set. Critics often raise concerns about relayer bypassability in the ePBS design, but this point is usually countered by explaining that ePBS is not about removing the relayer. Instead, it’s about enabling validators and builders to enter into a trust-minimized agreement with one another without the presence of a trusted relay mediating the agreement. Builders can assume the relayer role and open an RPC port if needed.</p>\n<p>Both designs decouple the delivery of the consensus block from the execution block, ensuring the inclusion of the consensus block even if the execution block is missing or invalid. In ePBS, the proposer receives an unconditional payment. In ET, the protocol gets the payment through ticket burning, or MEV burn.</p>\n<p>Both designs enable the resale of block space. In the case of MEV-Boost today and the current ePBS design, the beacon proposer puts block space up for auction, and the highest bidder among builders wins. Once the bid and transaction root are committed, the block space is locked in, meaning the beacon proposer can sell it only once. In contrast, the slot-auction variant of ePBS only requires the beacon proposer to commit to the bid’s value and the execution proposer’s ID, offering the execution proposer the chance to resell the block space. When it comes to ET, the reselling rules are protocol-dependent: if the protocol allows for the reselling of the ticket, then the ticket holder gains the right to resell the block space. Otherwise, the ticket holder can only sell the building rights of a block to another party while still retaining the role of the original proposer.</p>\n<h2><a name=\"epbs-vs-et-differences-7\" class=\"anchor\" href=\"https://ethresear.ch#epbs-vs-et-differences-7\"></a>ePBS Vs ET Differences</h2>\n<p><a href=\"https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612\">Timing game attack</a> occurs when a block proposer delays their proposal until the last second to extract more mev. In ePBS, the dynamics of the timing game remain unchanged, with consensus block proposers still incentivized to propose blocks close to the 4s mark.  In ET, consensus blocks no longer commit to execution blocks, removing the incentive for consensus validators to engage in the timing game. Execution proposers, however, are still incentivized to play the timing game, which raises questions of fairness, but this is no longer an issue for consensus.</p>\n<p>One of the differences is the timing of the execution block deadline. Currently, the deadline is when the proposer retrieves the header from the relayer, which is the start of the slot. In ePBS, the deadline remains the same. The slot starts when the execution block is committed in the consensus block. After that point, execution can no longer be changed. In ET, because the execution block does not commit to the consensus block, the execution deadline is pushed back to the second half of the slot. This could represent a significant mental shift for applications or MEV-related systems. Both designs present challenges in maintaining slot durations under 12s. In ePBS, the 12s duration is upheld by maintaining a small payload timeliness committee without additional rounds of aggregation. In ET, the current size of the execution committee is unknown.</p>\n<p>Both designs feature an inclusion list. In ePBS, the inclusion list for slot n is applied to slot n+1, even though the transactions may be available for slot n. In contrast, in ET, since the consensus block does not commit the execution block, the inclusion list for slot n can be directly applied to the execution block at slot n. This design is more advantageous, as there are fewer duplicated transactions over gossip between the inclusion list and the execution block of the same slot.</p>\n<p>Consensus blocks that do not commit to execution present specific trade-offs, with the primary concern being the potential for execution block equivocation. In ePBS, importing more than one execution block over p2p networks is only possible if multiple consensus blocks are processed. In this model, only the consensus block is subject to slashing. In ET, it is possible to import more than one execution block over p2p. Each is subject to its slashing rules, increasing the complexity of specs and implementation.</p>\n<p>Another trade-off involves the circuit breaker mechanism. Currently, to short-circuit a relayer for producing an invalid block, this mechanism involves an out-of-band design because the relayer’s identity is unknown on-chain, and the relayer’s address is not part of the consensus block. In contrast, ePBS records the builder’s address on the chain, and the builder’s public key and signature are included in the block, making it straightforward to bypass or short-circuit a builder if they fail to produce a block or produce an invalid one. The consistent production of execution blocks is less challenging in ePBS. In ET, the execution block proposal operates within its domain, complicating the implementation of a circuit-breaker-like system.</p>\n<h2><a name=\"open-questions-8\" class=\"anchor\" href=\"https://ethresear.ch#open-questions-8\"></a>Open Questions</h2>\n<p>ePBS contains open questions, such as how to address the issue of proposer split view. The current approach is to implement <a href=\"https://ethresear.ch/t/payload-boosts-in-epbs/18769\">payload boosts</a>, enabling the builder to inform PTC of its intention to withhold the execution block to reorg the current slot consensus block.</p>\n<p>ET contains open questions regarding economics, the scheme for selling and reselling tickets, and the slashing of execution blocks. The absence of slashing raises questions about its compatibility with Casper FFG’s principle of accountable safety and whether it’s just an LMD GHOST fault.</p>\n<p>The community’s decision is not between ePBS and ET but whether to pause until a satisfactory solution emerges or proceed with ePBS. Meanwhile, we are assessing whether ePBS is a stepping stone towards ET and whether they belong to the same skill trees. The subsequent table helps to clarify the overall picture.</p>\n<h2><a name=\"comparison-and-contrast-table-9\" class=\"anchor\" href=\"https://ethresear.ch#comparison-and-contrast-table-9\"></a>Comparison and Contrast Table</h2>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>ePBS</th>\n<th>ET</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Reduce trust between validator and builder</td>\n<td>ePBS integrates mev-boost directly into the protocol, allowing beacon proposers to securely obtain bids from builders without the need for trust of an intermediate party. Builders may incorporate the relayer role by opening up its RPC port.</td>\n<td>ET achieves this by completely isolating the role of the execution proposer from validators. Validators do not need to propose an execution block at all.</td>\n</tr>\n<tr>\n<td>Unconditional payment</td>\n<td>In ePBS, if a consensus block stays canonical but the execution block is invalid or not revealed, the beacon proposer still receives payment as part of the protocol if and only if the consensus bid captures the full payment.</td>\n<td>In ET, proposing execution blocks is external to the beacon proposer’s responsibilities, which becomes irrelevant in this context.</td>\n</tr>\n<tr>\n<td>Circuit breaker</td>\n<td>In ePBS, if a builder is at fault, this can be observed on the chain. The beacon proposer for the next slot will bypass any submissions from the faulty builder’s address after a subjective timeout period.</td>\n<td>In ET, there is no circuit breaker mechanism. The beacon proposer does not select the execution builder.</td>\n</tr>\n<tr>\n<td>Timing game</td>\n<td>In ePBS, a proposer might delay getting the header until the last moment to capture more MEV. This approach can distort consensus and raise questions about fairness for the next slot’s proposer.</td>\n<td>In ET, an execution proposer might delay broadcasting the execution block until the last possible moment to capture MEV. While this does not distort the consensus process, it still raises questions about fairness for the proposer of the next slot.</td>\n</tr>\n<tr>\n<td>Inclusion list</td>\n<td>In ePBS, an IL for slot n is enforced for slot n+1. Transactions from slot n may already be part of the IL for n+1, which is acceptable. Only a summary is committed on chain.</td>\n<td>In ET, an IL for slot n could be applied to slot n itself, as the consensus block does not specify the contents of the execution block, only the builder’s identity.</td>\n</tr>\n<tr>\n<td>Mev burn</td>\n<td>In ePBS, implementing MEV burn is difficult due to the complexity of ensuring bid credibility. The protocol cannot prevent collusion between proposers and builders nor guarantee that builders will accurately report the value to be burned.</td>\n<td>In ET, the ticket itself is burned. Not burning full amounts could lead to profitable off-chain agreements between parties. Partial auction is hard to do here.</td>\n</tr>\n<tr>\n<td>Empty slot</td>\n<td>In ePBS, if a consensus block is skipped, no execution block can be produced. However, if the consensus block exists but the execution block is skipped, the slot will contain only consensus information. Empty slot can be made to apply a penalty on the proposer.</td>\n<td>The current thinking is the same as ePBS, but it may not be. Assuming SSF and a clean consensus/execution separation, it may be possible to have an execution block if the consensus block is missing.</td>\n</tr>\n<tr>\n<td>Slot time</td>\n<td>In ePBS, upholding a 12s slot time is highly required.</td>\n<td>We need concrete evidence to explain why it cannot be identical to ePBS.</td>\n</tr>\n<tr>\n<td>Fork choice rule</td>\n<td>(Block, slot) fork choice rule is implemented to enable attesters to vote against late block.</td>\n<td>Single slot finality is likely required.</td>\n</tr>\n<tr>\n<td>Execution block equivocation</td>\n<td>In ePBS, execution block equivocation is prevented because the consensus block commits to one execution block. Any execution block that is not committed is ignored from every node’s perspective.</td>\n<td>In ET, execution block/ticket equivocation is possible. It may require some form of slashing scheme. As with all slashing designs and implementations, this introduces an element of unknown complexity. The question is whether ticket equivocation is the same as execution block equivocation under ePBS’s slot auction scheme.</td>\n</tr>\n<tr>\n<td>Bid delivery</td>\n<td>In ePBS, if the timing game matters, the bid exchange will happen using RPC over P2P. RPC is faster, and P2P is just the default fallback for liveness.</td>\n<td>In ET, the timing game does not involve consensus. Bids can be exchanged directly over P2P. This means builders don’t need to open their RPC ports to the beacon proposer, reducing one less concern.</td>\n</tr>\n<tr>\n<td>Multi slots attack</td>\n<td>In ePBS, acquiring multiple slot proposals is more challenging due to the validator requirements, where each validator has a minimum bound. This is where shuffling becomes relevant.</td>\n<td>In ET, the number of ticket participants is unclear, making it increasingly relevant that a single party might propose multiple slots in succession. Multi-slot MEV extraction or types of attacks could become a more significant issue.</td>\n</tr>\n<tr>\n<td>Reselling</td>\n<td>In ePBS, the proposer requests and receives the header from the builder JIT. The proposer then reallocates this opportunity to the builder. Builders have the option to collaborate with searchers or work alongside other builders.</td>\n<td>In ET, the winning round’s execution proposer can resell its block space to other entities.</td>\n</tr>\n<tr>\n<td>Economics</td>\n<td>In ePBS, the builder pays the proposer for the bid.</td>\n<td>In ET, the protocol issues the ticket, and the execution proposer pays the proposal cost. The protocol sets the ticket price according to a supply and demand curve.</td>\n</tr>\n<tr>\n<td>Hard fork complexity</td>\n<td>In ePBS, transitioning to the ePBS regime through a hard fork based on a specific timestamp is relatively straightforward.</td>\n<td>In ET, implementing a hard fork necessitates some degree of forward planning regarding proposer execution. There may be ways to start the ticket system without two forks, for example, by conducting a one-off sale or employing a 1559 AMM style market. However, it is too early to make definitive statements at this stage.</td>\n</tr>\n<tr>\n<td>Attesting for execution reveal and validity</td>\n<td>In ePBS, a PTC committee is utilized to attest for the execution reveal on time and ensure its validity. The committee size is determined to be appropriate where aggregation of attestations is not required. Consensus block of the next slot includes PTC attestations.</td>\n<td>In ET, a PTC committee could be employed to verify execution validity. The specifics of how this operates will become clear once the specs are released.</td>\n</tr>\n<tr>\n<td>Open questions</td>\n<td>In ePBS, a significant design challenge involves proposers splitting attester views, which forces builders to decide whether to reveal their execution block. Payload boost represents a promising effort to address this issue.</td>\n<td>In ET, the main challenges include addressing execution block equivocation, developing a viable hard-forking strategy for transitioning to the ET framework, ensuring all processes adhere to the 12s timeframe, and detailing the protocol’s ticket issuance mechanism.</td>\n</tr>\n</tbody>\n</table>\n</div>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232\">Read full topic</a></p>","link":"https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232","pubDate":"Mon, 08 Apr 2024 13:45:05 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19232"},"source":{"@url":"https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232.rss","#text":"Block-auction ePBS versus Execution Ticket"}},{"title":"Charity Bond Account Generation for Social Networks and More","dc:creator":"MicahZoltu","category":"Economics","description":"<p>Also blogged here: <a href=\"https://listed.to/authors/33689/posts/50805\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Charity Bond Account Generation for Social Networks and More | Micah Zoltu</a><br>\nMusical rendition of this concept also available: <a href=\"https://bafybeibbfboye32palpogfpfqj7fzdiy7zqk4oq3aywf2qyis2by4ri3yq.ipfs.zoltu.io\" rel=\"noopener nofollow ugc\">Charity Bond Account Creation - Boy Band.mp3</a></p>\n<h2><a name=\"abstract-1\" class=\"anchor\" href=\"https://ethresear.ch#abstract-1\"></a>Abstract</h2>\n<p>A system for limiting account generation and stopping spam in systems with a moderation system in place.</p>\n<h2><a name=\"motivation-2\" class=\"anchor\" href=\"https://ethresear.ch#motivation-2\"></a>Motivation</h2>\n<p>Most successful online social networks have a problem with spammers.  Spammers are able to create many accounts and then spam with them.  These accounts inevitably get banned, but often not before the damage is done.  Online social networks want to make account generation free, because network effects dominate their success which means they can’t just charge people to create an account.</p>\n<h2><a name=\"solution-3\" class=\"anchor\" href=\"https://ethresear.ch#solution-3\"></a>Solution</h2>\n<ol>\n<li><strong>Provider creates a list of charities:</strong>  The provider creates a list of charities that they consider legitimate.  This list should be as comprehensive as possible and is not meant to reflect the values of the provider, but rather provide a list of “probably not scam” charities.  All of the charities should be able to accept donations in the form of a crypto-currency that is available on a blockchain that supports contracts.</li>\n<li><strong>User selects a charity:</strong>  When a user begins the account creation process, they choose one of the charities that the provider has included in its list.  The user should choose a charity they feel is legitimate, and one that they wouldn’t mind donating to.</li>\n<li><strong>User pays a bond:</strong>  After selecting a charity, the user places a bond that is of meaningful size.  This doesn’t need to be prohibitive, but it does need to be significant.  $5 (at today’s value) is perhaps a proper order of magnitude.</li>\n<li><strong>User’s bond is put into a contract that either returns to user or pays the charity:</strong>  The users bond does <em>not</em> go to the provider.  It is put into a contract where the provider can only do one of two things with it: (A) Return it to the user or (B) forward it to the charity selected by the user.  The contract associates the bond with the user account identifier on the provider’s platform.</li>\n<li><strong>If the user closes their account voluntarily, they get the bond back:</strong>  When a user terminates their account with the provider, their bond is returned to them after a reasonable timeout (days).</li>\n<li><strong>If the user’s account is closed by the provider for spamming, the bond goes to the charity:</strong>  If a user is caught spamming, their account is closed but they do not get their bond back.  Instead, the bond is forwarded to the charity the user selected.</li>\n</ol>\n<h2><a name=\"rationale-4\" class=\"anchor\" href=\"https://ethresear.ch#rationale-4\"></a>Rationale</h2>\n<ul>\n<li>The bond ensures that spammers will have to pay a significant fee for each spam account they create.</li>\n<li>The bond is given to a charity rather than the provider when the user spams to ensure there is no direct financial incentive for the provider to close accounts as a source of revenue.</li>\n<li>The bond is given back to the user rather than the charity on voluntary account closure to maintain a “0 cost” (exception: time value of money) account creation process.</li>\n<li>The charity list is created by the provider to ensure that users cannot designate a scam charity that just gives them their money back.</li>\n<li>The specific charity is selected by the user to ensure that if the account is closed inappropriately or the provider is otherwise malicious, there is a silver lining for the user in that a charity they like received a small donation.</li>\n<li>There is a timeout after account closure before refunding the user to prevent users from spamming and then immediately closing their account before getting caught.</li>\n</ul>\n<h2><a name=\"remarks-5\" class=\"anchor\" href=\"https://ethresear.ch#remarks-5\"></a>Remarks</h2>\n<p>This mechanism can be used for any system that is susceptible to spam and has an existing system in place for closing spammer accounts.  Social networks are the obvious top choice, but one could also imagine something akin to CloudFlare’s captcha-replacement token, where users can pay a bond to acquire a token and if their token is used as part of a spam attack, their bond goes to charity.</p>\n<p>This system also is remarkably resilient to some degree of false positives.  With a sufficiently large charity list, even when a user gets caught up in a mass ban, they may not feel that bad since their bond just went to a charity of their choice anyway.  This is in stark contrast to when traditionally paid user accounts get caught in a mass ban because the people doing the banning were financially rewarded for getting it wrong, which feels very bad for the user.  A user whose bond went to charity may simply shrug and create another account, writing off the bond loss as a charitable donation that they would/should have done anyway.</p>\n            <p><small>2 posts - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/charity-bond-account-generation-for-social-networks-and-more/19220\">Read full topic</a></p>","link":"https://ethresear.ch/t/charity-bond-account-generation-for-social-networks-and-more/19220","pubDate":"Sun, 07 Apr 2024 05:26:57 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19220"},"source":{"@url":"https://ethresear.ch/t/charity-bond-account-generation-for-social-networks-and-more/19220.rss","#text":"Charity Bond Account Generation for Social Networks and More"}},{"title":"Replacing registration systems and captchas with VDFs to improve usability","dc:creator":"Uptrenda","category":"Layer 2","description":"<p>I’ve been thinking blockchains and the general web suffer from similar problems: they both try to make the creation of false identities difficult. Blockchains use computational and/or economic costs. Whereas, websites opt towards using visual challenges (captchas) to filter out bots. The problem with using captchas is the heavy degradation of usability. Services like ‘cloudflare’ now serve to guard websites from bots and force annoying puzzles on everyone. If there were a way to solve this problem without using captchas it would be extremely beneficial for users of the web.</p>\n<p>If we look at ‘hashcash’ it was originally designed as a computational stamp for sending emails. Its aim was to prevent spam in emails which is very similar to the aim of captcha. But using hashcash in this way would make it easy to parallelize. Attackers with botnets would still have the upper hand. There are some small changes that might make the idea workable though. Let’s throw out the idea of having individual proofs for actions and move towards a single, long-running verifiable delay function.</p>\n<p>account = VDF(…)</p>\n<p><strong>The aim of the algorithm will be to replace the need for manual account registration, especially the need to fill out captcha prompts by utilizing long-running VDFs that serve as a computational cost for reserving resources on other systems.</strong> A registration server will distribute a random IV to the user to run the VDF on. The user will give their intended run_time_speed for the VDF to the server which is accepted as long as it’s fast enough for modern hardware.</p>\n<p>account = VDF(server_iv, run_time_speed)</p>\n<p>Initial resources (say for that day) can be assigned to the user after a set period. In order for this to happen the user breaks up their VDF into checkpoints that the server can verify in parallel. E.g. see the construct of Gwern’s serial hashing for time-lock encryption. If the checkpoints are correct then the user must have kept running the VDF and they’re given their first resource allocation.</p>\n<p>resources = elapsed_time * run_time_speed * account_limit</p>\n<p>Since this scheme requires ‘bootstrapping’ to wait for an initial allocation of resources. It could be side-stepped by requiring a larger initial commitment of resources. Such as in a Storj-style file allocation where proofs would be made against files on disk. These files could then be reduced overtime as incurred computational cost offsets disk space resources.</p>\n<p>One useful consequence of using VDFs for accounts is complex, registration flows are no longer required. A service could manually check if the user has enough resources. Or they could outsource it to a specialized service who sends back signed vouches. If the user’s machine is offline they don’t automatically accrue more resources to spend on other systems. Their allocations are only refreshed while they’re active with their machines.</p>\n<p>Another problem that these account-based VDFs solves is it makes it easier to block abusive users. Traditional registration systems are often plagued by never-ending attacks because attackers have access to large pools of IPs. Simple ban-by-IP approaches don’t work here with VPNs leading to less privacy on the web. With account-based VDFs it would be harder to create sock puppets. One ban would invalidate an entire sequential VDF and VPNs could still be used. You could even require VDFs that were a certain maturity before they attained full permissions.</p>\n<p><strong>The main requirements for the VDF to be useful:</strong></p>\n<ol>\n<li>It should not be possible to paralyze it</li>\n<li>It should not degrade the performance of the machine it runs on</li>\n<li>One machine should ideally only be able to run one VDF</li>\n</ol>\n<p>Requirements (1) and (2) can be satisfied by using sequential, memory-based hashing. The difficulty for which should be chosen with respect to the ‘average consumer hardware’ at the time. Even though in reality it may be possible to run multiple VDFs on a single machine. The parameters should be chosen so that doing so would significantly degrade performance. At least so far as there’s a cost that regular users would not enjoy (this would also enable people infected with bots to detect infections since their machines would get marginally slower.)</p>\n<p>Requirement (3) is something that would be ‘nice to have’ but I suspect impossible to design algorithmically. If an attacker has access to hardware that could run many VDFs (it might have many cores or lots of memory), then they would be in a better position to launch attacks. I think that this might be an area where trusted computing may be useful. As an example – an Intel CPU could use trusted computing to vouch for its serial number and model ID. The registration server could then use this information to help reduce impersonation.</p>\n<p>These are my thoughts for now. Let me know what you think.</p>\n            <p><small>5 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/replacing-registration-systems-and-captchas-with-vdfs-to-improve-usability/19217\">Read full topic</a></p>","link":"https://ethresear.ch/t/replacing-registration-systems-and-captchas-with-vdfs-to-improve-usability/19217","pubDate":"Sat, 06 Apr 2024 04:49:08 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19217"},"source":{"@url":"https://ethresear.ch/t/replacing-registration-systems-and-captchas-with-vdfs-to-improve-usability/19217.rss","#text":"Replacing registration systems and captchas with VDFs to improve usability"}},{"title":"Towards an implementation of based preconfirmations leveraging restaking","dc:creator":"cairo","category":"Applications","description":"<p><img src=\"https://ethresear.ch/images/emoji/facebook_messenger/open_book.png?v=12\" title=\":open_book:\" class=\"emoji\" alt=\":open_book:\" loading=\"lazy\" width=\"20\" height=\"20\"> <strong>TL;DR:</strong> We introduce an exploratory implementation of a based preconfirmations protocol for sub-second transaction confirmations on Ethereum, inspired on <a href=\"https://ethresear.ch/t/based-preconfirmations/17353\">Justin Drake’s proposal</a>.</p>\n<blockquote>\n<p>Thanks to <a class=\"mention\" href=\"https://ethresear.ch/u/diego\">@diego</a>, <a href=\"https://twitter.com/W_Y_X\" rel=\"noopener nofollow ugc\">William X</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/ballsyalchemist\">@ballsyalchemist</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/ed\">@ed</a>, <a href=\"https://twitter.com/tjbecker_x\" rel=\"noopener nofollow ugc\">Tim Becker</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/justindrake\">@justindrake</a>, <a href=\"https://twitter.com/cooper_kunz\" rel=\"noopener nofollow ugc\">Cooper Kunz</a>, and others for the feedback and discussions.</p>\n</blockquote>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/e/e720183c77fcce7e0cfe98a3ca7f78c4a648666e.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/e720183c77fcce7e0cfe98a3ca7f78c4a648666e\" title=\"preconfirmations\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/e/e720183c77fcce7e0cfe98a3ca7f78c4a648666e_2_500x500.jpeg\" alt=\"preconfirmations\" data-base62-sha1=\"wYD3BGYCdg64XMMDTlqUS7gBwqG\" width=\"500\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/e/e720183c77fcce7e0cfe98a3ca7f78c4a648666e_2_500x500.jpeg, https://ethresear.ch/uploads/default/optimized/2X/e/e720183c77fcce7e0cfe98a3ca7f78c4a648666e_2_750x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/e/e720183c77fcce7e0cfe98a3ca7f78c4a648666e_2_1000x1000.jpeg 2x\" data-dominant-color=\"A47F4F\"></a></div><p></p>\n<h1><a name=\"background-1\" class=\"anchor\" href=\"https://ethresear.ch#background-1\"></a>Background</h1>\n<p>Ethereum preconfirmations, or “preconfs” for short, are a proposed mechanism to enable faster transaction confirmation and improve the user experience on Ethereum, and subsequently, on layer 2 rollups and validiums. The key idea is to have Ethereum block proposers issue signed promises to users guaranteeing that their transactions will be included in a certain block. Users pay a tip to block proposers for this service. By acquiring preconfirmation promises from upcoming block proposers, users can get assurance of speedy inclusion, with latencies as low as 100ms. Preconfirmations can be applied for a broad list of use cases, like timely blob transactions for L2s with regular cadence, markets of future block space, and expressivity for inclusion constraints.</p>\n<h1><a name=\"implementation-2\" class=\"anchor\" href=\"https://ethresear.ch#implementation-2\"></a>Implementation</h1>\n<blockquote>\n<p>Check out the implementation on <a href=\"https://github.com/cairoeth/preconfirmations\" rel=\"noopener nofollow ugc\">GitHub</a></p>\n</blockquote>\n<p>This implementation of preconfirmations leverages EigenLayer’s AVS (Actively Validated Services) system to power the slashing mechanism, ensuring the security of preconfirmation guarantees. Ethereum validators who wish to participate in the preconfirmation service must opt-in via EigenLayer and run the AVS software, known as <code>preconf-operator</code>, which enables them to receive and confirm requests with preconfirmation promises for blocks that they will propose. In the event that a preconfirmation is violated (safety fault) or not included in the established block (liveness fault), a fault proof can be posted to the service smart contracts, resulting in the retroactive slashing of the validator’s stake.</p>\n<p>To simplify the user experience, we introduce <code>preconf-share</code>, a fork of MEV-Share that serves as a trusted matchmaker between users and block proposers. Users submit preconfirmation requests along with hints to the <code>preconf-share</code> node, which then gossips the requests to validators that are the next block proposers. Based on the request hints and the associated tip, block proposers decide whether to promise a preconfirmation. The <code>preconf-share</code> node receives and ranks the preconfirmation promises according to the user’s preferences, such as the desired and maximum block. Once a preconfirmation promise is selected, the block proposer receives the raw transaction that should be included in the promised block. The user receives a receipt of the preconfirmation, and the signed promise of the block proposer is made public, allowing it to be used as evidence if the promise is violated (alongside the proof).</p>\n<p>To further enhance the user experience and enable the use of preconfirmations in wallets without requiring changes, we introduce a trusted JSON-RPC wrapper for <code>preconf-share</code>. This wrapper is forked from <a href=\"https://github.com/flashbots/rpc-endpoint\" rel=\"noopener nofollow ugc\">Flashbot’s RPC endpoint</a> and allows users to define their default preconfirmation preferences and hint criteria.</p>\n<h2><a name=\"preconf-operator-3\" class=\"anchor\" href=\"https://ethresear.ch#preconf-operator-3\"></a>Preconf-Operator</h2>\n<p>Validators who wish to receive and promise preconfirmations must register in the EigenLayer service and run the <code>preconf-operator</code> AVS client. Upon initialization, this client registers the given validator to the service smart contract and begins listening to the event stream of the <code>preconf-share</code> node, which is run by a trusted third-party. When a preconfirmation request is received, the client evaluates its available parameters to determine whether to send a promise. For example, block proposers may be more receptive to requests that include logs or calldata information, even if they have lower tips, as it opens the door for value extraction or OFAC limitations. Conversely, requests with little information can be accompanied by a high tip to balance the lack of information and have a higher inclusion rate. Block proposers must also consider other preconfirmations they have made for future blocks to make sure that new preconfirmations don’t collide with transactions obtained from the global public mempool.</p>\n<p>If a block proposer sends a preconfirmation promise back to the <code>preconf-share</code> node, the <code>preconf-operator</code> client will wait for the defined window time in case they provided the best promise and consequently receive the complete preconfirmation information, including the raw transaction, to fulfill the promise. If a promise was made for a specific future block, the <code>preconf-operator</code> client will hold the transactions until its turn to propose that block. It is important to note that although the <code>preconf-share</code> node enforces a series of checks on both user requests and preconfirmation promises, block proposers can still be slashed if they provide an out-of-protocol promise for a block that they are not building/proposing (or if they delegated the work to another party that didn’t fulfill it).</p>\n<h3><a name=\"request-event-scheme-4\" class=\"anchor\" href=\"https://ethresear.ch#request-event-scheme-4\"></a><strong>Request Event Scheme</strong></h3>\n<pre><code class=\"lang-tsx\">{\n    hash: string,\n    inclusion: RequestInclusion,\n    logs?: LogParams[],\n    txs: Array&lt;{\n        to?: string,\n        functionSelector?: string,\n        callData?: string,\n    }&gt;,\n}\n</code></pre>\n<ul>\n<li><code>hash</code> : Hex-string of the transaction or request hash.</li>\n<li><code>inclusion</code>: Inclusion parameters, containing block target, max block, and tip.</li>\n<li><code>logs</code>: Array of JSON-encoded event logs emitted by executing the transaction using the last state.</li>\n<li><code>txs</code>: Transactions in the request, for each one:\n<ul>\n<li><code>to</code>: Transaction recipient address</li>\n<li><code>functionSelector</code>: 4-byte function selector.</li>\n<li><code>callData</code>: Calldata of the transaction.</li>\n</ul>\n</li>\n</ul>\n<h3><a name=\"promise-callback-scheme-5\" class=\"anchor\" href=\"https://ethresear.ch#promise-callback-scheme-5\"></a><strong>Promise Callback Scheme</strong></h3>\n<pre><code class=\"lang-tsx\">{\n    hash: string,\n    txs: Array&lt;{\n        tx: string,\n    }&gt;,\n}\n</code></pre>\n<ul>\n<li><code>hash</code> : Hex-string of the transaction or request hash.</li>\n<li><code>inclusion</code>: Inclusion parameters, containing block target, max block, and tip.</li>\n<li><code>logs</code>: Array of JSON-encoded event logs emitted by executing the transaction using the last state.</li>\n<li><code>txs</code>: Transactions in the request, for each one:\n<ul>\n<li><code>tx</code> : The raw transaction bytes.</li>\n</ul>\n</li>\n</ul>\n<h3><a name=\"proofs-slashing-6\" class=\"anchor\" href=\"https://ethresear.ch#proofs-slashing-6\"></a>Proofs &amp; Slashing</h3>\n<p>The <code>preconf-share</code> node publishes signed preconfirmation promises, enabling anyone to raise a dispute by posting a bond as soon as the target block has passed. The slashing smart contract verifies the authenticity of the preconfirmation promise by checking if it was correctly signed by a valid block proposer. If the signature is valid, the contract opens a challenge window, during which the block proposer has the opportunity to win the dispute by submitting a transaction inclusion proof.</p>\n<p>The proof is constructed off-chain by the block proposer and passed to the slashing smart contract, which then submits it to <a href=\"https://explorer.relicprotocol.com/mainnet/prover/0xf22Be64911Db8E84925c8f03C73Bb21ddD33B442\" rel=\"noopener nofollow ugc\">Relic Protocol’s Transaction Prover</a>. The prover verifies whether the given transaction hash was indeed included in the specified block. If the block proposer successfully proves the transaction’s inclusion, the disputer loses their bond, which is then transferred to the block proposer as a reward for their honesty.</p>\n<p>However, if the block prposer fails to respond within the designated challenge window, the disputer automatically wins the challenge. In this case, the block proposer is considered to have broken their promise and is subsequently slashed, with a portion of their stake potentially being redistributed as a reward to the disputer.</p>\n<p>Looking ahead, <a href=\"https://twitter.com/tjbecker_x\" rel=\"noopener nofollow ugc\">Tim</a> proposed the possibility of adding a a non-existence prover to streamline the dispute process. This approach would trade off the current design’s round of interactivity and communication for a higher cost. By utilizing a non-existence prover, the disputer could directly prove that a block proposer has broken their promise by demonstrating that the transaction hash is absent from the targeted block. This optimization would reduce the reliance on block proposer to actively participate in the dispute resolution process, thereby enhancing the efficiency and trustlessness of the slashing mechanism. Similar to the inclusion proof, the non-existence proof would also be generated off-chain by the disputer and submitted to the slashing smart contract for verification.</p>\n<h2><a name=\"preconf-share-7\" class=\"anchor\" href=\"https://ethresear.ch#preconf-share-7\"></a>Preconf-Share</h2>\n<p>The <code>preconf-share</code> component serves as an API endpoint for users to send and receive requests and for block proposers to send promises with extremely low latency and cost. Additionally, <code>preconf-share</code> acts as an intermediary between users and block proposers, shielding IP addresses on both sides. The features inherited from MEV-Share, such as hints via privacy settings and inclusion conditions, help control the principal-agent problem (PAP), where a block proposer could unbundle the request to include only the tip transaction while omitting the other transactions in the request. This is achieved through the following measures:</p>\n<ol>\n<li>When relaying user requests, only the transaction hash, hints, tip, and preferences are shared with the block proposers.</li>\n<li>The signed raw transactions are shared only with the block proposer that provided the best preconfirmation.</li>\n</ol>\n<h3><a name=\"preconf_sendrequest-8\" class=\"anchor\" href=\"https://ethresear.ch#preconf_sendrequest-8\"></a><code>preconf_sendRequest</code></h3>\n<p><code>preconf_sendRequest</code> allows users to send a preconfirmation request for signed transactions with privacy settings and inclusion conditions.</p>\n<pre><code class=\"lang-tsx\">{\n    inclusion: {\n        desiredBlock: string,      // hex-encoded number\n        maxBlock?: string,         // hex-encoded number\n        tip: string,               // hex-encoded number (wei)\n    },\n    body: Array&lt;\n        { tx: string }\n    &gt;,\n    privacy?: {\n        hints?: Array&lt;\n            \"calldata\" |\n            \"contract_address\" |\n            \"logs\" |\n            \"function_selector\" |\n            \"hash\" |\n            \"tx_hash\"\n        &gt;,\n        operators?: Array&lt;string&gt;,\n    }\n}\n</code></pre>\n<ul>\n<li><code>inclusion</code>: Parameters used by <code>preconf-share</code> node to rank and filter preconfirmation promises.\n<ul>\n<li><code>desiredBlock</code>: The best block to include this request.</li>\n<li><code>maxBlock</code>: The maximum block height in which this request <em>may</em> be included.</li>\n<li><code>tip</code>: The tip to pay the block proposer, denominated in wei, which must match the tip transaction in the request.</li>\n</ul>\n</li>\n<li><code>body</code>: An array of signed transactions. It must contain the tip transaction and match the <code>tip</code> amount in the <code>inclusion</code> parameters.</li>\n<li><code>privacy</code>: Preferences on what data should be shared to block proposers about the request.\n<ul>\n<li><code>hints</code>: Each item additively specifies which data about all transactions in the request to share. If no hints are specified, no transaction data is shared.</li>\n<li><code>operators</code>: Addresses of block proposers that have permission to receive this request and provide a promise.</li>\n</ul>\n</li>\n</ul>\n<h3><a name=\"preconf_confirmrequest-9\" class=\"anchor\" href=\"https://ethresear.ch#preconf_confirmrequest-9\"></a><code>preconf_confirmRequest</code></h3>\n<p><code>preconf_confirmRequest</code> allows block proposers to send a signed preconfirmation promise.</p>\n<pre><code class=\"lang-tsx\">{\n    preconf: {\n        request: PreconfSendRequestParams,\n        block: string\n    },\n    signature: string\n}\n</code></pre>\n<ul>\n<li><code>preconf</code>: The content of the preconfirmation, which is composed of the user request received from the stream and the block number where the block proposer will include the request transactions.\n<ul>\n<li><code>request</code>: The request received from the <code>preconf-share</code> stream.</li>\n<li><code>maxBlock</code>: The block where the block proposer will include the request transactions. It is verified by <code>preconf-share</code> that the block proposer is both an operator of the AVS and the proposer of that block.</li>\n</ul>\n</li>\n<li><code>signature</code>: The <code>preconf</code> parameter signed with the block proposer’s (operator) private key.</li>\n</ul>\n<h1><a name=\"transaction-flow-10\" class=\"anchor\" href=\"https://ethresear.ch#transaction-flow-10\"></a>Transaction flow</h1>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/2311d83e60a2dce3bc197a7fe47e2680ae7167ea.png\" data-download-href=\"https://ethresear.ch/uploads/default/2311d83e60a2dce3bc197a7fe47e2680ae7167ea\" title=\"swimlanes-f8dc5a95d3307a60e4fff4dc4dfb1bbf\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/2311d83e60a2dce3bc197a7fe47e2680ae7167ea_2_642x500.png\" alt=\"swimlanes-f8dc5a95d3307a60e4fff4dc4dfb1bbf\" data-base62-sha1=\"50eWv3u3Ru1hFZFqExhQgyAQHAC\" width=\"642\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/2311d83e60a2dce3bc197a7fe47e2680ae7167ea_2_642x500.png, https://ethresear.ch/uploads/default/optimized/2X/2/2311d83e60a2dce3bc197a7fe47e2680ae7167ea_2_963x750.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/2311d83e60a2dce3bc197a7fe47e2680ae7167ea_2_1284x1000.png 2x\" data-dominant-color=\"FAFAF8\"></a></div><p></p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/a/a00cc30ec982528b24e8cab451abde471e7f6b36.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/a00cc30ec982528b24e8cab451abde471e7f6b36\" title=\"preconf-post-final\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/a/a00cc30ec982528b24e8cab451abde471e7f6b36_2_690x309.jpeg\" alt=\"preconf-post-final\" data-base62-sha1=\"mPRJJnuGoS3YsLyGxOkrX7f22Vw\" width=\"690\" height=\"309\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/a/a00cc30ec982528b24e8cab451abde471e7f6b36_2_690x309.jpeg, https://ethresear.ch/uploads/default/optimized/2X/a/a00cc30ec982528b24e8cab451abde471e7f6b36_2_1035x463.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/a/a00cc30ec982528b24e8cab451abde471e7f6b36_2_1380x618.jpeg 2x\" data-dominant-color=\"F7F4F4\"></a></div><p></p>\n<h1><a name=\"security-11\" class=\"anchor\" href=\"https://ethresear.ch#security-11\"></a>Security</h1>\n<p>The economic security of this protocol relies on the AVS implementation using EigenLayer. For the guarantees to be considered secure, the cost of corruption must exceed the profit from corruption, creating a deterrent against malicious behavior. Under the current Ethereum design, stakers can have a maximum of 50% (16 ETH) of their total staked ETH slashed. Consequently, block proposers are incentivized to violate preconfirmation promises if:</p>\n<ul>\n<li>The sum of tips in the request is more than 16 ETH. In this case, the block proposer can unbundle the request and only include the tip transactions in a block, profiting from the tips while avoiding the execution of the other transactions.</li>\n<li>The sum of profits from extracting value using the request transactions is more than 16 ETH. For example, a block proposer may choose to unbundle a request containing a white-hat funds rescue and tip, and only include the tip while replacing the white-hat rescue with one done by themselves (essentially keeping both the rescue funds and tip), leading to partial inclusion.</li>\n</ul>\n<p>It’s important to note that slashed ETH can potentially be used by the AVS to compensate parties that were wronged, such as the affected users in these scenarios. However, external factors like gas costs, complexity, and opportunity costs also influence the cost of corruption.</p>\n<p>In the context of MEV, the 16 ETH slashing penalty may not always be sufficient to economically secure transactions, a problem similar to that which occurs under PBS implementations. According to data from <a href=\"https://libmev.com/\" rel=\"noopener nofollow ugc\">libMEV</a> for the period from February 23 to March 24, five bundles yielded profits exceeding 16 ETH for searchers: <a href=\"https://libmev.com/bundles/0x37bc7187d9aabad293c07b88265941e0cf5e5885c3c5a39ac0cd4dd3d3120cd3\" rel=\"noopener nofollow ugc\">22.33 ETH</a>, <a href=\"https://libmev.com/bundles/0xe725d9e25199f27e065d7d1dd09468ee65bdf54d5cc1b1ee238c492257083e92\" rel=\"noopener nofollow ugc\">32.53 ETH</a>, <a href=\"https://libmev.com/bundles/0x52c0a7cfae21e8e147aaabef789ae006e6a9e42d380dbcd59b0b81bc4577dfb7\" rel=\"noopener nofollow ugc\">59.19 ETH</a>, and <a href=\"https://libmev.com/bundles/0x013073ecf628cee04c79459c806aaf35943b6f29b6b406db25b7c87793dbe1fd\" rel=\"noopener nofollow ugc\">124.36 ETH</a>. Nevertheless, it’s worth noting that out of the 183,440 bundles that landed on-chain during this period, the average profit was $12.53, out of the total value. This suggests that the vast majority of transactions can be economically secured by the 16 ETH slashing penalty.</p>\n<p>To enhance the security of individual preconfirmation promises, three potential approaches can be explored:</p>\n<ol>\n<li>Implementing an attestation system that provides additional assurances beyond the slashing mechanism.</li>\n<li>An idea from <a class=\"mention\" href=\"https://ethresear.ch/u/diego\">@diego</a> is to extend the AVS or EigenLayer smart contracts to allow block proposers to stake additional ETH, increasing the potential cost of violating a preconfirmation promise.</li>\n<li>As noted by <a class=\"mention\" href=\"https://ethresear.ch/u/ed\">@ed</a>, implementing preconfirmations using enshrined execution tickets, which aims to solve the economic security problem as well.</li>\n</ol>\n<h1><a name=\"looking-ahead-12\" class=\"anchor\" href=\"https://ethresear.ch#looking-ahead-12\"></a>Looking Ahead</h1>\n<p>Having developed and tested the protocol on local networks, the natural next step is to deploy it on a testnet environment. This will provide valuable insights into how the various components and dynamics of the system play out in a more realistic setting.</p>\n<p>One key area to explore is the interaction between preconfirmations and mev-boost. In the current implementation, block proposers act as both block builders and proposers. However, integrating preconfirmations with mev-boost could potentially expand the pool of block proposers and improve the efficiency of the system. To achieve compatibility with mev-boost, a communication channel would need to be established, enabling block proposers to share their preconfirmation promises with builders, who can then include them in the blocks they are constructing.</p>\n<p>It’s important to note that this approach introduces a trust assumption, as block proposers would need to rely on builders to include their promises in the constructed blocks, whereas inclusion lists offer a trustless alternative. Another potential solution to mitigate this trust assumption is to leverage builders running under Trusted Execution Environments (TEEs), such as those in SUAVE. <code>preconf-share</code> nodes are also trusted to not publish signed preconfirmations that were not chosen, so it should eventually be decentralized (akin to mev-boost relays).</p>\n<p>An additional aspect to consider is the complexity of being a block proposer. For many EigenLayer AVS users, the sophistication required to effectively operate as a block proposer may be quite high. Builders, on the other hand, are well-positioned to take on this role, as they already possess the necessary expertise and infrastructure for block building and have developed in-house algorithms for optimizing transaction inclusion. As a result, less sophisticated block proposers may choose to offload the preconfirmation responsibilities to specialized parties.</p>\n<p>To further enhance the protocol and explore its potential, several areas of research and development can be pursued:</p>\n<ol>\n<li>Investigating the economic incentives and game-theoretic aspects of the AVS to ensure a stable and secure system.</li>\n<li>Developing more advanced algorithms for block proposers to optimize transaction inclusion and maximize their rewards.</li>\n<li>Exploring potential interactions with mev-boost, MEV-Share and in-block conditions (like preconfirmations for top-of-block).</li>\n</ol>\n<h2><a name=\"references-13\" class=\"anchor\" href=\"https://ethresear.ch#references-13\"></a>References</h2>\n<ul>\n<li><a href=\"https://ethresear.ch/t/based-preconfirmations/17353\">Based preconfirmations</a> by Justin Drake</li>\n<li><a href=\"https://ethresear.ch/t/analyzing-bft-proposer-promised-preconfirmations/17963\">Analyzing BFT &amp; Proposer-Promised Preconfirmations</a> by Ellie Davidson, et al.</li>\n<li><a href=\"https://github.com/flashbots/mev-share\" rel=\"noopener nofollow ugc\">MEV-Share</a> by Flashbots</li>\n</ul>\n<blockquote>\n<p>Check out the implementation on <a href=\"https://github.com/cairoeth/preconfirmations\" rel=\"noopener nofollow ugc\">GitHub</a></p>\n</blockquote>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/towards-an-implementation-of-based-preconfirmations-leveraging-restaking/19211\">Read full topic</a></p>","link":"https://ethresear.ch/t/towards-an-implementation-of-based-preconfirmations-leveraging-restaking/19211","pubDate":"Thu, 04 Apr 2024 18:01:39 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19211"},"source":{"@url":"https://ethresear.ch/t/towards-an-implementation-of-based-preconfirmations-leveraging-restaking/19211.rss","#text":"Towards an implementation of based preconfirmations leveraging restaking"}},{"title":"Blue shell strategy - discouraging the most concentrated actor as an optimal path","dc:creator":"themandalore","category":"Economics","description":"<p>In light of <a href=\"https://ethresear.ch/t/addressing-systemic-risks-discouragement-attacks-against-centralized-validator-sets/19067\">my post describing a new discouragement attack</a>, I present here an optimal strategy of discouragement to reduce centralization in the validator set. This post will address the most common concerns of “who do we discourage” and “how do we keep it objective”. The short answer for both is that each individual validator should target the largest concentrated actor they see, regardless of size. The article will finish by going into some challenges and traps present in the journey to a desired game theoretic outcome.</p>\n<p><strong>introduction</strong></p>\n<p>To reiterate the goal, we’re designing a system with a globally decentralized and anonymous validator set that is not owned, held accountable, or censorable by any third party corporation or government. Additionally, the validation of the chain should be open to all, including parties using standard consumer grade hardware.</p>\n<p>Currently the Ethereum validator set is threatening to be centralized by economic forces deriving from liquid staking tokens, restaking protocols, and traditional financial products (ETFs). If we do not protect the integrity and decentralization of the validator set, the cause will be lost.</p>\n<p>To briefly go over the discouragement attack from the previous post, participating validators ignore attestations from targeted validators when they (the participating validators) are the committee aggregator. There is no penalty for this as they will normally not be chosen (the proposer picks the attestation list that has the most number of attestations), however the attack succeeds when participating validators are also the proposer, as they will choose the aggregated attestation that does not include targeted validators. This will cause the targeted validators to miss out on attestation rewards for that block and potentially expose them to inactivity leaks (slashing) depending on the size of the concentrated actor. Long story short, once you hit ~10% of validators in agreement with a specific group to discourage, you can reduce their rewards at the percentage of validators supporting (e.g. if 20% of validators participate, you can reduce the discouragement target’s rewards by 20%).</p>\n<p><strong>the plan - a writhing criticism of an EIP should teach them a lesson</strong></p>\n<p>As with any penalty in the system, any implementation must avoid this becoming a popularity contest amongst validators (each LST or validator group saying the other is worse). There should be no alignment police and we don’t want there to be.</p>\n<p>For that reason an example EIP for this strategy is simply: “all parties are to discourage the largest concentrated group of validators’.</p>\n<p>Then you leave it at that. The definition of largest concentrated group is of course subjective, but can mean anything from a CEX, to an LST, to a restaking protocol. It’s up to individual validators to grab the list of validator indices associated with what they perceive as the largest concentrated actor(CA). Even if there is not complete agreement over the set, the system will work to reduce CA rewards if there is any overlap in the lists. The hopeful outcome is that everyone participates and parties are most profitable as anonymous sets of solo stakers. The end goal is to reduce or eliminate usage of the validator set as a means for alternative systems (LST’s, restaking, financialized tradfi products).</p>\n<p>As for largest concentrated actor selection, one option is to make the target list for each validator public. Knowing who is targeting what CA will allow for quick alignment on the issue and there will probably be researchers, oracles, and bounty contracts leading the way in identifying and programmatically updating the list.</p>\n<p>Some may come back with a critique that we should only discourage concentrated validators if they cross some threshold; but this is more difficult. If all other validators discourage someone at 40%, the most rewards they can stop is 60% as they’ll still get attestation rewards from their own blocks. On the other hand, if you can stop a CA when they’re at 5%, it makes a shift in business plans necessary. Identifying threshold violators is also tricky. If the threshold is 20% and two doxxed parties are at 15% and their governance token ownership overlaps…are they over the limit? This could be tough to analyze. Under the blue shell proposal however, if 15% is the largest group, they’ll be discouraged and economically encouraged to divest.</p>\n<p><strong>the desired outcome - self inflicted antitrust laws</strong></p>\n<blockquote>\n<p><a href=\"https://ethresear.ch/t/how-optional-non-kyc-validator-metadata-can-improve-staking-decentralization/17032\">What if a staking provider does manage to get large while evading detection?</a></p>\n<p>In order for this to happen, this hypothetical large provider must have:</p>\n<p><em>Carefully distributed its validators geographically</em><br>\n<em>Carefully distributed its validators in different IP subnets, including likely residential IP regions</em><br>\n<em>Carefully avoid registering any real-world legal entity that could be investigated and/or prosecuted</em><br>\n<em>Carefully chose a diverse set of operators each with near-perfect opsec</em></p>\n<p>… And if all of that happens, well: <a href=\"https://xkcd.com/810/\" rel=\"noopener nofollow ugc\">Mission. Fucking. Accomplished</a> Ethereum is now very resiliently decentralized.***</p>\n</blockquote>\n<p>The truth is that we want people to be afraid of being known. Bring the dark forest to validator sets. Any LST will be forced to go through centralized entities that might as well be investing them in treasuries, but even worse are subject to a whistleblower in their organization doxing their validator indices and ruining the whole thing. Any restaking operation would never work because the validators would be known and targeted. No one would leverage the validator set and this is the point.</p>\n<p>Over time you’d have smaller validators run a few clusters here and there, but if you beat them down to everyone being a single validator or close to it, no one would even attempt a publicly coordinated effort without writing off their rewards.</p>\n<p><strong>trap and challenge scenarios</strong></p>\n<p><em><strong>retaliation scenario</strong></em> - Starting this change is the most difficult part. We have very large players in the validator set now and if broad support is not reached, one potential blowback scenario would be that the CA retaliates and discourages anyone participating in the discouragement attack. They would probably pitch it as themselves protecting consensus integrity and they would discourage anyone they detect as participating. This could be dangerous because the CA could initially be larger (i.e. reduce more rewards) than the participating validators. Overall, they might not do this if they viewed the press around doing such an action as a negative, but if the CA threatens to do this, it could severely hamper participation in the discouragement of the CA. For this reason, we’d hope that an EIP or other “upgrade” initiative would be enough to kick start support over this threshold.</p>\n<p><em><strong>cartel scenario</strong></em> - Here, you have a majority group agree to discourage anyone not in the majority groups. The example would be something like 8 different LST providers all agreeing to split the market (stay under a threshold), but then would attack anyone not in their cartel (e.g. vampire LST’s, CEX’s starting to dominate, or just other non-identified validators). This is a real risk in the current market because LST’s and restaking protocols have billions of dollars in governance tokens riding on them staying active. To break any cartel behavior, social slashing and/or censorship at the app level may be necessary (e.g. don’t include their token transactions).</p>\n<p><em><strong>aligned cartels</strong></em> - We already see it, but this will likely grow to nauseating levels with this proposal. You will see all LST’s / restaking / governance tokens SAY they are aligned and that they are really the best thing for the protocol. They will act as though this upgrade is not meant to target them and they are actually groups of solo staker specifically designed for maximum decentralization and Ethereum alignment. But this is not the case. This strategy is 100% meant to include them. If you can tie the validators together in any way you should count it as a single entity(an LST, all run by a CEX, all in a restaking protocol, all run from the same IP address, a co-op of solo stakers, etc.). It’s up to each validator to pick the grouping, but the standard should be to force coordination out in every way possible. Tell everyone to stay away from using the validator set for anything but validation.</p>\n<p><em><strong>external rewards - the pit of restaking</strong></em></p>\n<p>If you add in external rewards, a big problem could occur. What happens if <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751/11\">validators actually don’t care about base rewards</a>? What happens if concentrated actors make enough off of MEV and restaking that the attestation and sync committee rewards are meaningless to them?</p>\n<p>To beat this, you may have to start ignoring CA blocks (assuming you have &gt;66% participating validators). This is dangerous as you would need more coordination on the target list, but would work if it was unanimous for certain parties. MEV rewards for the CA would go away and coupled with the inactivity leak of enough participation, the penalties would be quite severe to the CA. Overall, more research will be needed in this area if this discouragement is not enough to dissuade the economics causing centralization, however I’m hopeful that just throwing out these ideas would be enough to move serious players from having threatening levels of control.</p>\n<p><strong>enshrinement of the idea</strong></p>\n<p>The main downfall to this proposal is that you’re throwing away valid attestations. Since many concentrated actors could be 10, 20, or more percent of the validator set, this would represent throwing out a lot of attestations and quickly inactivity leaking participants who are of this size. Of course we would hope that before this implementation ever took place, the centralization would be addressed, but the initial state should be handled for. One in-protocol change we could make is to allow the attestation to count toward the threshold, but still penalize them in some way (e.g. remove attestation rewards, but no inactivity leak; or something similar). This option would make it much less disruptive on the chain and could minimize unforeseen consequences if the CA target is too large.</p>\n<p><strong>conclusion</strong></p>\n<p>This article should be a great starting place for continuing discussions with stakeholders and developers in the Ethereum ecosystem as to the best path forward. With<a href=\"https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171\"> talks of reduced ETH issuance/ staking targets</a>, we must recognize that the threats from concentrated actors are too large to ignore and must be handled before we can seriously discuss an equilibrium or even the economics of staking without external influences.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/3/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83.png\" data-download-href=\"https://ethresear.ch/uploads/default/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/3/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83_2_125x130.png\" alt=\"\" data-base62-sha1=\"7PIcQD795N39HGyaFr7ZBwGZfs7\" width=\"125\" height=\"130\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/3/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83_2_125x130.png, https://ethresear.ch/uploads/default/optimized/2X/3/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83_2_187x195.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/3/36e7b442aeebd6ecf028a4aed86b442e5f0a9b83_2_250x260.png 2x\" data-dominant-color=\"E1E5F2\"></a></div><p></p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/blue-shell-strategy-discouraging-the-most-concentrated-actor-as-an-optimal-path/19200\">Read full topic</a></p>","link":"https://ethresear.ch/t/blue-shell-strategy-discouraging-the-most-concentrated-actor-as-an-optimal-path/19200","pubDate":"Wed, 03 Apr 2024 13:44:22 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19200"},"source":{"@url":"https://ethresear.ch/t/blue-shell-strategy-discouraging-the-most-concentrated-actor-as-an-optimal-path/19200.rss","#text":"Blue shell strategy - discouraging the most concentrated actor as an optimal path"}},{"title":"EIP-7623 - Post-4844 Analysis","dc:creator":"Nerolation","category":"Execution Layer Research","description":"<h1><a name=\"eip-7623-post-4844-analysis-1\" class=\"anchor\" href=\"https://ethresear.ch#eip-7623-post-4844-analysis-1\"></a>EIP-7623 - Post-4844 Analysis</h1>\n<p><strong><a href=\"https://eips.ethereum.org/EIPS/eip-7623\" rel=\"noopener nofollow ugc\">EIP-7623</a> proposes to increase the calldata cost for transactions that use Ethereum mainly for DA.</strong></p>\n<p>This is done by setting a floor price for <strong>non-zero bytes at 48 gas</strong> and <strong>zero-bytes at 12 gas</strong>.<br>\nThe goal is to reduce the maximum possible block size (incl. blobs) from <strong>~3.5 MiB</strong> to <strong>~1.9 MiB</strong>.</p>\n<blockquote>\n<p>It’s important to again analyse the impact of the EIP, now that <a href=\"https://eips.ethereum.org/EIPS/eip-4844\" rel=\"noopener nofollow ugc\">EIP-4844</a> went live, in order to form a decision for Pectra.</p>\n</blockquote>\n<h2><a name=\"block-sizes-2\" class=\"anchor\" href=\"https://ethresear.ch#block-sizes-2\"></a>Block sizes</h2>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/f4de385119c7fceddf740fd319d49281b35a0a05.png\" data-download-href=\"https://ethresear.ch/uploads/default/f4de385119c7fceddf740fd319d49281b35a0a05\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/original/2X/f/f4de385119c7fceddf740fd319d49281b35a0a05.png\" alt=\"\" data-base62-sha1=\"yWcBCZjKCE6jSzx2zMYOYFoYdq5\" role=\"presentation\" width=\"690\" height=\"273\" data-dominant-color=\"D8E2E3\"></a></div><p></p>\n<ul>\n<li>With EIP-4844, we increased the avg. block size (incl. blobs for simplicity) by around 4x compared to the pre-4844 times when the avg. block size was around 125 KiB.</li>\n<li>At the same time, we observe the EL part of blocks to become smaller and smaller since Dencun.</li>\n</ul>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/8/815c263ba6c4001831e791a89cec75c899030377.png\" data-download-href=\"https://ethresear.ch/uploads/default/815c263ba6c4001831e791a89cec75c899030377\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/8/815c263ba6c4001831e791a89cec75c899030377_2_690x267.png\" alt=\"\" data-base62-sha1=\"isn1pt7sD8L18WaRU8LS3XxpMRV\" role=\"presentation\" width=\"690\" height=\"267\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/8/815c263ba6c4001831e791a89cec75c899030377_2_690x267.png, https://ethresear.ch/uploads/default/original/2X/8/815c263ba6c4001831e791a89cec75c899030377.png 1.5x, https://ethresear.ch/uploads/default/original/2X/8/815c263ba6c4001831e791a89cec75c899030377.png 2x\" data-dominant-color=\"F6F6F7\"></a></div><p></p>\n<ul>\n<li>The EL payload size trending down means that the gap between the maximum possible block size and the avg. block size increases even further. This is inefficient and max-size blocks have no use case except DoS.</li>\n<li>Currently by creating a <strong>2.78 MiB</strong> block (which is close to the max possible) + including 6 blobs, one ends up at a size of <strong>3.51 MiB</strong> (snappy compressed). Thus, the max possible block size (incl. blobs) is currently <strong>8 times larger</strong> than the average block size we observe.</li>\n</ul>\n<h2><a name=\"impact-of-eip-7623-on-individual-accounts-3\" class=\"anchor\" href=\"https://ethresear.ch#impact-of-eip-7623-on-individual-accounts-3\"></a>Impact of EIP-7623 on individual accounts</h2>\n<p>The following impact analysis is based on one week of data (Mar-26-2024 - Apr-03-2024). The dataset contains all transactions between the blocks 19,520,000 and 19,572,329.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/c/c8b137146897c11cfcb2210f2e5076bcea04bfb0.png\" data-download-href=\"https://ethresear.ch/uploads/default/c8b137146897c11cfcb2210f2e5076bcea04bfb0\" title=\"drawing\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/c/c8b137146897c11cfcb2210f2e5076bcea04bfb0_2_600x300.png\" data-base62-sha1=\"sDpaTO7WvKtdoUuaFhfBsNznA5i\" alt=\"drawing\" width=\"600\" height=\"300\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/c/c8b137146897c11cfcb2210f2e5076bcea04bfb0_2_600x300.png, https://ethresear.ch/uploads/default/optimized/2X/c/c8b137146897c11cfcb2210f2e5076bcea04bfb0_2_900x450.png 1.5x, https://ethresear.ch/uploads/default/original/2X/c/c8b137146897c11cfcb2210f2e5076bcea04bfb0.png 2x\" data-dominant-color=\"F8F7F8\"></a></div><p></p>\n<ul>\n<li>\n<p>With EIP-7623 in place, <strong>~3.02% of the transactions</strong> of the last 7 days would have had to pay the floor price of 12 gas per calldata token. This translates to 48 gas per non-zero calldata byte and 12 gas per zero-byte. Those <strong>3% of transactions</strong> are executed by <strong>1.4% of the active senders</strong>  during that time frame.</p>\n</li>\n<li>\n<p><strong>Thus, the impact on users is minimal.</strong> As shown in <a href=\"https://ethresear.ch/t/analyzing-eip-7623-increase-calldata-cost/19002\">this</a> previous analysis, there are two types of impacted users:</p>\n<ul>\n<li>Using Calldata for DA = <em>Rollups</em><br>\n → those can use blobs</li>\n<li>Putting “messages” into transaction calldata<br>\n → those won’t feel the difference because those transaction, for the majority, have very small messages attached.</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>EIP-7623 initially proposed 16 gas instead of 12 gas as the floor price for every calldata token but based on further analysis, 12 made more sense and not heavily impact on-chain merkle proofs or post-quantum crypto (both of which require much calldata but still need to use the EVM in parallel).</p>\n</blockquote>\n<p><strong>For more details on the individual methods impacted, check out <a href=\"https://nerolation.github.io/eip-7623-impact-analysis/index2.html\" rel=\"noopener nofollow ugc\">this table</a> that lists method IDs and their canonical representation with stats on gas usage and impact of EIP-7623.</strong></p>\n<p>For example, as visible in the <a href=\"https://nerolation.github.io/eip-7623-impact-analysis/index2.html\" rel=\"noopener nofollow ugc\">table</a>, among the affected methods is Starkware’s <em>verifyFRI</em>, a function that is usually executed with 128,796 gas spent on calldata and 125,917 gas spent on EVM operations. The cost in gas for that function, assuming the block gas limit remains the same, would increase by 39.38%.  Similar applies to Scroll’s <em>commitBatch</em> function (which could move to blobs, though).</p>\n<h2><a name=\"the-case-for-pectra-4\" class=\"anchor\" href=\"https://ethresear.ch#the-case-for-pectra-4\"></a>The case for Pectra</h2>\n<p>EIP-7623 is a small change that brings clear benefits:</p>\n<ul>\n<li>reducing the maximum possible block size<br>\n → this is important in the context of further scaling the chain through initiatives such as <a href=\"https://pumpthegas.org/\" rel=\"noopener nofollow ugc\">pumpthegas.org</a> or <a href=\"https://github.com/ethereum/EIPs/pull/8343\" rel=\"noopener nofollow ugc\">EIP-XXXX</a> (<em>Stepwise Blob Throughput Increase</em>).<br>\n → reduces history growth<br>\n → it’s inefficient to have this big discrepancy between the avg. size block and the max possible one. With decreasing average EL payload sizes this gap becomes even larger.</li>\n<li>We do observe that the block size impacts reorgs, but we don’t observe block sizes getting even close to the maximum possible today. Big blocks, submitted to a proposer through MEV-Boost increase the chances of the proposer to miss its slot, benefitting the next proposer.</li>\n</ul>\n<hr>\n<p><em><strong>Find more on that topic here:</strong></em></p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Analyzing EIP-7623: Increase Calldata Cost</td>\n<td><a href=\"https://ethresear.ch/t/analyzing-eip-7623-increase-calldata-cost/19002\">https://ethresear.ch/t/analyzing-eip-7623-increase-calldata-cost/19002</a></td>\n</tr>\n<tr>\n<td>On Increasing the Block Gas Limit</td>\n<td><a href=\"https://ethresear.ch/t/on-increasing-the-block-gas-limit/18567\">https://ethresear.ch/t/on-increasing-the-block-gas-limit/18567</a></td>\n</tr>\n<tr>\n<td>How to Raise the Gas Limit, Part 1: State Growth</td>\n<td><a href=\"https://www.paradigm.xyz/2024/03/how-to-raise-the-gas-limit-1\" rel=\"noopener nofollow ugc\">https://www.paradigm.xyz/2024/03/how-to-raise-the-gas-limit-1</a></td>\n</tr>\n<tr>\n<td>Draft Implementation in Geth</td>\n<td><a href=\"https://github.com/ethereum/go-ethereum/pull/29040\" rel=\"noopener nofollow ugc\">https://github.com/ethereum/go-ethereum/pull/29040</a></td>\n</tr>\n</tbody>\n</table>\n</div>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/eip-7623-post-4844-analysis/19199\">Read full topic</a></p>","link":"https://ethresear.ch/t/eip-7623-post-4844-analysis/19199","pubDate":"Wed, 03 Apr 2024 13:38:01 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19199"},"source":{"@url":"https://ethresear.ch/t/eip-7623-post-4844-analysis/19199.rss","#text":"EIP-7623 - Post-4844 Analysis"}},{"title":"Radius SKDE: Enhancing Rollup Composability with Trustless Sequencing","dc:creator":"wooju","category":"Uncategorized","description":"<ul>\n<li><em>by Hankyung Ko(<a class=\"mention\" href=\"https://ethresear.ch/u/hankyungko\">@HankyungKo</a>) and Chanyang Ju(<a class=\"mention\" href=\"https://ethresear.ch/u/wooju\">@wooju</a>), Researcher at</em> <em><a href=\"https://twitter.com/radius_xyz\" rel=\"noopener nofollow ugc\">Radius</a></em> <em>. Thanks to</em> <em><a href=\"https://twitter.com/Hyunxukee\" rel=\"noopener nofollow ugc\">Tariz</a></em> <em>and</em> <em><a href=\"https://twitter.com/ZeroKnight_eth\" rel=\"noopener nofollow ugc\">AJ</a></em> <em>for reviewing this post.</em></li>\n<li><em>Your feedback and opinions are highly valued. For the original content, please visit</em> <em><a href=\"https://hackmd.io/@Radius/rJUjYRwyA\" rel=\"noopener nofollow ugc\">our blog</a></em> <em>.</em></li>\n</ul>\n<h1><a name=\"h-1-introduction-1\" class=\"anchor\" href=\"https://ethresear.ch#h-1-introduction-1\"></a>1. Introduction</h1>\n<hr>\n<p><a href=\"https://www.theradius.xyz/\" rel=\"noopener nofollow ugc\">Radius</a> is at the forefront of enhancing rollup composability through the development of ‘Shared Sequencer’. Enhancing composability between rollups allows users to access more opportunities, such as arbitrage, enhancing the blockchain ecosystem’s fluidity and potential for innovation. Service providers benefit as well, as they can manage multiple app-specific rollups and support seamless operations, scaling their services effectively. Our research indicates that the ‘Shared Sequencer’ is foundational to achieving the vision of inter-rollup composability. The ‘Shared Sequencer’ ensures atomic inclusion of transactions across multiple rollups or between Layer 1 (L1) and Layer 2 (L2) networks, representing a critical infrastructure component in our system.</p>\n<p>The ‘Shared Sequencer’ must be a neutral entity, more so than any other within the ecosystem. As the entity responsible for constructing blocks across multiple rollups, it must operate without bias, adhering strictly to predefined rules. The essence of being the most neutral sequencer means that the sequencing of blocks must be free from any hidden agendas, creating a trustable system where blocks are produced based solely on these established rules. This neutrality is paramount to prevent any potential for manipulation or unfair advantage within the network.</p>\n<p>Many of the security concerns in blockchain are addressed through cryptography or crypto-economic (optimistic) solutions, with the latter being effective when actions can be retrospectively verified for legitimacy. However, the role of the sequencer presents unique challenges; if a sequencer acts maliciously, such as censoring transactions or engaging in front-running attacks, these actions are not easily identifiable after the fact. Therefore, the development of a neutral shared sequencer necessitates a cryptographic approach. We see potential in an ‘encrypted mempool,’ where the encryption of transaction details hinders the ability of malicious actors to censor, reorder, or manipulate transactions for their benefit, fostering a more secure and trustworthy blockchain environment.</p>\n<h2><a name=\"h-11-delay-encryption-within-an-encrypted-mempool-2\" class=\"anchor\" href=\"https://ethresear.ch#h-11-delay-encryption-within-an-encrypted-mempool-2\"></a>1.1. Delay Encryption within an Encrypted Mempool</h2>\n<hr>\n<p>We have concentrated on designing an encrypted mempool using ‘Delay encryption,’ a cryptographic algorithm that requires a predetermined amount of computation time to obtain the decryption key, utilizing timelock puzzles. This design ensures that the sequencer can commit to the transaction order before reaching the timelock parameter, thus enforcing an unbiased ordering process. The use of delay encryption introduces a mechanism where transactions are secured and ordered without the possibility of tampering or bias, establishing a fair and transparent sequencing process.</p>\n<p>There are currently two main methods to create a censorship-resistant sequencer using delay encryption: Radius’s original <a href=\"https://ethresear.ch/t/mev-resistant-zk-rollups-with-practical-vde-pvde/12677\">Practical Verifiable Delay Encryption (PVDE)</a> and Multiparty Delay Encryption (MDE) [<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>]. Both methods have their trade-offs. PVDE achieves complete trustlessness, allowing users to trust that their transactions are securely included in a block without relying on any external entities. However, this comes at the cost of higher computational expenses for both users and sequencers. On the other hand, MDE reduces computational costs for users and sequencers by introducing multiparty key generation, but this necessitates a 1-out-of-N trust assumption and, as our analysis shows, incurs significant gas fees for storing keys publicly with each block.</p>\n<p>This article introduces Radius’s new encrypted mempool model, Single Key Delay Encryption (SKDE), which inherits the advantages of MDE while addressing its two main drawbacks: the trust assumption and high gas fees. We will briefly discuss how PVDE and MDE achieve their respective trade-offs and then delve into the innovative aspects of our SKDE model. The article will also present experimental results comparing the three models, showcasing the effectiveness and efficiency of SKDE in enhancing the security and trustworthiness of blockchain transaction sequencing.</p>\n<h1><a name=\"h-2-background-3\" class=\"anchor\" href=\"https://ethresear.ch#h-2-background-3\"></a>2. Background</h1>\n<hr>\n<p>Delay encryption is a cryptographic tool that employs time-lock puzzles to enforce a predetermined delay on the availability of a decryption key. This method ensures that encrypted data cannot be decrypted until a specified amount of computational work, often measured in time, has been completed.</p>\n<p>As its core, delay encryption involves two main phases: encryption and timed decryption. During the encryption phase, data is encrypted using a standard cryptographic algorithm, and a time-lock puzzle is generated. This puzzle is constructed in such a way that solving it requires a predictable amount of computational effort, effectively creating a “delay” before the information can be accessed.</p>\n<h2><a name=\"h-21-radius-original-pvde-4\" class=\"anchor\" href=\"https://ethresear.ch#h-21-radius-original-pvde-4\"></a>2.1. Radius’ Original PVDE</h2>\n<hr>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/5/5b65fa0efb6b614032462656e116a754e20a36b5.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/5b65fa0efb6b614032462656e116a754e20a36b5\" title=\"pvde\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/5/5b65fa0efb6b614032462656e116a754e20a36b5_2_690x352.jpeg\" alt=\"pvde\" data-base62-sha1=\"d2xVUAYYwibeDJd3iMegmbAxdBP\" width=\"690\" height=\"352\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/5/5b65fa0efb6b614032462656e116a754e20a36b5_2_690x352.jpeg, https://ethresear.ch/uploads/default/optimized/2X/5/5b65fa0efb6b614032462656e116a754e20a36b5_2_1035x528.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/5/5b65fa0efb6b614032462656e116a754e20a36b5_2_1380x704.jpeg 2x\" data-dominant-color=\"F3F3F3\"></a></div><p></p>\n<p><em>&lt;The overview of Radius’ original PVDE model&gt;</em></p>\n<p>Radius’s original Practical Verifiable Delay Encryption (PVDE) is a sophisticated approach to securing transactions through the use of symmetric key encryption. This method places the onus of encryption key generation directly on the user, effectively eliminating the need for trust assumptions. This trustless model is pivotal in ensuring that users retain complete control over their transaction privacy without depending on external validators or third parties.</p>\n<p>Nevertheless, the implementation of PVDE brings to the fore certain computational challenges, particularly attributed to its reliance on zero-knowledge proofs (ZKPs) and the requirement for sequencers to solve timelock puzzles for each transaction. The computational overhead is twofold:</p>\n<ol>\n<li><strong>Zero-Knowledge Proofs</strong>: Users are required to conduct ZKP proving to validate their encryption keys and the integrity of the encryption process. While ZKPs offer a powerful means to achieve privacy and security by enabling the verification of information without revealing the underlying data, generating these proofs entails a significant computational effort on the part of the users.</li>\n<li><strong>Timelock Puzzle Solving by Sequencers</strong>: Beyond the ZKP-related overhead, sequencers face an additional, substantial computational burden due to the necessity of solving a timelock puzzle for each transaction. Given a timelock parameter set to, for instance, 100 milliseconds, a sequencer operating on a single thread could decrypt fewer than 10 transactions per second. This limitation poses a significant bottleneck, severely impacting the system’s usability and scalability.</li>\n</ol>\n<p>Furthermore, PVDE employs the zk-friendly Poseidon encryption algorithm for its encryption scheme. While Poseidon is lauded for its compatibility with zero-knowledge proof systems, it is inherently more computationally intensive than more conventional encryption algorithms. This additional complexity contributes to the decryption process’s overall computational demands on the sequencer.</p>\n<h2><a name=\"h-22-public-key-delay-encryption-with-multiparty-key-generation-5\" class=\"anchor\" href=\"https://ethresear.ch#h-22-public-key-delay-encryption-with-multiparty-key-generation-5\"></a>2.2. Public Key Delay Encryption with Multiparty Key Generation</h2>\n<hr>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/989b498b598377ee23d05d57a556dcb742d5af6f.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/989b498b598377ee23d05d57a556dcb742d5af6f\" title=\"mde\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/989b498b598377ee23d05d57a556dcb742d5af6f_2_690x366.jpeg\" alt=\"mde\" data-base62-sha1=\"lM1haHjfOsyOq9gGBBAcOQr84gf\" width=\"690\" height=\"366\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/989b498b598377ee23d05d57a556dcb742d5af6f_2_690x366.jpeg, https://ethresear.ch/uploads/default/optimized/2X/9/989b498b598377ee23d05d57a556dcb742d5af6f_2_1035x549.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/989b498b598377ee23d05d57a556dcb742d5af6f_2_1380x732.jpeg 2x\" data-dominant-color=\"E2E9EF\"></a></div><p></p>\n<p><em>&lt;The Overview of MDE [<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>]&gt;</em></p>\n<p>Unlike PVDE, which relies on symmetric key encryption, MDE[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] utilizes asymmetric key encryption. This shift brings about a new approach to generating encryption and extraction <span class=\"math\">(enc, ext)</span> key pairs. Rather than being generated by the user, these key pairs are created by a committee, which operates under the assumption that at least one member is trustworthy. Once the <span class=\"math\">(enc, ext)</span> key pair is made public, the decryption key can be extracted from the <span class=\"math\">ext</span> key after a specified amount of computational effort, equivalent to a set period.</p>\n<p>For sequencers, this model simplifies the process significantly since <strong>only one timelock puzzle needs to be solved</strong>, making the timelock parameter more manageable. Furthermore, users are not required to generate ZKP proof for their transactions, and the system does not rely on zk-friendly encryption, leading to more efficient decryption. Consequently, this methodology allows for accommodating more transactions within a given time slot.</p>\n<h3><a name=\"advantages-6\" class=\"anchor\" href=\"https://ethresear.ch#advantages-6\"></a><strong>Advantages</strong></h3>\n<ul>\n<li><strong>User’s Computation Efficiency</strong>: MDE[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] offers a more efficient computational process for users compared to Radius’s PVDE, as it eliminates the need for generating zero-knowledge proofs. This enhancement is due to a shift in responsibility for creating Timelock Puzzle (TLP) parameters. In PVDE’s architecture, users were tasked with generating TLPs, which necessitated proving the legitimacy of their puzzles to prevent potential attacks that could influence the sequencer’s computation load. However, in MDE, the burden of TLP generation does not fall on individual users, substantially reducing the risk of such attacks. This change eliminates the need for users to prove the proper encryption of their transactions using their keys, streamlining the user experience without compromising security.</li>\n<li><strong>Sequencer’s Computation Efficiency</strong>: The requirement to solve only one timelock puzzle significantly reduces the computational burden on sequencers. This efficiency boosts the capacity to process a higher volume of transactions in a predetermined time slot.</li>\n</ul>\n<h3><a name=\"limitations-7\" class=\"anchor\" href=\"https://ethresear.ch#limitations-7\"></a><strong>Limitations</strong></h3>\n<ul>\n<li><strong>1-out-of-N Trust Model</strong>: The system necessitates a descent to a 1-out-of-N trust model, where trust is decentralized as much as possible to the KeyGen Committee. This approach introduces a reliance on the committee’s integrity for key pair generation.</li>\n<li><strong>Periodic Public Key Pair Storage</strong>: Each period requires the public storage (e.g., on Ethereum) of committee members’ partial key pairs. Assuming there are 20 sequencers, and without considering range proofs, this could result in a fee of approximately 0.768 ETH per block, illustrating a significant cost implication.</li>\n</ul>\n<p>In summary, MDE[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] marks a pivotal evolution in encrypted mempool technology, offering enhanced computational efficiencies for both users and sequencers. However, it also introduces specific trade-offs, including the need for a trust model reliant on a committee and potential cost associated with the system’s operation. These factors present a complex yet promising landscape for MEV mitigation strategies within blockchain networks.</p>\n<h1><a name=\"h-3-radius-new-skde-8\" class=\"anchor\" href=\"https://ethresear.ch#h-3-radius-new-skde-8\"></a>3. Radius’ new SKDE</h1>\n<hr>\n<p>Our Single Key Delay Encryption (SKDE) design represents a step forward from Multiparty Delay Encryption (MDE)[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>], inheriting its two primary advantages while addressing its limitations. Here’s a breakdown of how the SKDE design enhances the framework:</p>\n<h3><a name=\"advantages-inherited-from-scrolls-mde-9\" class=\"anchor\" href=\"https://ethresear.ch#advantages-inherited-from-scrolls-mde-9\"></a><strong>Advantages Inherited from Scroll’s MDE</strong></h3>\n<ul>\n<li><strong>User’s and Sequencer’s Computational Efficiency</strong>: Like Scroll’s MDE, our SKDE design maintains high computational efficiency for both users and sequencers. It simplifies the decryption process and eliminates the need for users to generate zero-knowledge proofs (zkp) for their transactions.</li>\n</ul>\n<h3><a name=\"solutions-to-limitations-10\" class=\"anchor\" href=\"https://ethresear.ch#solutions-to-limitations-10\"></a><strong>Solutions to Limitations</strong></h3>\n<ol>\n<li><strong>Reduced Public Storage Cost</strong>: Our design introduces an entity responsible for performing aggregate operations, significantly reducing the cost associated with storing partial key pairs in a public repository. We have reduced the gas fees from the previously estimated 0.768 ETH to merely 0.008 ETH for storing essential data on a platform like Ethereum.\n<ul>\n<li>The legitimacy of <strong>the aggregator’s operations is proven through Zero-Knowledge Proofs (ZKP)</strong>, where <strong>only compressed information (hash) of the partial keys is made public</strong>. Each committee member signs the hash to validate that it corresponds to the key they generated. This method ensures privacy and integrity without revealing the actual keys, while also drastically cutting down on the blockchain storage costs associated with our system.</li>\n</ul>\n</li>\n<li><strong>Minimized Trust Assumptions</strong>: We have designed the system to allow individuals who do not trust the committee to participate in the key generation process directly. This inclusivity enhances the trustlessness of the system by decentralizing key generation further.</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1\" title=\"Trust_Assumptions\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1_2_690x263.jpeg\" alt=\"Trust_Assumptions\" data-base62-sha1=\"6BtZzWnnxW8R8MyIMw7jHX3xKJX\" width=\"690\" height=\"263\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1_2_690x263.jpeg, https://ethresear.ch/uploads/default/optimized/2X/2/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1_2_1035x394.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/2e49c28058b3c7c9bf8a870ba61a42ae18bbc4e1_2_1380x526.jpeg 2x\" data-dominant-color=\"F3F3F3\"></a></div><p></p>\n<p><em></em></p>\n<h3><a name=\"design-implications-11\" class=\"anchor\" href=\"https://ethresear.ch#design-implications-11\"></a><strong>Design Implications</strong></h3>\n<p>With the SKDE framework, the partial keys are no longer fully public, diverging from MDE[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] where all entities could directly verify partial keys and aggregate only the valid ones. As a result:</p>\n<ul>\n<li><strong>Implemented Robust Crypto-Economic Model for Partial Key Verification</strong>: We have designed and implemented a robust economic model for the verification of partial keys. This model is crafted to incentivize honest participation and deter malicious activities effectively. It strikes a balance between ensuring privacy and maintaining the system’s integrity through trust, showcasing our proactive approach in fortifying the blockchain ecosystem against vulnerabilities.</li>\n</ul>\n<p>In summary, our SKDE design not only adopts the computational efficiencies found in MDE[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] but also addresses its shortcomings by reducing public storage costs and minimizing trust assumptions. By incorporating an aggregation entity validated through ZKP and allowing direct user participation in key generation, we aim to foster a more secure, efficient, and trustless environment for MEV mitigation.</p>\n<h2><a name=\"h-31-main-idea-of-our-skde-12\" class=\"anchor\" href=\"https://ethresear.ch#h-31-main-idea-of-our-skde-12\"></a>3.1. Main idea of our SKDE</h2>\n<hr>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/98e2c52a286cee5920ca741ed7565fee5e272d35.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/98e2c52a286cee5920ca741ed7565fee5e272d35\" title=\"skde\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/98e2c52a286cee5920ca741ed7565fee5e272d35_2_690x383.jpeg\" alt=\"skde\" data-base62-sha1=\"lOuqyDIF15QlI5u3W5jHlfI0ce1\" width=\"690\" height=\"383\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/98e2c52a286cee5920ca741ed7565fee5e272d35_2_690x383.jpeg, https://ethresear.ch/uploads/default/optimized/2X/9/98e2c52a286cee5920ca741ed7565fee5e272d35_2_1035x574.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/98e2c52a286cee5920ca741ed7565fee5e272d35_2_1380x766.jpeg 2x\" data-dominant-color=\"E3E8EE\"></a></div><p></p>\n<p><em></em></p>\n<p>The Single Key Delay Encryption (SKDE) process involves several entities: the Key Generation Committee, Key Aggregator, Sequencer, and Users. Each plays a crucial role in the secure and efficient handling of encrypted transactions.</p>\n<blockquote>\n<p><strong>Key Generation Committee</strong>: Responsible for initiating the encryption process by generating partial keys.</p>\n<p><strong><code>[Phase 1]</code></strong></p>\n<ol>\n<li>Generate a partial key pair <span class=\"math\">(k_{enc}, k_{ext})</span>.</li>\n<li>Produce a hash <span class=\"math\">h</span> to compress <span class=\"math\">(k_{enc}, k_{ext})</span>.</li>\n<li>Sign the compressed <span class=\"math\">h</span>, creating a signature <span class=\"math\">\\sigma</span>.</li>\n<li>Create a proof <span class=\"math\">\\pi</span> that validates the partial key’s integrity.</li>\n<li>Send the generated information <span class=\"math\">(k_{enc}, k_{ext}, h, \\sigma, \\pi)</span> to the Key Aggregator and the Committee.</li>\n</ol>\n<p><strong><code>[Phase 2]</code></strong> (After “Key aggregation” process)</p>\n<ol>\n<li>Validate the integrity of all partial keys, as the initial steps performed by the Key Aggregator.</li>\n<li>If any discrepancies are found or if the aggregation process does not meet specified conditions—such as <span class=\"math\">\\pi_{agg}</span> verification, inclusion of invalid key pairs, or omission of valid key pairs—claims are raised to the Key Aggregator.</li>\n</ol>\n<p><strong>Key Aggregator</strong>: Serves as the central figure in consolidating partial keys and making them known to Sequencers.</p>\n<ol>\n<li>Compute <span class=\"math\">h</span> using the partial keys and verify the signatures <span class=\"math\">\\sigma</span>.</li>\n<li>Verify the validity of all partial keys using <span class=\"math\">\\pi</span>.</li>\n<li>Exclude any invalid partial keys and aggregate the rest.</li>\n<li>Generate a proof of aggregation <span class=\"math\">\\pi_{agg}</span>.</li>\n<li>Announce the Aggregated key <span class=\"math\">(k_{enc}^{agg}, k_{ext}^{agg})</span> to Sequencers.</li>\n</ol>\n<p><strong>Sequencer</strong>: Responsible for finalizing the transaction sequence and decryption process.</p>\n<ol>\n<li>Verify <span class=\"math\">\\pi_{agg}</span>.</li>\n<li>Upon User request, provide the Aggregated encryption key <span class=\"math\">k_{enc}^{agg}</span>.</li>\n<li>Upon receiving an Encrypted Transaction, commit its order and using the Aggregated extraction key <span class=\"math\">k_{ext}^{agg}</span> to compute the decryption key <span class=\"math\">k_{dec}^{agg}</span>.</li>\n<li>Decrypting the transactions.</li>\n</ol>\n<p><strong>User</strong>: Engages with the Sequencer to encrypt transactions using the Aggregated encryption key <span class=\"math\">k_{enc}^{agg}</span>.</p>\n<ol>\n<li>Query the Sequencer for the Encryption key.</li>\n<li>Encrypt their transaction using the received Encryption key <span class=\"math\">k_{enc}^{agg}</span> and send <span class=\"math\">CT</span> to the Sequencer.</li>\n</ol>\n</blockquote>\n<h2><a name=\"h-32-addressed-security-challenges-13\" class=\"anchor\" href=\"https://ethresear.ch#h-32-addressed-security-challenges-13\"></a>3.2. Addressed security challenges</h2>\n<hr>\n<p>Our Single Key Delay Encryption (SKDE) design effectively navigates through several security challenges inherent in encrypted mempool systems. By addressing the following attack scenarios, SKDE enhances the integrity and confidentiality of transactions within the blockchain. Here’s how the SKDE framework addresses these challenges:</p>\n<blockquote>\n<p><strong>1. Key Contamination Attack</strong> : A potential attack where an invalid partial key pair <span class=\"math\">(k_{enc}, k_{ext})</span> contaminates the aggregated key, rendering all encrypted transactions undecryptable and compromising the Sequencing Layer.</p>\n<ol>\n<li><strong>Partial Key Verifiability</strong>: The SKDE design ensures that each partial key pair’s validity can be verified, preventing the Key Aggregator from generating a contaminated aggregated key. We achieve this through:\n<ul>\n<li>Creating proofs <span class=\"math\">\\pi</span> for key validity, utilizing Sigma protocols for verifying the relationship of partial key pairs and range proofs to ensure aggregated keys are the unique combination of partial keys.</li>\n</ul>\n</li>\n<li><strong>Key Generation Non-repudiation</strong>: Ensures that Key Setup Committee members cannot deny having generated an invalid partial key. This is done by signing the hash of the partial key, allowing the Aggregator to verify this commitment and depend on crypto-economics to encourage claims against discrepancies.</li>\n<li><strong>Aggregator Responsibility</strong>: The Aggregator is held accountable for excluding invalid partial keys, backed by a penalty protocol that enforces economic consequences for contaminating the block with invalid keys.</li>\n</ol>\n<hr>\n<p><strong>2. Decryption Key Leakage Attack</strong> : A scenario where the Aggregator prematurely discloses an aggregated key <span class=\"math\">(k_{enc}^{agg}, k_{ext}^{agg})</span>, potentially exposing transaction privacy and enabling MEV attacks.</p>\n<ol>\n<li>\n<p><strong>Aggregate Computation Verifiability</strong>: By generating zero-knowledge proofs that validate the legitimacy of aggregate operations, SKDE ensures that the public can verify the correctness of the published aggregated key.</p>\n</li>\n<li>\n<p><strong>Commitment Consistency Verifiability</strong>: The framework relies on cryptographic economics to verify that the commitments made public by the Aggregator match the partial keys used in the aggregation process.</p>\n</li>\n<li>\n<p><strong>Timelock Privacy</strong>: SKDE’s design guarantees that, given a minimum of one honest Sequencer, no collusion among the others can compromise the privacy of a user’s transaction until the designated time has passed.</p>\n<ul>\n<li>Additionally, SKDE allows users to partake in the key generation process, offering a fundamental property where, regardless of any collusion among committee members, the confidentiality of the decryption key is preserved. This inclusion ensures that no single group can undermine the system’s security, significantly reinforcing the trustworthiness of the key generation and aggregation phases.</li>\n</ul>\n</li>\n</ol>\n<hr>\n<p><strong>3. Mismatched Key Replay Attack</strong> : A scenario where the encryption key delivered to the user does not match the actual aggregated key, allowing Sequencers or intermediaries to decrypt and re-encrypt transactions under a guise of normalcy.</p>\n<ol>\n<li>\n<p><strong>Mitigation</strong>: Users can verify the aggregated encryption key published in the block against the key received. If discrepancies are found, users have the ability to claim against the Sequencer they communicated with, enhancing transaction privacy and deterring potential MEV attacks.</p>\n<ul>\n<li>Improving proving performance is an ongoing research area that could enable users to verify the validity of keys upon receipt instantaneously, further mitigating the risk of MITM attacks. Our commitment to advancing SKDE’s proving performance promises to strengthen the security framework against sophisticated attack vectors, ensuring a more secure and trustless environment for all network participants.</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<h2><a name=\"h-33-the-lifecycle-of-a-key-14\" class=\"anchor\" href=\"https://ethresear.ch#h-33-the-lifecycle-of-a-key-14\"></a>3.3. The lifecycle of a key</h2>\n<hr>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/273d8fd884dc7350b31e4c7bcebee14fe2013df1.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/273d8fd884dc7350b31e4c7bcebee14fe2013df1\" title=\"key_lifecycle\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/273d8fd884dc7350b31e4c7bcebee14fe2013df1_2_690x119.jpeg\" alt=\"key_lifecycle\" data-base62-sha1=\"5B8w3KxBxyVCvwopof7CyvBM3D3\" width=\"690\" height=\"119\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/273d8fd884dc7350b31e4c7bcebee14fe2013df1_2_690x119.jpeg, https://ethresear.ch/uploads/default/optimized/2X/2/273d8fd884dc7350b31e4c7bcebee14fe2013df1_2_1035x178.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/273d8fd884dc7350b31e4c7bcebee14fe2013df1_2_1380x238.jpeg 2x\" data-dominant-color=\"F2F0F0\"></a></div><br>\nIn the lifecycle of a key within systems like Single Key Delay Encryption (SKDE), we can delineate three distinct phases.<p></p>\n<blockquote>\n<p><strong>Preparation Phase</strong>: During this initial stage, the key is generated and undergoes several crucial steps to ensure its readiness for encryption purposes. Key activities include:</p>\n<ul>\n<li>Generation of the partial keys, marking its inception.</li>\n<li>To share the partial keys among Sequencers.</li>\n<li>Aggregation of partial keys to form a robust, unified encryption key.</li>\n<li>Dissemination of the aggregated key for upcoming encryption tasks.</li>\n</ul>\n<hr>\n<p><strong>Accessibility Phase</strong>: This phase is characterized by the system’s readiness to accept and process transactions using the previously prepared key. It involves:</p>\n<ul>\n<li>Collection of encrypted transactions from users.</li>\n<li>To Solve the key, ensuring readiness for decryption.</li>\n<li>Execution of fair sequencing and transmission of order commitments.</li>\n<li>Production of proofs for the aggregation process, affirming the validity of the encryption key.</li>\n</ul>\n<hr>\n<p><strong>Lockdown Phase</strong>: The final stage locks the usage of aggregated key and focuses on transitioning from encryption to decryption. This phase includes:</p>\n<ul>\n<li>Decryption of the amassed transactions, rendering them into their original, intelligible state.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/4/47c4c39b11428643f12782db9a05646489fe40ec.png\" data-download-href=\"https://ethresear.ch/uploads/default/47c4c39b11428643f12782db9a05646489fe40ec\" title=\"key_cycle_period\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/4/47c4c39b11428643f12782db9a05646489fe40ec_2_690x286.png\" alt=\"key_cycle_period\" data-base62-sha1=\"aeTsRpX8Yc0NfS8RHVcU3w0DlcE\" width=\"690\" height=\"286\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/4/47c4c39b11428643f12782db9a05646489fe40ec_2_690x286.png, https://ethresear.ch/uploads/default/optimized/2X/4/47c4c39b11428643f12782db9a05646489fe40ec_2_1035x429.png 1.5x, https://ethresear.ch/uploads/default/original/2X/4/47c4c39b11428643f12782db9a05646489fe40ec.png 2x\" data-dominant-color=\"F3F2F3\"></a></div></li>\n</ul>\n</blockquote>\n<p>So far, we have discussed the birth and eventual retirement of a single key within our system. Now, we turn our attention to the cyclical nature of key generation and how it perpetuates throughout the system’s operation. Given that all entities utilize a single key, there is a need for a defined periodic cycle to manage its use. We have partitioned the key’s lifecycle into three distinct phases to delineate when users can access and utilize the key. Also, the length of the Lockdown phase directly influences the volume of transactions that can be decrypted and ordered within the given cycle. Therefore, we have established our key usage cycle around the Lockdown phase, setting a rhythm for the generation, active use, and phasing out of keys.</p>\n<p>This systematic cycle ensures that key generation and retirement are synchronized with the network’s operational needs, facilitating a seamless flow of transaction processing and maintaining the security and efficiency of our encrypted mempool system.</p>\n<h1><a name=\"h-4-experimental-results-15\" class=\"anchor\" href=\"https://ethresear.ch#h-4-experimental-results-15\"></a>4. Experimental results</h1>\n<hr>\n<p>In our journey to refine encrypted mempool technology and bolster MEV mitigation efforts, Radius has achieved substantial progress by rolling out the Curie Testnet and Portico Testnet, both powered by the original Practical Verifiable Delay Encryption (PVDE). Additionally, we have implemented Multiparty Delay Encryption (MDE)[<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">KAJ+23</a>] and our Single Key Delay Encryption (SKDE). In this chapter, we present the experimental analysis that offers a detailed comparison of the computational costs entailed by the PVDE, MDE, and SKDE frameworks for each participating entity.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/6/6ce082277915fffc453dd79878189adf285fddcc.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/6ce082277915fffc453dd79878189adf285fddcc\" title=\"Performance_Table\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/6/6ce082277915fffc453dd79878189adf285fddcc_2_690x250.jpeg\" alt=\"Performance_Table\" data-base62-sha1=\"fxazzX0Uss6WYwI5bKSlsBxz3kg\" width=\"690\" height=\"250\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/6/6ce082277915fffc453dd79878189adf285fddcc_2_690x250.jpeg, https://ethresear.ch/uploads/default/optimized/2X/6/6ce082277915fffc453dd79878189adf285fddcc_2_1035x375.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/6/6ce082277915fffc453dd79878189adf285fddcc_2_1380x500.jpeg 2x\" data-dominant-color=\"ECEDEE\"></a></div><p></p>\n<p><em></em><br>\nThe experiments are conducted on an Apple M3 Pro with 18GB memory. The Zero-Knowledge Proofs (ZKP) utilized in PVDE and SKDE are both constructed using the Halo2 proving system. In this context, <span class=\"math\">n</span> represents the number of users and <span class=\"math\">c</span> denotes the number of Key Generation Committee members. <span class=\"math\">T_s</span> denotes a short-cycle timelock parameter for PVDE, and <span class=\"math\">T_l</span> is a long-cycle timelock parameter for MDE and SKDE.</p>\n<blockquote>\n<p><span class=\"math\">T_s</span> in PVDE : This parameter is designed to accommodate the generation of a time lock puzzle for every individual transaction within PVDE. It is set to ensure that there is sufficient time to send an order commit to the user before the conclusion of the time lock parameter. The shorter cycle is necessitated by the per-transaction time lock puzzle approach, requiring a quicker turnaround to maintain transaction flow and commit timing.</p>\n<p><span class=\"math\">T_l</span> in MDE and SKDE : Unlike PVDE, MDE and SKDE operate under a model where only one time lock puzzle needs to be solved within a defined cycle. This allows for a longer time lock parameter <span class=\"math\">T_l</span>, providing the flexibility to accumulate transactions over a longer period. The extended time lock cycle facilitates not only a First-Come-First-Served (FCFS) sequencing but also enables the aggregation of transactions to apply predetermined rules (such as fee auctions) for ordering and committing transactions. This longer duration ensures there is ample time to order transactions according to these rules, enhancing the system’s capacity to handle transactions efficiently and securely.</p>\n</blockquote>\n<p>Through this analysis, we have determined that SKDE stands out in terms of computational efficiency for both users and sequencers. Moreover, it has reduced the gas fee significantly, which is required for storing partial keys each block period. It is also reasonable to project that if blob storage were to be factored into the equation, both MDE and SKDE would likely see a corresponding decrease in fees.</p>\n<p>The introduction of an aggregator entity makes an advancement in our framework, adding a layer of complexity and efficiency. The security of this aggregator is ensured through the application of Zero-Knowledge Proofs (ZKP) and crypto-economic principles, forming a robust design that balances privacy, efficiency, and trust.</p>\n<p>Regarding the <strong>ZKP</strong> entry in the table, it indicates that the aggregator’s computational effort is denoted as <strong>ZKP</strong> + <span class=\"math\">(78c)ms</span>. The ZKP proving computation is linear to the committee size <span class=\"math\">c</span>. Current ongoing research efforts are focused on optimizing the <strong>ZKP</strong> computation of the aggregator, aiming to minimize its operational overhead while maintaining the integrity and efficacy of the system.</p>\n<h1><a name=\"h-5-conclusion-16\" class=\"anchor\" href=\"https://ethresear.ch#h-5-conclusion-16\"></a>5. Conclusion</h1>\n<hr>\n<p>In summarizing the key points from our exploration of PVDE, MDE, and SKDE, we draw conclusions across several critical dimensions: security, user computation, sequencer computation, aggregator computation, and public storage gas fee.</p>\n<blockquote>\n<p><strong>Security</strong>: Our SKDE design approaches ‘trustlessness’, being architected to minimize trust assumptions wherever possible. We have identified potential attack vectors, defined security requirements formally, and proved mathematically to validate these security claims. This rigorous approach ensures a high level of confidence in the robustness of our system against MEV vulnerabilities.</p>\n<p><strong>User Computation</strong>: Unlike previous PVDE, SKDE does not require users to generate individual timelock puzzles, eliminating the risk of DDoS attacks stemming from malformed puzzles. This change effectively removes the need for user-generated proofs, resulting in a revolutionary decrease in user-side computational requirements.</p>\n<p><strong>Sequencer Computation</strong>: By only needing to solve a single timelock puzzle for a defined cycle, SKDE significantly lightens the computational load for sequencers, compared to the multiple puzzle resolutions required in PVDE.</p>\n<p><strong>Aggregator Computation</strong>: The aggregator is a novel entity introduced within the SKDE framework. It was developed to address the significant gas fees associated with MDE’s public key storage. The aggregator performs computational tasks including the creation of ZKPs, contributing to the overall system efficiency while ensuring the integrity of the aggregation process.</p>\n<p><strong>Public Storage Gas Fee</strong>: SKDE achieves a remarkable reduction in the gas fees for public storage, mainly due to the reduced frequency and size of key information that needs to be stored on-chain.</p>\n</blockquote>\n<p>Acknowledging PVDE’s strength in offering a ‘fully trustless’ environment, Radius plans to provide both PVDE and SKDE as viable options, catering to diverse needs within the blockchain ecosystem. While SKDE offers reduced computational demands and gas fees, PVDE remains a powerful choice for those prioritizing maximal trustlessness. Both systems signify Radius’ commitment to offering tailored solutions that enhance security, efficiency, and composability in the rollup landscape.</p>\n<h1><a name=\"references-17\" class=\"anchor\" href=\"https://ethresear.ch#references-17\"></a>References</h1>\n<hr>\n<p>[KAJ+23] Khajehpour, Amirhossein, et al. “<a href=\"https://eprint.iacr.org/2023/1612\" rel=\"noopener nofollow ugc\">Mitigating MEV via Multiparty Delay Encryption.</a>” <em>Cryptology ePrint Archive</em> (2023).<br>\n[PVDE] <a href=\"https://ethresear.ch/t/mev-resistant-zk-rollups-with-practical-vde-pvde/12677\" class=\"inline-onebox\">MEV-resistant ZK-Rollups with Practical VDE (PVDE)</a><br>\n[Curie] <a href=\"https://docs.theradius.xyz/testnet/curie-testnet\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Curie Testnet | Radius</a><br>\n[Portico] <a href=\"https://docs.theradius.xyz/testnet/portico-testnet\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Portico Testnet | Radius</a></p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/radius-skde-enhancing-rollup-composability-with-trustless-sequencing/19185\">Read full topic</a></p>","link":"https://ethresear.ch/t/radius-skde-enhancing-rollup-composability-with-trustless-sequencing/19185","pubDate":"Tue, 02 Apr 2024 03:16:14 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19185"},"source":{"@url":"https://ethresear.ch/t/radius-skde-enhancing-rollup-composability-with-trustless-sequencing/19185.rss","#text":"Radius SKDE: Enhancing Rollup Composability with Trustless Sequencing"}},{"title":"DA Trap: When a DA Attack Becomes Significantly Easy","dc:creator":"leohio","category":"Layer 2","description":"<h3><a name=\"tldr-1\" class=\"anchor\" href=\"https://ethresear.ch#tldr-1\"></a>TL;DR</h3>\n<p>Actual simulations were performed on the cost of attacks against the DA Layer and the probability of being attackable.</p>\n<ol>\n<li>The cost of an attack on the DA Layer is totally unlike that of a PoS double vote.</li>\n<li>The probability of attackability increases rapidly when the degree of redundancy of data holding nodes falls below a certain number like 200.</li>\n</ol>\n<h2><a name=\"withhold-attack-2\" class=\"anchor\" href=\"https://ethresear.ch#withhold-attack-2\"></a>Withhold Attack:</h2>\n<p>The block withholding attack is always the biggest issue in Layer 2. If finality is confirmed in a state where the block data or part of it is withheld, in the case of finality using zkp, everyone’s assets will be frozen. And in a security model like ORU that goes through a fraud proof period, the attacker can extract all the assets.</p>\n<p>As a current countermeasure, DAS is basically used to prevent withhold attacks in the DA Layer. By having randomly selected nodes hold finely chunked data in a redundant manner and having validators verify it with KZG commitments, etc., it becomes extremely difficult to lose a block. However, while it is cryptographically possible to prove data possession, <a href=\"https://arxiv.org/abs/1809.09044\" rel=\"noopener nofollow ugc\">it is not possible to prove that withholding was not done</a>.</p>\n<h2><a name=\"bpvalidator-collusion-economics-3\" class=\"anchor\" href=\"https://ethresear.ch#bpvalidator-collusion-economics-3\"></a>BP/Validator Collusion Economics:</h2>\n<p>The economics of block producers and validators for blocks containing directly verified data differs completely before and after the separation of the DA Layer. For example, in the previous Ethereum or Bitcoin, the probability of blocks continuing after a block containing malicious transactions was extremely low. This is because subsequent BPs would surely confirm that the content is malicious by verifying it, and fork. In other words, to be malicious, you need to deceive future validators regarding the transactions. However, for blocks with a separated DA area that is not directly verified in the future, there is no need to deceive future validators in order to pass blocks with withheld data.</p>\n<p>Incentives for Validator Collusion<br>\nPros:</p>\n<ol>\n<li>Can steal all assets of ORU</li>\n<li>Can receive block rewards</li>\n</ol>\n<p>Cons:</p>\n<ol>\n<li>Reputation gets bad</li>\n</ol>\n<p>In other words, unlike the case of Ethereum PoS, which uses the term “slashing” in the same way, attackers can obtain rewards while also obtaining attack gains, and the cost is not defined in the protocol. Basically, the economic security of slashing cannot be applied to the incentives for data retention and attack, and it will depend on non-incentivized honesty assumptions or community reputation.</p>\n<p>Even so, if this attack can be established with 1/N honest security, it can be said to be sufficiently prevented. Is the security assumption of the DA Layer 1/N?</p>\n<h2><a name=\"h-1n-security-assumption-of-dal-4\" class=\"anchor\" href=\"https://ethresear.ch#h-1n-security-assumption-of-dal-4\"></a>1/N Security Assumption of DAL</h2>\n<p>In DAS, since data is chunked in 2D and distributed redundantly, colluding to withhold seems to be very troublesome. However, considering that you only need to be able to withhold even a part of the block data to perform a DA attack, the assumption of DA attack in DAL including DAS can and should be simplified and calculated as follows:</p>\n<p>Let’s assume a protocol where a single chunk of data like a block is recovered from m redundant nodes, and n such data chunks are posted over a certain period of time, say a year. (Note that this m is neither the total number of nodes holding chunked data in DAS, nor the number of light clients in Celestia!)</p>\n<p>Let’s say that a ratio s (0&lt;s&lt;1) of m are fully aligned nodes, i.e., always online and never malicious or fooled. For DA attacks, unlike explicit double voting in PoS or DPoS, you can contribute to the attack just by going offline for a few days. Therefore, it is reasonable to count nodes that are not honest and online as attackers, rather than considering what percentage of attackers there are.</p>\n<p>Let’s say the threshold for block production is t (0&lt;t&lt;1), where everyone’s DAS proof and signatures need to be collected. (If all are required, a liveness attack that simply stops the blockchain becomes possible. You need a threshold.)</p>\n<p>What do the attackers need to do? The attackers succeed in the attack only if they manage to assign all m<em>t of the nodes selected for block production from m to the m</em>(1-s) group. It is a kind of 1/N security, but if they succeed even once in n repetitions of this game, the entire attack succeeds.</p>\n<p><span class=\"math\">\nattackrisk_1: 1 - (1- {}_{m(1-s)}\\mathrm{C}_{mt} / {}_m\\mathrm{C}_{mt} )^n\n</span></p>\n<p>This can be expressed with <a href=\"https://en.wikipedia.org/wiki/Hypergeometric_distribution\" rel=\"noopener nofollow ugc\">the probability distribution function of hypergeometric distribution f(k,N,K,n)</a> as well.</p>\n<p><span class=\"math\">\nattackrisk_1: 1 - (1- f(mt,m,m(1-s),mt) )^n \n</span></p>\n<p>Let’s actually plug in some typical values. Let’s assume we want to guarantee security for 3 years. s is conservatively about 1/5, or optimistically 1/3. Let’s use 1/5 here. Assuming that 2/3 of the nodes are fully aligned (never go offline or absolutely never join an attack) for a long period of time is extremely scary. With a simple block interval of 15 seconds, n is 6307200. Let’s set the threshold t to 1/2.</p>\n<p>For example, if m is 100,<br>\n<span class=\"math\">\nattackrisk_1: 1 - (1- {}_{80}\\mathrm{C}_{50} / {}_{100}\\mathrm{C}_{50} )^{6307200} = 0.42\n</span></p>\n<p>You can use this python code to calculate it or play with numbers.</p>\n<pre><code class=\"lang-auto\">import math\nm=100; s=0.2; t=0.5; n = 6307200\nm1s = int(m*(1-s)); mt = int(m*t)\nattackrisk = 1 - (1 - float(math.comb(m1s, mt))/float(math.comb(m, mt)))**n\nprint(attackrisk)\n</code></pre>\n<p><strong>There is a 42% chance of being attacked once within 3 years.</strong> This is not a double spend attack, but in the case of ORU, all funds are completely drained. I just put the normal numbers which you can come up with easily.</p>\n<p>And when m=50, it is almost 100% likely to be attacked.</p>\n<p>When m=200, it can be kept to a practically safe probability of around 4.2*10^-8, <em><strong>showing how crucial it is to increase the number of m even if it’s not a significant difference</strong></em>. With this model, it can be shown that security improvement by chunking is effective, and also that it is barely above the passing line.</p>\n<p>In the case of chunking data like DAS, m increases but n also increases greatly, and security improvement is only possible if the increase in m cancels out the increase in n. For any blockchain system, including Ethereum, there has been no successful case of controlling the number of nodes as desired in the long term. If we expect an increase in m by reducing the load, we need to try various models to look at the relationship between data size and available nodes (= the relationship between c and c’ described later).</p>\n<p>Here is a favorably interpreted model for the case where data size is reduced by chunking:</p>\n<p><span class=\"math\">\nattackrisk_2: 1 - (1- {}_{m(1-s)c'}\\mathrm{C}_{mtc'} / {}_{mc'}\\mathrm{C}_{mtc'} )^{nc}\n</span><br>\nwhere c is the number of divisions by chunking, and c’ is the term representing the increase in m due to that.</p>\n<p><span class=\"math\">attackrisk_2  &lt; attackrisk_1</span> when</p>\n<p><span class=\"math\">\n(1- {}_{m(1-s)c'}\\mathrm{C}_{mtc'} / {}_{mc'}\\mathrm{C}_{mtc'} )^{c} &gt; 1- {}_{m(1-s)}\\mathrm{C}_{mt} / {}_m\\mathrm{C}_{mt}\n</span></p>\n<p>While the notation itself is simple, it seems very difficult to back-calculate the proper relationship between c and c’ from this inequality. (We can express <span class=\"math\">{}_{m(1-s)}\\mathrm{C}_{mt} / {}_m\\mathrm{C}_{mt}</span> as the cumulative distribution function of the hypergeometric distribution and approximating it with the Poisson distribution using the fact that n  is large enough. But it  introduces Γ function, ruining all the appetite for wonder.)</p>\n<p>Since it is difficult to derive a general solution, let’s plug in various values based on m=200, s=0.2, t=0.5. This program plots the relationship between c and c’ when attackrisk_1 and attackrisk_2 are equal under the above conditions.</p>\n<blockquote>\n<p>c: 2   c’: 1.0<br>\nc: 5   c’: 1.02<br>\nc: 10   c’: 1.05<br>\nc: 50   c’: 1.15<br>\nc: 200   c’: 1.16<br>\nc: 500   c’: 1.17<br>\nc: 600   c’: 1.17<br>\nc: 700   c’: 1.17</p>\n</blockquote>\n<p>The code is <a class=\"attachment\" href=\"https://ethresear.ch/uploads/short-url/2Tmx4CYVtvrT59vO1LO6gN1NOp9.txt\">here</a> (547 Bytes)</p>\n<p>Even if one data is divided into c=700, c’ is only about 1.2, meaning m increases by only about 20%, which is of order log(n). Assuming that the total number of nodes is divided by the number of groups c since the data is divided by c, the total number of nodes turns out to be <span class=\"math\">t_o = c log(c) * m</span>. (Otherwise, there is no point in chunking if security only decreases.)</p>\n<p>First, it seems reasonable to try <a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\" rel=\"noopener nofollow ugc\">a lognormal distribution</a> for the relationship between data size <span class=\"math\">d = d' / c</span> (d’ is the origial data size) and probability of node, which relates to <span class=\"math\">t_o</span>. This is the distribution that shows the relationship between the amount of wealth and the number of people for that wealth in the world, so it makes sense to apply this distribution if we consider storage as wealth.  The probability density function of the lognormal distribution looks close to <a href=\"https://www.wolframalpha.com/input/?i=Solve%5B%28logx%29%2Fx-y%3D%3D0%2Cx%5D\" rel=\"noopener nofollow ugc\">the inverse function of log(x)/x</a>, so we can expect the number of nodes needed to maintain security after chunking almost follows this distribution. Conversely, if we assume this distribution, it does not seem security has improved significantly.</p>\n<p>And, please note that this expectation can be said on the favorable model.</p>\n<h1><a name=\"inference-and-conclusion-5\" class=\"anchor\" href=\"https://ethresear.ch#inference-and-conclusion-5\"></a>Inference and Conclusion</h1>\n<p>DA Layers are fine.<br>\nA DA Layer with a small m is spicy if it carries an ORU where DA attacks can be incentivized. We should also be careful about cases where trying to improve security ends up increasing n and becoming more dangerous. Even if fancy cryptography is used to create a DA, we still need to know what m and n are, and it solves nothing if they are bad.<br>\nRegarding chunking, assuming that the increase in nodes follows a lognormal distribution, it may be admitted that it is useful, but if m falls below a number like 200 and is small, any effort is futile.</p>\n<p>By the way, what would be a good term to call this security assumption of “in order to attack, you have to happen to be assigned all the bad actors to all the seats” instead of calling it a 1/N honesty assumption?</p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/da-trap-when-a-da-attack-becomes-significantly-easy/19183\">Read full topic</a></p>","link":"https://ethresear.ch/t/da-trap-when-a-da-attack-becomes-significantly-easy/19183","pubDate":"Tue, 02 Apr 2024 00:59:54 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19183"},"source":{"@url":"https://ethresear.ch/t/da-trap-when-a-da-attack-becomes-significantly-easy/19183.rss","#text":"DA Trap: When a DA Attack Becomes Significantly Easy"}},{"title":"On-chain Distributed RNG using ZK?","dc:creator":"kladkogex","category":"Multiparty Computation","description":"<p>I am looking to create a simple <strong>smart contract  based algorithm</strong>  that provides <strong>common random number generation</strong>, provided that <span class=\"math\">t</span> out of <span class=\"math\">N</span> participants are honest, where <span class=\"math\">t * 2 &gt; N</span></p>\n<p>The algorithm has the following properties</p>\n<ul>\n<li>at the end, all honest participants know the common random number <span class=\"math\">R</span></li>\n<li>malicious participants are not able to influence <span class=\"math\">R</span> or make the algorithm stuck.</li>\n</ul>\n<p><em>Preliminary setup</em></p>\n<p>Each participant <span class=\"math\">j</span> register her public keys <span class=\"math\">P[j]</span> with a smartcontract <span class=\"math\">DRNGManager</span>.</p>\n<p>Together with the public key <span class=\"math\">P[j]</span> each participant  submits to <span class=\"math\">DRNGManager</span> a ZK proof that <span class=\"math\">P[j]</span> is valid and that she knows the corresponding private key.</p>\n<p><em>Commit phase</em>  <strong>(10 minutes)</strong></p>\n<p>Each participant <span class=\"math\">j</span> generates a random  EC polynomial of degree <span class=\"math\">t</span>  <span class=\"math\">POLY[j]()</span>.<br>\nThe participant then generates a vector of polynomial evaluations <span class=\"math\">A[i] = [POLY[j](i)]</span> at <span class=\"math\">N</span> integer points  <span class=\"math\">i</span>.</p>\n<p>The participant will then encrypt the evaluations to obtain  a vector of encrypted polynomial evaluations <span class=\"math\">G_[j] = [Encrypt(POLY[j](i))]</span>.<br>\nIt then submits to <code>DRNGManager</code></p>\n<ul>\n<li>\n<p>vector <span class=\"math\">G[j][i]</span></p>\n</li>\n<li>\n<p>commitment to <span class=\"math\">POLY[j]</span></p>\n</li>\n<li>\n<p>a ZK-proof that <span class=\"math\">G[j][i]</span> were correctly generated from <span class=\"math\">POLY[j]</span>.</p>\n</li>\n</ul>\n<p>DRNGManager verifies ZK-proof on receipt</p>\n<p>After the commit phase, <span class=\"math\">DRNGManager</span> will contain  <span class=\"math\">j</span> valid vectors <span class=\"math\">G[j]</span>, where <span class=\"math\">j &gt;= t</span>.</p>\n<p><em>Reveal phase</em>. <strong>(10 minutes)</strong></p>\n<p>Each participant <span class=\"math\">j</span> will be able to  decrypt and reveal to <span class=\"math\">DRNGManager</span> a vector of points <span class=\"math\">POLY[j](i)</span>. The participants will then submit these vector to <span class=\"math\">DRNGManager</span> together with a ZK proof that reveal was done correctly.</p>\n<p>After the reveal phase, <span class=\"math\">DRNGManager</span>  will include <span class=\"math\">k</span> reveals, where <span class=\"math\">k &gt;= t</span>.</p>\n<p><em>RNG computation phase</em>. For each committed polynomial <span class=\"math\">POLY[j]</span>, each participant is then able calculate random number <span class=\"math\">R[j]</span> = <span class=\"math\">POLY[j](0)</span>. The common random is then XOR of all <span class=\"math\">R[j]</span></p>\n            <p><small>1 post - 1 participant</small></p>\n            <p><a href=\"https://ethresear.ch/t/on-chain-distributed-rng-using-zk/19176\">Read full topic</a></p>","link":"https://ethresear.ch/t/on-chain-distributed-rng-using-zk/19176","pubDate":"Mon, 01 Apr 2024 18:38:26 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19176"},"source":{"@url":"https://ethresear.ch/t/on-chain-distributed-rng-using-zk/19176.rss","#text":"On-chain Distributed RNG using ZK?"}},{"title":"Increasing Gas Limit Without State Growth Implications Through Periodic Scheduled Downtime","dc:creator":"MaxResnick","category":"Uncategorized","description":"<p>Lately there has been increased discussion of raising the block gas limit from 30m gas to 40m gas. Critics of this proposal argue that increasing the gas limit risks excessive state bloat which could impact the ability to run full nodes on consumer hardware. With stateless light clients still far away we argue that a different solution could allow us to increase the gas limit without contributing to state bloat. We suggest periodic scheduled downtime outside 9 am-5 pm EST.</p>\n<p>Periodic scheduled downtime has a number of advantages:</p>\n<ol>\n<li>\n<p>Reduced state growth: By having scheduled downtime, the Ethereum network would have regular periods where no new transactions are being processed. This means that the state would not be growing during these times, helping to control the overall state size.</p>\n</li>\n<li>\n<p>Node maintenance: Scheduled downtime provides an opportunity for node operators to perform necessary maintenance tasks, such as pruning the state, switching to RETH, or plugging in more hard drives. This can help ensure that nodes continue to run efficiently and can handle the increased gas limit.</p>\n</li>\n<li>\n<p>Missed Slots: Fewer blocks per day means fewer opportunities for missed slots caused by optimistic relays and other bugs.</p>\n</li>\n<li>\n<p>Network resilience: Regularly scheduled downtime can help identify and address potential issues with the network before they become critical. For example, if an entity is engaging in a socially slashable activity, regularly scheduled downtime allows time for us to coordinate with the social slashing committee and prepare a hard fork before activity resumes.</p>\n</li>\n<li>\n<p>MEV smoothing: Data shows that MEV rewards are higher during EST business hours (see Figure 1 below for Average MEV-Boost payments by hour of day, this is based on 200,000 blocks from … to … ). This is unfair to solo stakers who randomly propose their blocks at night. By scheduling downtime at night, we avoid the unfair distribution of MEV rewards.</p>\n</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d\" title=\"meme\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d_2_690x377.jpeg\" alt=\"meme\" data-base62-sha1=\"yLHCqLH2EbfxaXL213ACftKmWtv\" width=\"690\" height=\"377\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d_2_690x377.jpeg, https://ethresear.ch/uploads/default/optimized/2X/f/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d_2_1035x565.jpeg 1.5x, https://ethresear.ch/uploads/default/original/2X/f/f3ae5fbdbaf3ed34099a896b63eacd0244a9655d.jpeg 2x\" data-dominant-color=\"F1F1F2\"></a></div><p></p>\n<p>Of course, there are some disadvantages— a key one that comes to mind is that this arrangement may be unfair to Solo stakers in RoW: While a 9 am – 5pm chain will be ideal for solo stakers based in North America, it can be incredibly inconvenient for a staker in e.g. Asia (straightforward calculations show that this will be 11pm–7am for a staker in Singapore). Nevertheless we believe the stated advantages overwhelm these.</p>\n<p>In conclusion, implementing periodically scheduled downtime outside of peak hours could provide a balanced solution that allows for increased gas limits while mitigating the risks of excessive state growth. As the Ethereum network continues to evolve, it is crucial to explore and adopt innovative approaches to scaling that maintain the network’s decentralization and accessibility.</p>\n            <p><small>3 posts - 3 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/increasing-gas-limit-without-state-growth-implications-through-periodic-scheduled-downtime/19175\">Read full topic</a></p>","link":"https://ethresear.ch/t/increasing-gas-limit-without-state-growth-implications-through-periodic-scheduled-downtime/19175","pubDate":"Mon, 01 Apr 2024 16:24:21 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19175"},"source":{"@url":"https://ethresear.ch/t/increasing-gas-limit-without-state-growth-implications-through-periodic-scheduled-downtime/19175.rss","#text":"Increasing Gas Limit Without State Growth Implications Through Periodic Scheduled Downtime"}},{"title":"Reward curve with tempered issuance: EIP research post","dc:creator":"aelowsson","category":"Economics","description":"<h1><a name=\"reward-curve-with-tempered-issuance-eip-research-post-1\" class=\"anchor\" href=\"https://ethresear.ch#reward-curve-with-tempered-issuance-eip-research-post-1\"></a>Reward curve with tempered issuance: EIP research post</h1>\n<p>By <a href=\"https://twitter.com/weboftrees\">Anders</a> <a href=\"https://warpcast.com/anderselowsson\">Elowsson</a></p>\n<p><em>My aim with this post is to present the rationale for a reward curve with tempered issuance. It is a longer format of a forthcoming EIP, offering a more detailed account of the benefits and the trade-offs that must be balanced, as well as a comparison with alternative options. I will try to answer any questions you may have in the comments!</em></p>\n<h2><a name=\"h-1-overview-2\" class=\"anchor\" href=\"https://ethresear.ch#h-1-overview-2\"></a>1. Overview</h2>\n<p>Validators began receiving execution layer rewards with The Merge, and liquidity improved when withdrawals were enabled with Shapella. Both upgrades have served to increase the equilibrium quantity of stake. There is a broad consensus that the current deposit size keeps Ethereum sufficiently secure (e.g., <a href=\"https://www.reddit.com/r/ethereum/comments/191kke6/comment/kh79gh1\">1</a>, <a href=\"https://www.reddit.com/r/ethereum/comments/191kke6/comment/kh7do9k/\">2</a>, <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-12-security-and-deposit-size-4\">3</a>). Yet issuance will rise substantially as more stake is deposited under the current reward curve. Excessive incentives for staking, beyond what is necessary for security, can unfortunately over time turn into <a href=\"https://en.wikipedia.org/wiki/Subsidy#Perverse_subsidies\">perverse subsidies</a>, with many downsides. This post will explore the benefits of moderating issuance and available options. It concludes that Ethereum should adopt the <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-55-potential-candidate-for-a-new-reward-curve-23\">candidate reward curve</a>, designed to effectively moderate quantity staked while still maintaining reliable consensus incentives, economic security, resistance to discouragement attacks and cartelization attacks, a favorable composition of the staking set, and viable conditions for solo staking. The candidate reward curve divides the equation of the current reward curve by <span class=\"math\">1+D/k</span>. The single adjusted variable <span class=\"math\">k</span> then comes to define the quantity staked at the peak issuance point, which also corresponds to the point where issuance is halved relative to the current reward curve. A setting of <span class=\"math\">k=2^{26}</span> (67.1M ETH) is suggested as feasible for the near term, with a subsequent potential final adjustment to <span class=\"math\">k=2^{25}</span> (33.6M ETH).</p>\n<h4><a name=\"section-2-rationale-3\" class=\"anchor\" href=\"https://ethresear.ch#section-2-rationale-3\"></a>Section 2 – Rationale</h4>\n<p>The equilibrium yield offered to stakers corresponds to the cost that the marginal staker assigns to staking, i.e., their indifference point between staking and not staking. Section 2.1 shows that if Ethereum offers a higher yield than necessary for maintaining security, it compels its users to incur higher costs, degrading user utility in aggregate. This explains why all ETH holders can benefit from an issuance reduction, something which is also illustrated in Figure 2. The macro perspective is reviewed in Section 2.2. As the quantity of stake grows, one or a few liquid staking tokens (LSTs) may come to supplant ETH as money in Ethereum. Positive network externalities could then lead to both lower user utility and protocol decentralization. Their derivative nature can also erode the social layer’s capacity for upholding Ethereum’s intended consensus process. Section 2.3 suggests that Ethereum should adopt a graduated approach to the proposed changes. Taking a first smaller step will improve Ethereum without being too disruptive, smooth out disequilibria, and allow for an intermediate evaluation of effects on stake composition and quantity.</p>\n<h4><a name=\"section-3-proposed-reward-curve-and-alternative-paradigms-4\" class=\"anchor\" href=\"https://ethresear.ch#section-3-proposed-reward-curve-and-alternative-paradigms-4\"></a>Section 3 – Proposed reward curve and alternative paradigms</h4>\n<p>Section 3 presents the proposed reward curve and alternative paradigms. The proposed reward curve is labeled as Option A, with an issuance level that slowly falls as the quantity staked increases beyond desirable levels. Option B sees the issuance level will instead approach an asymptotic maximum. Option C is the current reward curve, with a rising issuance across the full staking range. The options are compared in Section 3.4, showing how the reward curves diverge as the quantity staked increases.</p>\n<h4><a name=\"section-4-trade-offs-and-priors-5\" class=\"anchor\" href=\"https://ethresear.ch#section-4-trade-offs-and-priors-5\"></a>Section 4 – Trade-offs and priors</h4>\n<p>Section 4.1 explores yield variability for non-pooled stakers and Section 4.2 then reviews how the equilibrium staking yield may affect the proportion of solo stakers. The biggest risk is that disadvantageous economies of scale make solo staking less viable. However, at a higher quantity staked, dominant staking service providers (SSPs) can offer lower fees, better LST money, and lower risk due to emerging moral hazard. The proposed reward curve offers a positive yield across the full range—low enough to make a high quantity stake unlikely, yet sufficiently high as to never force out solo stakers on efficient setups under more improbable scenarios. It is noted that priors regarding both the supply curve and the level of the maximum extractable value (MEV) are relevant to the design. A scenario with a lower supply curve under the current level of MEV is analyzed in Section 4.2.3, aiding the understanding of how the proposed reward curve helps the consensus mechanism absorb delegating stakers with low reservation yields to ensure that solo stakers always are provided with some yield. The broader composition of the staking set is explored in Section 4.3, emphasizing that competition for delegated stake will take place across diverse market segments. Seeing that the cost of running a staking node will not be made prohibitively high relative to the yield, the proposed change will allow variety in preferences and circumstances between delegators to play a more central role in shaping the composition of the staking set. Section 4.4 finally plots the “isoproportion map”, presenting the conditions under which a change to issuance policy is profitable to stakers.</p>\n<h4><a name=\"section-5-security-considerations-6\" class=\"anchor\" href=\"https://ethresear.ch#section-5-security-considerations-6\"></a>Section 5 – Security considerations</h4>\n<p>The effects of issuance policy on economic security are discussed both for the short run and long run in Section 5.1. An important reason for providing a positive yield across the full range in the near term is the to preserve consensus incentives without making more extensive adjustments to the protocol, as discussed in Section 5.2. Sections 5.3-4 take a closer look at discouragement attacks and cartelization attacks. These attacks will become more favorable under stricter reward curves where issuance decreases substantially (particularly under a design with negative issuance levels), and are therefore important to keep in mind. The candidate reward curve does not materially exacerbate the risks of these attacks.</p>\n<h4><a name=\"section-6-conclusions-and-discussion-7\" class=\"anchor\" href=\"https://ethresear.ch#section-6-conclusions-and-discussion-7\"></a>Section 6 – Conclusions and discussion</h4>\n<p>Section 6.1 summarizes the advantages and disadvantages of different issuance levels, and Section 6.2 then presents the author’s conclusion that the proposed candidate reward curve (Option A) is the best alternative for Ethereum at this time. Option C can function as a provisional backup plan. The post concludes by exploring the unknown endgame, broadening the utility measure for token holders to incorporate the development of the entire ecosystem, and cautioning against exploiting users’ bounded rationality concerning yield.</p>\n<h2><a name=\"h-2-rationale-8\" class=\"anchor\" href=\"https://ethresear.ch#h-2-rationale-8\"></a>2. Rationale</h2>\n<h3><a name=\"h-21-user-utility-9\" class=\"anchor\" href=\"https://ethresear.ch#h-21-user-utility-9\"></a>2.1 User utility</h3>\n<p>Define the “reservation yield” as the lowest staking yield <span class=\"math\">y</span> at which an individual is willing to stake. Ethereum’s supply curve then emerges from prospective ETH holders’ reservation yields. Figure 1 shows a <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-21-supply-and-demand-9\">hypothetical supply curve</a> in blue that will be used in a few examples of this post. Total yearly rewards are <span class=\"math\">Y=yD</span>, where <span class=\"math\">D</span> is the quantity staked (“deposit size”). A holder’s reservation yield can be characterized as the “indifference point” where they derive as much utility from staking as from not staking. The area below the supply curve thus represents the implied aggregate cost to stakers <span class=\"math\">Y_c</span> and the area above represents their surplus <span class=\"math\">Y_s</span>, which combines into total rewards <span class=\"math\">Y_c+Y_s=Y</span>. Relevant costs (broadly defined) include hardware and other resources, upkeep, the acquisition of technical knowledge, illiquidity, trust in third parties and other factors increasing the risk premium, various opportunity costs, taxes, etc. A high yield compels users to incur higher costs than necessary for maintaining security, diminishing user utility in aggregate. Slashing risks or any bugs that would effectively burn the stake are from an “accounting perspective” less attributable as a pure cost at the aggregate protocol level, and taxes will by their nature actually increase costs for a user when its surplus rises. But the general principle of capturing costs below the supply curve as the issuance that does not generate any surplus to stakers is very useful for understanding staking economics and welfare.</p>\n<p>A change to Ethereum’s issuance policy from the current reward curve (illustrated in black) to the proposed reward (green) shifts the equilibrium from the black square (1) to the green circle (2). The associated cost reduction <span class=\"math\">Y'_c</span> indicated by the darker blue area benefits all ETH holders, because the ETH was just issued to offset staking costs, without generating any surplus. The shift to the equilibrium also transfers a surplus <span class=\"math\">Y'_s</span> from stakers to all ETH holders (stakers included). The cost reduction is determined by the definite integral of the equation for the inverse supply curve <span class=\"math\">f(x)</span>, bounded by the two equilibrium quantities of the comparative static: <span class=\"math\">Y'_c = \\int_{D_2}^{D_1} f(x)dx\\approx</span> 446k ETH. The surplus shift is instead quantified as <span class=\"math\">Y'_s = D_1y_1-D_2y_2-Y'_c \\approx</span> 252k ETH. Thus, almost 2/3 of the issuance reduction directly contributes to welfare improvement, with 1/3 reallocating utility from stakers to all ETH holders. The outcome for a supply curve with a similar shape will be a similar definite integral and cost/surplus respectively. If the supply curve is flatter around the comparative static, <span class=\"math\">Y'_c</span> becomes relatively larger and <span class=\"math\">Y'_s</span> relatively smaller, and vice versa.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/f51b3a319616300c3c6246c18d0a8cba7f26042d.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/f51b3a319616300c3c6246c18d0a8cba7f26042d\" title=\"Figure 1\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/f51b3a319616300c3c6246c18d0a8cba7f26042d_2_690x410.jpeg\" alt=\"Figure 1\" data-base62-sha1=\"yYjjv1rSCSKtukJksxjm4kmcpdz\" width=\"690\" height=\"410\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/f51b3a319616300c3c6246c18d0a8cba7f26042d_2_690x410.jpeg, https://ethresear.ch/uploads/default/optimized/2X/f/f51b3a319616300c3c6246c18d0a8cba7f26042d_2_1035x615.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/f/f51b3a319616300c3c6246c18d0a8cba7f26042d_2_1380x820.jpeg 2x\" data-dominant-color=\"E7E8F5\"></a></div><p></p>\n<p><strong>Figure 1.</strong> Implied cost <span class=\"math\">Y_c</span> and surplus <span class=\"math\">Y_s</span> of staking with a hypothetical supply curve. A change in issuance policy shifts the equilibrium from the black square to the green circle. The cost savings <span class=\"math\">Y'_c</span> leads to aggregate welfare improvement as long as the protocol remains secure and decentralized, and the reduction in surplus <span class=\"math\">Y'_s</span> simply shifts some utility from stakers to everyone.</p>\n<p>Too often, all staking yield is considered as a surplus <span class=\"math\">Y_s</span>, with the implication that issuance policy is a zero-sum game. But due to the costs that must be borne by stakers, <strong>issuance policy is emphatically <em>not</em> zero sum</strong>. It is fundamental to understand that by having a higher yield, Ethereum steers its users to take on higher costs in aggregate. This is the reason why <a href=\"https://x.com/weboftrees/status/1710708846249865374\">everyone can gain</a> when keeping issuance at the minimum viable level, as long as they own the underlying ETH.</p>\n<p>To illustrate this, the attainable change to someone’s proportion of all ETH <a href=\"https://notes.ethereum.org/@anderselowsson/MinimumViableIssuance#Benefits-of-MVI-to-user-utility\">can be calculated</a> as</p>\n<div class=\"math\">\ny_p=\\frac{1+y}{1+s}-1.\n</div>\n<p>It can be interpreted as the <a href=\"https://en.wikipedia.org/wiki/Fisher_equation\">Fisher equation</a> adapted to Ethereum. The “proportional yield” <span class=\"math\">y_p</span> can be computed for both stakers and non-stakers, in the latter case with <span class=\"math\">y=0</span>. The circulating supply inflation rate <span class=\"math\">s=i-b</span> derives from the issuance rate <span class=\"math\">i=Y_i/S</span> and the burn rate <span class=\"math\">b=B/S=0.008</span>, where <span class=\"math\">Y_i</span> is yearly issuance, <span class=\"math\">S</span> is the circulating supply and <span class=\"math\">B</span> is yearly burn (using the average since The Merge). Further complexities regarding the interpretation of rates in light of compounding effects under a drift of the circulating supply are set aside. Figure 2 illustrates the hypothetical effect of an issuance reduction on user utility, utilizing a comparison of <span class=\"math\">y_p</span> at two different equilibria. It is shown here under the proposed reward curve (Option A) and was in <a href=\"https://x.com/weboftrees/status/1710706011185545671\">previous work</a> presented when halving issuance with the current reward curve (Option C), under a slightly different supply curve. Both <span class=\"math\">y</span> (red arrow) and <span class=\"math\">s</span> (orange arrow) are reduced approximately the same, so stakers are left virtually unaffected. Define the change in cardinal utility for a comparative static where <span class=\"math\">y_p</span> changes from <span class=\"math\">y^b_p</span> to <span class=\"math\">y^a_p</span> as</p>\n<div class=\"math\">\nu'=\\frac{1+y^a_p}{1+y^b_p}-1,\n</div>\n<p>but use the reservation yield as <span class=\"math\">y</span> for those who stop staking when computing <span class=\"math\">y^a_p</span>. Below that yield, they do not stake anyway, so they suffer no additional loss in utility as the yield decreases further. As shown in the bottom pane, de-stakers will under this definition derive a higher utility at the new equilibrium, with non-stakers clearly better off. The reason why welfare can improve in this manner is that the staking costs <span class=\"math\">Y'_c</span> of the blue area from Figure 1 are eliminated. Of course, from a protocol perspective, the question of whether solo stakers continue staking or not is also important. This is a separate topic further explored in Section 4.2. The analysis simply concludes that with the hypothetical supply curve, stakers will be left either unaffected (remaining as stakers if they have low reservation yields) or left even better off—as de-stakers. The effect of issuance policy on stakers under any supply curve is illustrated with an isoproportion map in Section 4.4.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/9653863b260144f60e47d8300c14bb59fc8b7f7a.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/9653863b260144f60e47d8300c14bb59fc8b7f7a\" title=\"Figure 2\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/9653863b260144f60e47d8300c14bb59fc8b7f7a_2_690x466.jpeg\" alt=\"Figure 2\" data-base62-sha1=\"lrQznxCOQflw9uOkxcI3xYFWg54\" width=\"690\" height=\"466\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/9653863b260144f60e47d8300c14bb59fc8b7f7a_2_690x466.jpeg, https://ethresear.ch/uploads/default/optimized/2X/9/9653863b260144f60e47d8300c14bb59fc8b7f7a_2_1035x699.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/9653863b260144f60e47d8300c14bb59fc8b7f7a_2_1380x932.jpeg 2x\" data-dominant-color=\"F7F5F5\"></a></div><p></p>\n<p><strong>Figure 2.</strong> The change in <span class=\"math\">y</span> and <span class=\"math\">s</span> between two hypothetical equilibria is utilized to isolate a change in cardinal utility <span class=\"math\">u'</span> for all token holders. Stakers are subjected to a reduction in yield <span class=\"math\">y</span>, but the reduction in the inflation rate <span class=\"math\">s</span> is similar, so they are left unaffected (<span class=\"math\">y_p</span> stays the same). De-stakers incur no further loss in utility once <span class=\"math\">y</span> falls below their reservation yield. They benefit together with non-stakers from the reduction in <span class=\"math\">s</span>.</p>\n<p>Schwarz-Shilling and Dietrich refer to <span class=\"math\">y_p</span> as the “<a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751\">real total staking yield</a>” (they do not specify an equation in their post, but may imply that they use <span class=\"math\">y_p=y-s</span>; with <span class=\"math\">b=0</span> for visual clarity). Their plots across reward curves, including <a href=\"https://ethereum-magicians.org/t/electra-issuance-curve-adjustment-proposal/18825#proposal-for-electra-issuance-curve-adjustment-3\">plots of Option A</a>, are very useful for conceptualizing the measure itself.</p>\n<h3><a name=\"h-22-macro-perspective-10\" class=\"anchor\" href=\"https://ethresear.ch#h-22-macro-perspective-10\"></a>2.2 Macro perspective</h3>\n<p>The reward curve influences the proportion of all circulating ETH that is staked, and it is therefore important to examine the <a href=\"https://notes.ethereum.org/@anderselowsson/MinimumViableIssuance#Benefits-of-MVI-from-a-macro-perspective\"><em>macro perspective of Ethereum’s issuance policy</em></a>. This can be regarded as one component of a <a href=\"https://en.wikipedia.org/wiki/True_cost_accounting\">true cost accounting</a>, extending Section 2.1 to incorporate externalities.</p>\n<p>An LST exceeding critical thresholds regarding the proportion of stake under its control can gain outsized profits. This <a href=\"https://notes.ethereum.org/@djrtwo/risks-of-lsd#Stratum-for-cartelization\">stratum for cartelization</a> of block space can ultimately compromise the consensus mechanism. Risks to Ethereum are further exacerbated if an expansive issuance policy (which the current reward curve arguably represents) enables an LST to attain control over a significant proportion of the <em>total</em> ETH—propelled by network externalities of, e.g., the money function.  The compromised institution(s) then sits one layer above the consensus mechanism, namely the social layer. It became apparent with <a href=\"https://en.wikipedia.org/wiki/The_DAO\">The DAO</a> that if the proportion of the total circulating supply affected by an outcome grows sufficiently large, then the “social layer” may waver on its commitment to the underlying intended consensus process. If the community can no longer effectively intervene in the event of for example a 51 % liveness attack, then risk mitigation in the form of the <a href=\"https://www.youtube.com/watch?v=8DHGOlIlMvc&amp;t=1938s\">warning system</a> discussed by Buterin may not be effective. The proof-of-stake consensus mechanism has in this case through derivatives grown so interconnected with Ethereum’s users that it has overloaded its ultimate arbitrator, the social consensus mechanism. It is a special and in a way inverted case of issues Buterin <a href=\"https://vitalik.eth.limo/general/2023/05/21/dont_overload.html\">previously warned about</a>.</p>\n<p>If the issuance policy leads to a high proportion of all ETH being staked, one or a few LSTs may overtake as money in the Ethereum ecosystem, embedding themselves across every layer and application. As has <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751#network-effects-of-money-lsts-no-thanks-to-forced-risk-taking-8\">been noted</a>, this is a deliberate <a href=\"https://research.lido.fi/t/hasus-goose-submission-proposed-goals-for-lido-dao-to-consider/5590\">objective</a> of some SSPs. By moderating the issuance, each LST will have tougher competition with non-staked ETH, ensuring a <a href=\"https://x.com/fradamt/status/1760808900792594593\">trustless asset</a> within the ecosystem. The social layer will not become co-dependent on an outside organization and its issued derivative of ETH. The principal–agent problem (PAP) of delegating stake to a dominant LST can then be priced more accurately because moral hazard will be less likely to develop. <a href=\"https://x.com/weboftrees/status/1710713959362252884\">No LST will grow “too big to fail”</a> in the eyes of the Ethereum social layer. This pricing will reflect the fact that the agent acting on behalf of the delegator (or any party able to inject themselves into that relationship) gains greater opportunities to degrade consensus for its own profit the larger proportion of the stake it controls. The delegating staker must then continuously assess its security guarantees (e.g., the staking agent’s or injecting parties’ own value at risk), knowing that it may lose everything if the worst-case scenario ever comes to pass.</p>\n<p>One cost explored in Section 2.1 can also affect Ethereum at a macro level. In the case where everyone must stake to not see their savings eroded, differences in tax policies across jurisdictions can hamper geographical decentralization.</p>\n<h3><a name=\"h-23-graduated-approach-11\" class=\"anchor\" href=\"https://ethresear.ch#h-23-graduated-approach-11\"></a>2.3 Graduated approach</h3>\n<p>There are a few arguments for a graduated approach, taking a smaller step in the right direction in one hard fork—evaluating the outcome—and if appropriate taking the final step:</p>\n<ul>\n<li>Compromising economic agents’ ability to plan ahead is welfare degrading. While there have been several proposals seeking to temper issuance dating back to at least 2021 (<a href=\"https://ethresear.ch/t/simplified-active-validator-cap-and-rotation-proposal/9022\">1</a>, <a href=\"https://ethresear.ch/t/circulating-supply-equilibrium-for-ethereum-and-minimum-viable-issuance-during-the-proof-of-stake-era/10954\">2</a>, <a href=\"https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-deposits\">3</a>), individual solo stakers cannot be expected to follow the research debate all too closely. They may first pay attention once a decision has been taken or seriously contemplated. There is also a difference between signaled intentions to moderate issuance and a real decision having been made. At the same time, the quantity of stake has at this point already arguably exceeded levels providing sufficient security. Further growth must be considered welfare degrading <a href=\"https://www.reddit.com/r/ethereum/comments/14vpyb3/comment/jro1739\">as well</a>. A graduated approach can in this context:\n<ul>\n<li>Give solo stakers, and also SSPs, a longer and more gradual adaptation phase.</li>\n<li>Do something to temper the incentives to stake in the near term, while not being too disruptive.</li>\n<li>Convey the possibility of additional adjustments to users who may not follow ongoing discussions that closely.</li>\n</ul>\n</li>\n<li>Ignoring frictions in the decision to stake, a reduction in issuance will precipitate a temporary phase with below-equilibrium yields, until some stakers leave and a new equilibrium is established. A graduated reduction mitigates this problem. An even more gradual reduction, for instance, encoding a small adjustment to issuance every epoch, would bring more implementation overhead.</li>\n<li>It is not possible at this time to ascertain that the full issuance reduction will be necessary to temper the growth in the quantity of stake—it is only a reasonable estimate hinging on assumptions of frictions in the decision to stake or a falling supply curve. Therefore, it seems sensible to move gradually, at least as an acknowledgment of these uncertainties. This reasoning accounts for <a href=\"https://ethresear.ch/t/execution-tickets/17944\">MEV burn</a> on the horizon, which and will also affect the staking yield if implemented.</li>\n<li>There are a few properties of issuance level of particular interest going forward, such as the proportion of solo stakers retained. A graduated approach makes it possible to evaluate intermediate outcomes before implementing the full envisioned issuance reduction. Even if researchers are confident that the full reduction keeps relevant properties in balance, a graduated approach—with an intermediate evaluation before proceeding further—will make the change more palatable to those who may object.</li>\n</ul>\n<p>The next section will present reward curves that incorporate a potential intermediate step as part of a graduated approach.</p>\n<h2><a name=\"h-3-proposed-reward-curve-and-alternative-paradigms-12\" class=\"anchor\" href=\"https://ethresear.ch#h-3-proposed-reward-curve-and-alternative-paradigms-12\"></a>3. Proposed reward curve and alternative paradigms</h2>\n<p>There are three fundamental paradigms that the reward curve can be designed according to under current circumstances (e.g., absence of MEV burn, no staking fee, and a desire to keep yield variability manageable; see also Section 4.1 and 5.2). These were stipulated in <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-6-conclusion-and-discussion-24\">Table 2 in preceding work</a> and are summarized here in Table 1. Option A is the proposed reward curve. It is best at improving user utility and moderating quantity staked, as advocated in Sections 2.1-2.2. Option C provides a higher yield for (solo) staking in the scenario where almost everyone stakes. This may of course also be seen as a drawback, a trade-off further examined in Sections 4.1-4.3. Option B balances between these two approaches. Section 3.4 will plot the reward curves together for further comparison, both for a full reduction and a graduated approach.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Issuance</th>\n<th>Benefit</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Option A:</strong></td>\n<td>Falls marginally at deposit sizes above sufficient security.</td>\n<td>Improves user utility and moderates quantity staked.</td>\n</tr>\n<tr>\n<td><strong>Option B:</strong></td>\n<td>Asymptotically approaches maximum fixed level.</td>\n<td>Balances benefits of Option A and C.</td>\n</tr>\n<tr>\n<td><strong>Option C:</strong></td>\n<td>Continues increasing indefinitely</td>\n<td>Higher yield for solo staking if quantity staked approaches maximum</td>\n</tr>\n</tbody>\n</table>\n</div><p><strong>Table 1.</strong> Three main categories for the reward curves, each explored in this section. Option A is  the proposed approach, favored by the author.</p>\n<h3><a name=\"h-31-option-a-proposed-reward-curve-13\" class=\"anchor\" href=\"https://ethresear.ch#h-31-option-a-proposed-reward-curve-13\"></a>3.1 Option A – Proposed reward curve</h3>\n<h4><a name=\"overview-14\" class=\"anchor\" href=\"https://ethresear.ch#overview-14\"></a>Overview</h4>\n<p>The proposed reward curve attenuates issuance beyond a quantity of stake sufficient for security. It is designed to give very clear mental models: the value of a single adjusted variable <span class=\"math\">k</span> also defines the quantity of stake at both the peak issuance and the issuance halving point (relative to the current reward curve). The reward curve was presented as the <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-55-potential-candidate-for-a-new-reward-curve-23\">candidate reward curve</a> in a previous post on properties of issuance level. Figure 3 illustrates annualized issuance level across deposit size under perfect validator performance. Issuance of the current reward curve in black varies with deposit size according to the equation <span class=\"math\">Y_i=cF\\sqrt{D}</span>, with <span class=\"math\">F</span> set to 64 and the constant <span class=\"math\">c\\approx2.6</span>. The grey curve shows halved issuance (<span class=\"math\">F=32</span>). The proposed reward curve in green introduces a division by <span class=\"math\">1+D/k</span></p>\n<div class=\"math\">\nY_i=\\frac{cF\\sqrt{D}}{1+D/k},\n</div>\n<p>with <span class=\"math\">c</span> and <span class=\"math\">F</span>  unchanged. The full reduction is intended to be <span class=\"math\">k=2^{25}</span>, which gives a peak issuance slightly below 0.5M ETH at <span class=\"math\">2^{25}</span> (33.6M) ETH staked (plus sign), which is also the halving point. The dashed green curve with <span class=\"math\">k=2^{26}</span> (around 67.1M) indicates a potential step in a graduated approach. The fact that the reward curve stipulates a maximum issuance level, which cannot be exceeded, may be beneficial from a communication perspective. In the future, Ethereum’s reward curve shall transition to vary with deposit ratio <span class=\"math\">d=D/S</span> (see Section 6.3), which will then instead translate into a maximum circulating supply inflation rate.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d\" title=\"Figure 3\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d_2_690x404.jpeg\" alt=\"Figure 3\" data-base62-sha1=\"yUFR9kKp7rj2j05Y60w24ofsBfD\" width=\"690\" height=\"404\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d_2_690x404.jpeg, https://ethresear.ch/uploads/default/optimized/2X/f/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d_2_1035x606.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/f/f4b1fef3ee5264c02f7bf663c0a3257df1f1706d_2_1380x808.jpeg 2x\" data-dominant-color=\"F9FAF9\"></a></div><p></p>\n<p><strong>Figure 3.</strong> Issuance level for the proposed reward curve—Option A—in green, compared to the current reward curve in black. The dashed green line represents a stepwise reduction in a potential graduated approach. Halved issuance relative to the current reward curve is indicated in grey, with plus signs indicating both halving points and issuance peaks.</p>\n<p>Figure 4 illustrates the staking yield in green, assuming a realized extractable value (REV) of <span class=\"math\">V=</span> 300k ETH/year (REV is MEV after builders take their cut and the current prevailing level is slightly above 300k). The equation for staking yield is <span class=\"math\">y=y_i+y_v</span>, with <span class=\"math\">y_i=Y_i/D</span> and <span class=\"math\">y_v=V/D</span>. The equation for issuance yield thus becomes</p>\n<div class=\"math\">\ny_i=\\frac{cF}{\\sqrt{D}(1+D/k)},\n</div>\n<p>once again multiplying the denominator of the current reward curve (<span class=\"math\">y_i=cF/\\sqrt{D}</span>) by <span class=\"math\">1+D/k</span>. The same hypothetical supply curve as in Section 2.1 is included in Figure 4. It serves to illustrate how the propensity to supply stake may potentially vary across yield and deposit size a few years from now, and what the impact on the staking equilibrium then becomes with an altered reward curve. In this particular example, the equilibrium yield is reduced by 0.6 % (around 1/5), from 2.94 % with the current reward curve (black rectangle) to 2.34 % with the new reward curve (green circle). In the graduated approach, the equilibrium yield is reduced by only 0.43 % (around 1/7).</p>\n<p>A reasonable <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-22-influence-of-f-on-the-equilibrium-10\">assumption</a> is that the supply curve will gradually shift downwards over time as the staking experience simplifies and DeFi integrations improve. This will in essence depend on how the various costs outlined in Section 2.1 evolve. The faint blue curve could then be the supply curve after another year or two has passed. This would further reduce the yield under both the present and proposed reward curve. The supply curve may also under some circumstances shift upward, for instance, due to a consensus failure prompting stakers to reevaluate risks, or due to increased demand for non-staked ETH, elevating opportunity costs.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/b/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a\" title=\"Figure 4\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/b/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a_2_690x413.jpeg\" alt=\"Figure 4\" data-base62-sha1=\"qGhQKd6epf9EyoGzGpFXQVLJA4G\" width=\"690\" height=\"413\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/b/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a_2_690x413.jpeg, https://ethresear.ch/uploads/default/optimized/2X/b/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a_2_1035x619.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/b/bb00435c9bc5b2bce5cf3f4caf5e055920b1219a_2_1380x826.jpeg 2x\" data-dominant-color=\"F9FAF9\"></a></div><p></p>\n<p><strong>Figure 4.</strong> Staking yield (inclusive of REV) for the proposed reward curve—Option A—in green, compared to the current reward curve in black. The graduated approach is depicted in dashed green. Hypothetical changes in equilibrium from the black square to the green circles are indicated as a guideline, but remain speculative due to uncertainty regarding both the supply curve and future levels of REV.</p>\n<h4><a name=\"reward-variability-15\" class=\"anchor\" href=\"https://ethresear.ch#reward-variability-15\"></a>Reward variability</h4>\n<p>In preparation for the EIP, a <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-4-variability-in-rewards-for-solo-stakers-12\">simulation of reward variability</a> was performed with <a href=\"https://flashbots-data.s3.us-east-2.amazonaws.com/index.html\">current data for REV</a>. Figure 5 shows the simulated cumulative distribution function (CDF) of rewards for solo stakers at various deposit sizes for the proposed reward curve in its full implementation. Figure 6 instead shows the simulated outcome for the graduated approach.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/4/4269de3ae7e65eac785777084dd423808622379f.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/4269de3ae7e65eac785777084dd423808622379f\" title=\"Figure 5\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/4/4269de3ae7e65eac785777084dd423808622379f_2_690x379.jpeg\" alt=\"Figure 5\" data-base62-sha1=\"9twkJlLi6DYqbpbUcgJVvyv34Qv\" width=\"690\" height=\"379\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/4/4269de3ae7e65eac785777084dd423808622379f_2_690x379.jpeg, https://ethresear.ch/uploads/default/optimized/2X/4/4269de3ae7e65eac785777084dd423808622379f_2_1035x568.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/4/4269de3ae7e65eac785777084dd423808622379f_2_1380x758.jpeg 2x\" data-dominant-color=\"F7F7F5\"></a></div><p></p>\n<p><strong>Figure 5.</strong> Solo staker yield variability at various quantities staked under the candidate reward curve and present level of REV. Expected staking yields are indicated by dashed vertical lines.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/fff39e8c808be2d9cd92ee5970b7f1826111987e.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/fff39e8c808be2d9cd92ee5970b7f1826111987e\" title=\"Figure 6\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/fff39e8c808be2d9cd92ee5970b7f1826111987e_2_690x379.jpeg\" alt=\"Figure 6\" data-base62-sha1=\"AwfHPBTbBWkL4Us5WReTJsXG9A2\" width=\"690\" height=\"379\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/fff39e8c808be2d9cd92ee5970b7f1826111987e_2_690x379.jpeg, https://ethresear.ch/uploads/default/optimized/2X/f/fff39e8c808be2d9cd92ee5970b7f1826111987e_2_1035x568.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/f/fff39e8c808be2d9cd92ee5970b7f1826111987e_2_1380x758.jpeg 2x\" data-dominant-color=\"F7F7F5\"></a></div><p></p>\n<p><strong>Figure 6.</strong> Solo staker yield variability at various quantities staked under a graduated implementation of the candidate reward curve and present level of REV. Expected staking yields are indicated by dashed vertical lines.</p>\n<h3><a name=\"h-32-option-b-asymptotically-fixed-issuance-16\" class=\"anchor\" href=\"https://ethresear.ch#h-32-option-b-asymptotically-fixed-issuance-16\"></a>3.2 Option B – Asymptotically fixed issuance</h3>\n<h4><a name=\"overview-17\" class=\"anchor\" href=\"https://ethresear.ch#overview-17\"></a>Overview</h4>\n<p>A somewhat more modest option is to instead divide the present reward curve with <span class=\"math\">1+\\sqrt{D}/k</span>, giving an issuance of</p>\n<div class=\"math\">\nY_i=\\frac{cF\\sqrt{D}}{1+\\sqrt{D}/k}=\\frac{cF}{D^{-0.5}+k^{-1}}.\n</div>\n<p>The equation is in essence a log-logistic CDF, and issuance will thus approach an asymptotic maximum of <span class=\"math\">cFk</span> (but it may not come close to that value while Ethereum operates at its current circulating supply). Figure 7 illustrates a potential reward curve for Option B in orange with <span class=\"math\">k=2^{12}</span> and a potential graduated approach with <span class=\"math\">k=2^{13}</span>. As indicated in the figure, the variable <span class=\"math\">F</span> was adjusted to produce a similar issuance as Options A (and Option C) at specific levels, for easier comparison in subsequent sections. Hence, the halving point marked by a plus sign is also around <span class=\"math\">D=2^{25}</span>, and the graduated approach matches the issuance of Option A at the current quantity staked (31M ETH). But <span class=\"math\">F</span> could be re-adjusted to 64, which would increase the probability of an equilibrium at a lower quantity staked.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/a/a09030ca3df5130faccc0609d9f9f11e5d8edf11.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/a09030ca3df5130faccc0609d9f9f11e5d8edf11\" title=\"Figure 7\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/a/a09030ca3df5130faccc0609d9f9f11e5d8edf11_2_690x404.jpeg\" alt=\"Figure 7\" data-base62-sha1=\"mUpjYrVqYMCtpgnxHeTx1LjamB3\" width=\"690\" height=\"404\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/a/a09030ca3df5130faccc0609d9f9f11e5d8edf11_2_690x404.jpeg, https://ethresear.ch/uploads/default/optimized/2X/a/a09030ca3df5130faccc0609d9f9f11e5d8edf11_2_1035x606.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/a/a09030ca3df5130faccc0609d9f9f11e5d8edf11_2_1380x808.jpeg 2x\" data-dominant-color=\"FAFAF9\"></a></div><p></p>\n<p><strong>Figure 7.</strong> Issuance level for Option B in orange, relative to the current reward curve in black. The dashed orange line outlines a stepwise reduction in a potential graduated approach. Halved issuance relative to the current reward curve is indicated in grey with plus signs.</p>\n<p>The equation for issuance yield instead becomes</p>\n<div class=\"math\">\ny_i=\\frac{cF}{\\sqrt{D}+D/k}.\n</div>\n<p>It is plotted in Figure 10 in Section 3.4 together with the other reward curves.</p>\n<h3><a name=\"h-33-option-c-current-reward-curve-with-reduced-base-reward-factor-18\" class=\"anchor\" href=\"https://ethresear.ch#h-33-option-c-current-reward-curve-with-reduced-base-reward-factor-18\"></a>3.3 Option C – Current reward curve with reduced base reward factor</h3>\n<h4><a name=\"overview-19\" class=\"anchor\" href=\"https://ethresear.ch#overview-19\"></a>Overview</h4>\n<p>The simplest option is to reduce the base reward factor, keeping the current reward curve. The full reduction could then be <span class=\"math\">F=32</span>. It can be noted that this reward curve will reduce the yield relatively more at lower quantities of stake, so <span class=\"math\">F</span> can hardly be reduced below 32 from a security perspective, at least not at this point (see also Section 5.1). A graduated approach should opt for a range between 40-48. In this post, <span class=\"math\">F=44</span> will be illustrated, since the graduated reward curve will then coincide with all others for easier comparison. Figure 8 plots issuance. Yield is plotted in Figure 10 in Section 3.4 together with the other reward curves.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/9/92abc717a5ca3bb39c5391471677aa123014e602.png\" data-download-href=\"https://ethresear.ch/uploads/default/92abc717a5ca3bb39c5391471677aa123014e602\" title=\"Figure 8\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/9/92abc717a5ca3bb39c5391471677aa123014e602_2_690x398.png\" alt=\"Figure 8\" data-base62-sha1=\"kVvK312whXeTN5ed4HaQqCTQ2qu\" width=\"690\" height=\"398\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/9/92abc717a5ca3bb39c5391471677aa123014e602_2_690x398.png, https://ethresear.ch/uploads/default/optimized/2X/9/92abc717a5ca3bb39c5391471677aa123014e602_2_1035x597.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/9/92abc717a5ca3bb39c5391471677aa123014e602_2_1380x796.png 2x\"></a></div><p></p>\n<p><strong>Figure 8.</strong> Issuance level for Option C, relying on the current reward curve with a reduced base reward factor. The dashed grey curve indicates a potential setting for the graduated approach. The full possible reduction that retains sufficient economic security is a halving of issuance, indicated by the grey curve.</p>\n<h3><a name=\"h-34-comparison-of-options-a-c-20\" class=\"anchor\" href=\"https://ethresear.ch#h-34-comparison-of-options-a-c-20\"></a>3.4 Comparison of Options A-C</h3>\n<p>Figure 9 shows the three outlined options, both for a full reduction and a graduated approach. With the full reduction, all curves coincide around <span class=\"math\">D=2^{25}</span> ETH (circle), above which issuance for Option A declines, B levels off, and C continues increasing. With the graduated approach, all curves (dashed) coincide around the current quantity of stake of <span class=\"math\">D=</span> 31M ETH (star), after which they diverge in a similar pattern. It can be noted that the graduated approach of both Option A and (narrowly) Option B gives a lower issuance if all ETH is staked than the full reduction in Option C.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/7/7714d22c1103e37bcc3a44b88c22b54a48e70800.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/7714d22c1103e37bcc3a44b88c22b54a48e70800\" title=\"Figure 9\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/7/7714d22c1103e37bcc3a44b88c22b54a48e70800_2_690x398.jpeg\" alt=\"Figure 9\" data-base62-sha1=\"gZrqwdUfDvV1y4h71QvyyFhfur6\" width=\"690\" height=\"398\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/7/7714d22c1103e37bcc3a44b88c22b54a48e70800_2_690x398.jpeg, https://ethresear.ch/uploads/default/optimized/2X/7/7714d22c1103e37bcc3a44b88c22b54a48e70800_2_1035x597.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/7/7714d22c1103e37bcc3a44b88c22b54a48e70800_2_1380x796.jpeg 2x\" data-dominant-color=\"F9FAF8\"></a></div><p></p>\n<p><strong>Figure 9.</strong> Comparison of issuance levels for Options A-C, with the graduated approach depicted by dashed curves. The three options provide the same issuance at around <span class=\"math\">2^{25}</span> ETH staked for the full reduction (circle) and at 31M ETH for the graduated step (star), above which issuance for Option A falls, B flatlines, and C continues rising.</p>\n<p>Figure 10 shows the staking yield (at the present level of REV) for the same three options. The black double-sided arrow illustrates that the initial reduction in staking yield at the present quantity staked would be under 1 %. The blue double-sided arrows capture the equilibrium shift in yield under the same hypothetical supply curves as previously, demonstrating that the hypothetical reduction in yield would be under 0.5 % for the first graduated step.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/1a61871de21e5de1c966aab7c66c8c8167d15e5b.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/1a61871de21e5de1c966aab7c66c8c8167d15e5b\" title=\"Figure 10\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/1a61871de21e5de1c966aab7c66c8c8167d15e5b_2_690x413.jpeg\" alt=\"Figure 10\" data-base62-sha1=\"3LnmJ81mkYC2sHYTHO0bfXKXkSf\" width=\"690\" height=\"413\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/1a61871de21e5de1c966aab7c66c8c8167d15e5b_2_690x413.jpeg, https://ethresear.ch/uploads/default/optimized/2X/1/1a61871de21e5de1c966aab7c66c8c8167d15e5b_2_1035x619.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/1a61871de21e5de1c966aab7c66c8c8167d15e5b_2_1380x826.jpeg 2x\" data-dominant-color=\"F8F9F8\"></a></div><p></p>\n<p><strong>Figure 10.</strong> Comparison of staking yield (at the present level of REV) for Options A-C, with the graduated approach illustrated by dashed curves, and the current reward curve in black. A shift in the equilibrium from the black square to the circle is indicated as a guideline, but there is uncertainty regarding both the supply curve and future REV. The initial reduction in the graduated approach is under 1 % (black arrows) and under 0.5 % at hypothetical equilibria (blue arrows).</p>\n<h2><a name=\"h-4-trade-offs-and-priors-21\" class=\"anchor\" href=\"https://ethresear.ch#h-4-trade-offs-and-priors-21\"></a>4. Trade-offs and priors</h2>\n<h3><a name=\"h-41-variability-for-solo-stakers-22\" class=\"anchor\" href=\"https://ethresear.ch#h-41-variability-for-solo-stakers-22\"></a>4.1 Variability for solo stakers</h3>\n<p>If issuance is moderated, a larger part of rewards will stem from REV, and the relative variability in staking rewards will therefore increase. This affects solo stakers negatively since they cannot effortlessly rely on pooling for smoothing out variability. A simulation of reward variability was performed with current data for REV, resulting in, e.g., the CDFs of Figures 5-6, but also mappings of standard deviations (SDs) of annualized yield across <span class=\"math\">y</span> and <span class=\"math\">D</span>. Recognizing that stakers may be more <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-43-variability-with-fixed-supply-and-varied-demand-15\">more sensitive to variance at lower staking yields</a>, the SDs were divided by the square root of the expected yield, <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-45-two-dimensional-mappings-of-solo-rewards-variability-17\">referred to</a> as the SSD. This measure attempts to capture degradation from variability for non-pooled stakers. Figure 11 plots the SSD across quantity staked for the different reward curves of this study (lower is better). As evident, the SSD will rise marginally for Option A as the quantity staked increases. This increase is considered acceptable, on the basis that it is reasonable to sacrifice some variability to keep the quantity staked down. When considered in isolation, it is perhaps even desirable to allow the SSD to become a little worse at higher quantities staked than at lower quantities. But having a lower SSD at any <span class=\"math\">D</span> is of course preferable.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/1e1ace36a876ee07ece8e74b760333d408a56c0d.png\" data-download-href=\"https://ethresear.ch/uploads/default/1e1ace36a876ee07ece8e74b760333d408a56c0d\" title=\"Figure 11\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/1e1ace36a876ee07ece8e74b760333d408a56c0d_2_689x382.png\" alt=\"Figure 11\" data-base62-sha1=\"4ijKMZ0nSwPDqzYHxK6dW4GB5cp\" width=\"689\" height=\"382\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/1e1ace36a876ee07ece8e74b760333d408a56c0d_2_689x382.png, https://ethresear.ch/uploads/default/optimized/2X/1/1e1ace36a876ee07ece8e74b760333d408a56c0d_2_1033x573.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/1e1ace36a876ee07ece8e74b760333d408a56c0d_2_1378x764.png 2x\"></a></div><p></p>\n<p><strong>Figure 11.</strong> The SSD for the different reward curves (lower is better) across deposit size.</p>\n<h3><a name=\"h-42-equilibrium-yield-and-the-proportion-of-solo-stakers-23\" class=\"anchor\" href=\"https://ethresear.ch#h-42-equilibrium-yield-and-the-proportion-of-solo-stakers-23\"></a>4.2 Equilibrium yield and the proportion of solo stakers</h3>\n<h4><a name=\"h-421-overview-24\" class=\"anchor\" href=\"https://ethresear.ch#h-421-overview-24\"></a>4.2.1 Overview</h4>\n<p>Ethereum wants to retain solo stakers, certainly at least when measured as a proportion of all stakers. The anticipated outcome of a reduction in issuance level is that less ETH will be staked by both delegating and solo stakers, relative to the outcome when issuance is not reduced (<a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/12#the-complex-conundrum-of-retaining-solo-stakers-1\">1</a>, <a href=\"https://ethereum-magicians.org/t/electra-issuance-curve-adjustment-proposal/18825/11\">2</a>). Using Figure 10 as an example, it is not clear whether the proportion of solo stakers is lower at a hypothetical equilibrium of around 33M ETH staked and a staking yield of 2.34 % than at around 50M ETH staked and a staking yield of 2.94 %. A concern is if there might be a staking yield below which solo stakers in particular would drop off due to the relatively higher fixed costs associated with solo staking. If solo stakers leave en masse below a yield of 2.5 %, then a staking yield of 2.34 % at 33M ETH staked will give a lower proportion than when the yield is 2.94 % at 50M ETH staked. This is of course something to take seriously. Economies of scale are hard to design away in a decentralized blockchain.</p>\n<p>There are however also some arguments as to why a more restrictive reward curve could give a higher or at least similar proportion of solo stakers (see also Section 2.2):</p>\n<ul>\n<li>Dominant SSPs have <a href=\"https://twitter.com/weboftrees/status/1710719496971862072\">better economies of scale at higher quantities staked</a>, increasing their cost advantage over solo stakers.</li>\n<li>Likewise, the <a href=\"https://x.com/weboftrees/status/1710712326117097785\">positive network externality of the money function</a> grows with quantity staked, and with it the competitive advantage of dominant LST-issuing SSPs.</li>\n<li>Furthermore, the PAP associated with an LST may seem less risky if everyone else also uses the LST, with the expectation that the social layer will waver on its commitment to the intended consensus process in the event of a failure.</li>\n<li>Risks could very well price out delegating stakers earlier than solo stakers as the yield falls. If a large enough subset of potential delegators believe that there is a 1 % risk of failure over a year for the LST they wish to hold, then favorable economies of scale or liquidity can be insufficient as a competitive edge. Self-custody is undeniably <a href=\"https://x.com/nero_eth/status/1766354381543292985\">important</a> to a relevant proportion of ETH token holders; this factor should not be overlooked when evaluating the staking supply side.</li>\n<li>Token holders with enough ETH and the technical ability to solo stake are not necessarily abundant, implying a <a href=\"https://twitter.com/weboftrees/status/1710723555476803643\">soft upper bound</a> on the solo staked quantity. It can be argued that if this pool is more or less depleted, then relatively <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751#supply-side-give-me-eth-and-have-my-stake-4\">few of the new stakers</a> will be solo stakers as the supply curve falls and <span class=\"math\">D</span> increases under the current policy. Still, concerning this particular argument, it should be remembered that if the yield is reduced substantially to halt the increase in <span class=\"math\">D</span>, there is no guarantee of retaining a larger proportion of solo stakers in the long run. This ultimately depends on the finer-grained distribution of reservation yields among them.</li>\n</ul>\n<p>Issuance policy should be focused on long-term objectives and not rely on short-term remedies. This also relates to the presently rather valuable solo staking airdrops, if they can be expected to cease. Yet, Ethereum’s evolving consensus mechanism may look different in ten years, with different requirements for staking anyway—there may even be different classes of validators (<a href=\"https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683\">1</a>, <a href=\"https://notes.ethereum.org/bW2PeHdwRWmeYjCgCJJdVA\">2</a>)—so circumstances of the present and in the near-term future cannot be completely ignored. An additional nuance can also be added to the fourth bullet point: some solo stakers stake quite a bit more than 32 ETH, and these may be the most resilient to low yields. Finally note that solo stakers who do not own their hardware may still enjoy some external economies of scale; home stakers on the contrary are directly affected by hardware costs.</p>\n<p>At a fundamental level, the conjecture is that the relative <a href=\"https://x.com/weboftrees/status/1710723376233304391\">distribution of reservation yields may differ between different classes of stakers</a>. This then leads to different proportions of solo stakers under different issuance policies. But whether one policy is better than the other in this respect cannot be ascertained and may also vary over the forthcoming decade. This research topic is certain to receive further attention (<a href=\"https://ethereum-magicians.org/t/electra-issuance-curve-adjustment-proposal/18825/17\">1</a>, <a href=\"https://ethresear.ch/t/initial-analysis-of-stake-distribution/19014\">2</a>).</p>\n<h4><a name=\"h-422-priors-regarding-the-supply-curve-and-rev-25\" class=\"anchor\" href=\"https://ethresear.ch#h-422-priors-regarding-the-supply-curve-and-rev-25\"></a>4.2.2 Priors regarding the supply curve and REV</h4>\n<p>Studying the yield offered at 110M ETH staked in the CDF of staking yield for Option A in Figure 5 may raise particular concerns. The expected staking yield there is only 0.65 %. At a token price of around $3000, a 32 ETH stake would then only generate an expected monthly income just above $50. The “guaranteed” attestation yield not deriving from block proposal or sync-committee duties is only half of that. A decline in the ETH token price could further reduce the income from staking. However, it should be noted that a reasonable prior for the supply curve is that the yield must be quite a bit higher than 0.65 % for 110M ETH to get staked. The only time an equilibrium can be expected at 110M ETH staked is then if the REV increases significantly, pushing up the staking yield to required levels. One easily overlooked benefit of a lower issuance yield at high quantities staked is thus that it pre-emptively counters a higher REV (the staking yield will never go below the marginal staker’s reservation yield under equilibrium). Concerns may of course also be raised around the fact that the quantity of stake is allowed to expand to 110M ETH in the first place, given the good arguments against it. Why offer any yield at all? Besides care for solo stakers, important reasons pertaining to consensus incentives at the present are provided in Section 5.2.</p>\n<h4><a name=\"h-423-low-yield-scenario-26\" class=\"anchor\" href=\"https://ethresear.ch#h-423-low-yield-scenario-26\"></a>4.2.3 Low-yield scenario</h4>\n<p>While it seems probable that a high quantity staked under the proposed reward curve (Option A) would be associated with an elevated level of REV, thus maintaining a slightly higher staking yield, it can still be valuable to examine the alternative scenario. What if the supply curve indeed falls substantially over the next decade to a very low level? Option A gives a staking yield to 1 % at around 74.6M ETH staked under the current level of REV. Option B gives a staking yield of 1.16 % there, and Option C sets it to 1.37 %. But the equilibrium would of course shift to a higher quantity staked for Option B and C, reducing the yield a bit in the process. A hypothetical outcome for Options A-C in a scenario with an equilibrium yield of 1 % for Option A (green circle) is shown in Figure 12. It is of course challenging to speculate on what the supply curve might look like in this unlikely scenario, but it may still be helpful to plot one possible outcome to aid the understanding (it is formed as in the <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-21-supply-and-demand-9\">previous study</a> using <span class=\"math\">k=1</span> and <span class=\"math\">c_2 = 0.001</span>). Option B then gives a yield of 1.09 % at an equilibrium of around 80M ETH staked (orange circle) and Option C gives 1.24 % at around 87M ETH staked (grey circle). Which outcome is better for Ethereum?</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/e/e9411dcd70ebd79f60873997e3ba872f788e4fcf.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/e9411dcd70ebd79f60873997e3ba872f788e4fcf\" title=\"Figure 12\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/e/e9411dcd70ebd79f60873997e3ba872f788e4fcf_2_690x408.jpeg\" alt=\"Figure 12\" data-base62-sha1=\"xhsLeIksj4LMN68EeIcMIxowtRB\" width=\"690\" height=\"408\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/e/e9411dcd70ebd79f60873997e3ba872f788e4fcf_2_690x408.jpeg, https://ethresear.ch/uploads/default/optimized/2X/e/e9411dcd70ebd79f60873997e3ba872f788e4fcf_2_1035x612.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/e/e9411dcd70ebd79f60873997e3ba872f788e4fcf_2_1380x816.jpeg 2x\" data-dominant-color=\"F9F9F9\"></a></div><p></p>\n<p><strong>Figure 12.</strong> Hypothetical equilibria in a scenario with a low supply curve that intersects 1 % staking yield of Option A under the current level of REV.</p>\n<p>If many solo stakers have a reservation yield between 1.24 % and 1 %—in this particular scenario where the majority is staked with reservation yields below 1 %—then they could be disproportionately more likely to drop off. This goes back to the trade-off between the relatively higher fixed costs for solo stakers and the benefits of LSTs at high quantities staked: the notion that dominant SSPs can offer lower fees, better LST money, and lower risk due to emerging moral hazard.</p>\n<p>Ethereum can be designed to enforce an equilibrium at any point along the supply curve (but must be <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-3-consensus-incentives-11\">attentive</a> to the level of <span class=\"math\">y_i</span> relative to <span class=\"math\">y_v</span>). Would enforcing an equilibrium at the blue star be preferable under this supply curve? It corresponds to 30M ETH staked and a total staking yield of around 0.37 %. At present, <span class=\"math\">y_v</span> is 1 %  at 30M ETH staked, so a staking fee would need to be introduced and taken out every epoch. This would require making solo stakers <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-42-effect-of-pooling-14\">lose money every epoch</a>, on the slim chance that they may be assigned to propose a block. That outcome is rather unappealing. But what about after introducing <a href=\"https://ethresear.ch/t/execution-tickets/17944\">MEV burn</a>, would it be desirable at that point? There are several arguments in favor of it (e.g., Section 2), but it could also render solo staking rather disadvantageous due to the relatively higher fixed costs. The effect on the <a href=\"https://notes.ethereum.org/@mikeneuder/set-theoretic-ethereum\">composition</a> of the staking set is harder to predict when enforcing a low quantity staked in such a manner at this point (refer also the next subsection). If the equilibrium yield is 2.6 % at 30M ETH staked, as with the candidate reward curve, then the outcome is far less controversial. An upward shift to the equilibrium quantity of stake—from the blue star to the green circle—<a href=\"https://x.com/weboftrees/status/1754941832595693910\">acts as a “safety valve”</a>, which helps Ethereum neutralize the less desirable properties of a low quantity of stake under a lower supply curve. The consensus mechanism essentially absorbs all delegating stakers with low reservation yields, just to push up the yield enough to allow solo stakers to still operate a 32 ETH validator at a profit. Regardless of whether this is desirable or not, for the sake of users, the upward shift must <em>only</em> take place if strictly required. This is something that the reward curve facilitates.</p>\n<p>It can be interesting to note the difference between the proposed Option A and the current reward curve also under this hypothetical supply curve. The staking yield at the black square in Figure 12 is around 2 % and the incentives to stake thus much higher, drawing 105M ETH into staking. The downsides are the same as previously discussed. Everyone is forced to stake to not see their savings eroded. The issuance level at the black square is around 1708k ETH per year, i.e., almost four times higher than under Option A. Therefore, even though the yield increases by almost 1 %, the supply inflation rate increases even more. Thus, remarkably, stakers are still left worse off under the current reward curve than under Option A, and everyone loses in terms of <span class=\"math\">u'</span>. This follows from the fact that the gain in <span class=\"math\">y_i</span> does not materially surpass the loss from the increased issuance rate <span class=\"math\">i=y_id</span>, where <span class=\"math\">d</span> is the deposit ratio <span class=\"math\">d=D/S</span>. Thus, for an increase in issuance to be profitable at high deposit ratios, the supply curve must slope almost vertically upwards, as further explored in Section 4.4 and Figure 14.</p>\n<p>In the example in Figure 12 with a low supply curve, changing from Option C (grey circle) to Option A (green circle) reduces issuance by around 330k ETH, from around 775k ETH down to 446k ETH. Around 42 % of that reduction corresponds to decreased implied costs <span class=\"math\">Y'_c</span>. The change in utility for ETH holders is shown in Figure 13. Everyone would be better off at the equilibrium of Option A than Option C (disregarding frictions). However, as previously mentioned, this does not mean that solo stakers will keep staking. They could be even better off de-staking, if their reservation yield sits in between 1 % and 1.24 %. From a macro perspective, the overall protocol (including the ETH token holders) could then be worse off if the proportion of solo stakers falls too much. The macro perspective is further interwoven with user utility in Section 6.4.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/c/cf2b713b6293317030e37780d8a7a9498544beb0.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/cf2b713b6293317030e37780d8a7a9498544beb0\" title=\"Figure 13\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/c/cf2b713b6293317030e37780d8a7a9498544beb0_2_690x463.jpeg\" alt=\"Figure 13\" data-base62-sha1=\"tyHUuixYlqw8Xkdr7vSXFVX5Vrq\" width=\"690\" height=\"463\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/c/cf2b713b6293317030e37780d8a7a9498544beb0_2_690x463.jpeg, https://ethresear.ch/uploads/default/optimized/2X/c/cf2b713b6293317030e37780d8a7a9498544beb0_2_1035x694.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/c/cf2b713b6293317030e37780d8a7a9498544beb0_2_1380x926.jpeg 2x\" data-dominant-color=\"F7F6F6\"></a></div><p></p>\n<p><strong>Figure 13.</strong> Isolating the change in utility <span class=\"math\">u'</span> when changing from Option C to Option A under a low supply curve. Stakers are subjected to a reduction in yield <span class=\"math\">y</span>, but the reduction in the inflation rate <span class=\"math\">s</span> is larger, so they are left slightly better off. De-stakers incur no further loss in utility once <span class=\"math\">y</span> falls below their reservation yield. They benefit together with non-stakers from the reduction in <span class=\"math\">s</span>.</p>\n<h3><a name=\"h-43-equilibrium-yield-and-the-broader-composition-of-the-staking-set-27\" class=\"anchor\" href=\"https://ethresear.ch#h-43-equilibrium-yield-and-the-broader-composition-of-the-staking-set-27\"></a>4.3 Equilibrium yield and the broader composition of the staking set</h3>\n<p>The relationship between issuance level and diversity in SSPs also entails a <a href=\"https://twitter.com/weboftrees/status/1710723555476803643\">trade-off</a> between economies of scale and factors such as the positive network externality of the money function. The fact that a positive yield is offered across the full staking range helps alleviate concerns that a major SSP with a structural advantage such as a centralized exchange (CEX)—perhaps leveraging some hypothetical staked ETF—can push up their proportion of the stake to critical levels. At the same time, the risks of centralization around such entities should not be disproportionately emphasized over other risk scenarios. There are already today SSPs attaining critical proportions of the stake by leveraging network externalities onchain, ostensibly foregoing profits in the pursuit of monopolization. This type of structural advantage grows with higher issuance, and stifling that before native ETH possibly is in the minority relative to one LST must be considered as a net positive to the community. When weighing these trade-offs, an issuance level that invariably forces any outcome—whether a very low or very high quantity staked—does not seem desirable. Just as when discussing solo staking, if the supply curve indeed is very low, then it seems acceptable to let the deposit size grow a bit above a level sufficient for security so that some staking yield still exists. If the supply curve turns out to be rather high, then a low deposit size is perfectly fine. No SSP can reasonably outcompete all others if there is an equilibrium at a 2.6 % staking yield and 30M ETH staked (as with Option A).</p>\n<p>Each SSP, reaching for a specific market segment, incurs unique costs besides the cost of running staking nodes, with a wide variety ranging from compliance to software. Indeed, CEXes have somewhat of a local monopoly on their customers-as-delegators, and the opportunity cost of keeping fees competitive with any onchain option is presumably so high that it does not represent the profit-maximizing strategy. What is clear is that competition for delegated stake will unfold across diverse market segments, and perfect competition is not a reasonable assumption. Seeing that the cost of operating a node will not be made prohibitively high relative to the yield, the proposed reward curve (or any of the other options) does not explicitly force a low quantity staked, ultimately allowing variety in preferences and circumstances between delegators to take a more central role in shaping the composition of the staking set. There is therefore no compelling argument as to why any one SSP will overtake others under Option A, B, or C. This is especially pertinent when adopting a graduated approach and evaluating the outcome before proceeding further. There is also already the risk of centralization being more likely under the current reward curve, in this case leveraged by some emerging dominant LST as the money of Ethereum.</p>\n<h3><a name=\"h-44-the-isoproportion-map-28\" class=\"anchor\" href=\"https://ethresear.ch#h-44-the-isoproportion-map-28\"></a>4.4 The isoproportion map</h3>\n<p>Figure 14 maps <span class=\"math\">y_p</span> for stakers across <span class=\"math\">y</span> and <span class=\"math\">D</span> under the previously specified burn rate <span class=\"math\">b=0.008</span> and annual REV <span class=\"math\">V=</span> 300k ETH. The thin black lines can be characterized as “isoproportion” lines across which <span class=\"math\">y_p</span> remains constant (refer to the equation below). The isoproportion map is essential for stakers attempting to understand the effects of issuance policy on their share of the circulating supply. If the slope of the supply curve is steeper than the associated isoproportion line at some specific equilibrium, stakers benefit from an increase in issuance (<span class=\"math\">u'&gt;0</span>); if it is flatter, they are worse off. In microeconomics, a “production possibility curve” can be compared with isoprofit lines to optimize a production set. To the staker, the supply curve becomes a “proportion possibility curve” (the PPC of staking economics), capturing how stakers’ attainable proportion of the circulating supply varies with issuance policy.</p>\n<p>Two hypothetical supply curves are shown in blue, the low supply curve from Figure 12 (dashed) and the baseline supply curve from previous figures (full). The purple isoproportion lines intersect the equilibria of the current reward curve (squares). Since the supply curves (the PPCs) have a flatter slope at equilibrium, stakers are worse off from an increase in issuance, and thus benefit from a decrease in issuance in both cases. They are clearly better off (higher <span class=\"math\">y_p</span>) under the low supply curve at the equilibrium for the proposed reward curve (green circle), and left indifferent under the baseline supply curve (as also indicated in Figure 2). The stars mark where the supply curves reach their maximum <span class=\"math\">y_p</span>, tangent to the corresponding isoproportion lines. This is the ideal equilibrium in terms of <span class=\"math\">y_p</span> for stakers. All other token holders would of course still gain from a reduction in issuance, so in terms of <span class=\"math\">u'</span>, they would certainly prefer an equilibrium at 20M ETH staked under the low supply curve (triangle), where stakers are just as well off as at the outset at the square.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/10314f24aa5b1c0045cc14a22db0546dd7534ec9.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/10314f24aa5b1c0045cc14a22db0546dd7534ec9\" title=\"Figure 14\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/10314f24aa5b1c0045cc14a22db0546dd7534ec9_2_690x413.jpeg\" alt=\"Figure 14\" data-base62-sha1=\"2jfhBjuCu1pIe9A3T0GNlxW24Y1\" width=\"690\" height=\"413\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/10314f24aa5b1c0045cc14a22db0546dd7534ec9_2_690x413.jpeg, https://ethresear.ch/uploads/default/optimized/2X/1/10314f24aa5b1c0045cc14a22db0546dd7534ec9_2_1035x619.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/10314f24aa5b1c0045cc14a22db0546dd7534ec9_2_1380x826.jpeg 2x\" data-dominant-color=\"F6F5F7\"></a></div><p></p>\n<p><strong>Figure 14.</strong> Isoproportion map that illustrates the effects of issuance policy on staker’s proportional yield <span class=\"math\">y_p</span> under equilibrium. A reduction in issuance from the current reward curve (black) is profitable to stakers under both hypothetical supply curves, because the purple isoproportion lines have a steeper slope at equilibrium. The stars indicate the maximum attainable <span class=\"math\">y_p</span> along the supply curves.</p>\n<p>Define <span class=\"math\">v</span> as the REV rate <span class=\"math\">v=V/S</span>. The isoproportion line for any specific <span class=\"math\">y_p</span> then follows the equation</p>\n<div class=\"math\">\ny = \\frac{y_p-(1+y_p)(v+b)}{1-d-y_pd},\\quad \\quad  y_p&lt;\\frac{1-d}{d}.\n</div>\n<p>This equation implies the basic condition for profitability that can be imposed on the supply curve under any equilibrium (e.g., via derivation and analysis of elasticities). If the (inverse) supply curve follows this equation (along any specified <span class=\"math\">y_p</span>), stakers will be indifferent to a change in issuance across the whole deposit ratio range.</p>\n<h2><a name=\"h-5-security-considerations-29\" class=\"anchor\" href=\"https://ethresear.ch#h-5-security-considerations-29\"></a>5. Security considerations</h2>\n<h3><a name=\"h-51-economic-security-30\" class=\"anchor\" href=\"https://ethresear.ch#h-51-economic-security-30\"></a>5.1 Economic security</h3>\n<p>There are certain critical thresholds to be attentive to when reasoning about the economic security of Ethereum. An attacker holding <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attack-and-defense/#attackers-with-33-stake\">more than 1/3</a> of the stake can delay <a href=\"https://eth2book.info/capella/part2/consensus/casper_ffg/\">finality</a>, an attacker holding more than 1/2 can control the <a href=\"https://eth2book.info/capella/part2/consensus/lmd_ghost/\">fork choice</a>, and an attacker holding <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attack-and-defense/#attackers-with-66-stake\">more than 2/3</a> of the stake can finalize the chain. Each of these attacks would cause severe disruption, but comes at a great potential cost to an attacker. In the case of a delay to finality, the attacker is subjected to an <a href=\"https://eth2book.info/capella/part2/incentives/inactivity/\">inactivity leak</a>. The cost of causing loss of finality for some specific amount of time in some specific way scales linearly with the total deposit size, and <a href=\"https://eth2book.info/capella/part2/incentives/inactivity/#mathematics\">quadratically</a> with time. An offline validator leaks around half their ETH in a little less than three weeks during an inactivity leak. A complete cost analysis for causing loss of finality (and other attacks) also needs to account for price movements on the ETH that an attacker necessarily must control. An attacker may both lose ETH and see the value of any ETH they still retain diminish—if the attack causes real damage to Ethereum. For attacks made possible by holding more than 1/2 or 2/3 of the stake, it is a natural assumption that the <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attack-and-defense/#people-the-last-line-of-defense\">social layer would intervene</a>. The ultimate recourse would then be to burn some or all of the attacker’s stake.</p>\n<p>When it comes to attacks from a smaller stake, there are <a href=\"https://mirror.xyz/jmcook.eth/YqHargbVWVNRQqQpVpzrqEQ8IqwNUJDIpwRP7SS5FXs\">several reorg attacks</a> and minority discouragement attacks (Section 5.3) to take into consideration. Many of these attacks also depend on the proportion of the stake held by an attacker (i.e., holding 25 % of the stake opens up more avenues than holding 0.1 %). From this brief review, it becomes evident that the quantity of stake cannot be allowed to become too small, because the cost of causing severe disruption to Ethereum would then not match the damage done. Table 2 denotes the cost of 1/3, 1/2 and 2/3 of the stake at a token price of $3000 under a deposit size of 14M ETH (the deposit size at The Merge), 24M ETH (20 % of the stake), and 30M ETH (close to the current deposit size).</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th>1/3</th>\n<th style=\"text-align:center\">1/2</th>\n<th style=\"text-align:center\">2/3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>14M</strong></td>\n<td>$14B</td>\n<td style=\"text-align:center\">$21B</td>\n<td style=\"text-align:center\">$28B</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>24M</strong></td>\n<td>$24B</td>\n<td style=\"text-align:center\">$36B</td>\n<td style=\"text-align:center\">$48B</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>30M</strong></td>\n<td>$30B</td>\n<td style=\"text-align:center\">$45B</td>\n<td style=\"text-align:center\">$60B</td>\n</tr>\n</tbody>\n</table>\n</div><p><strong>Table 2.</strong> Value at risk for the critical proportions 1/3, 1/2 and 2/3 of the stake at a token price of $3000 across a few relevant deposit sizes.</p>\n<p>While present fiat-denominated costs of potential attacks at various deposit sizes are interesting to review, Ethereum’s economic security will in the long term inherently be linked to the ability of ETH to retain its value. A holistic perspective is therefore important also when considering economic security. This is underscored by reflecting on the early days of Ethereum, when the ETH token was much less valuable. Eight years ago, In May 2016, <a href=\"https://blog.ethereum.org/2016/05/09/on-settlement-finality\">Buterin deliberated on</a> the value that Ethereum can and cannot secure at a deposit ratio of <span class=\"math\">d=0.3</span>. At the time, the market cap of the ETH token was roughly 500 times lower than today, and the economic security that Ethereum could offer was therefore limited. Increasing the deposit ratio from 0.3 to 0.6 would only increase the value of 1/3 of the stake from $70M to $140M. This highlights that once the deposit ratio has risen above insignificant levels, it will ultimately be Ethereum’s role in the world economy, and the ether’s role in the Ethereum economy, that determines the economic security. Insights from all sections of this post, including the forthcoming Section 6.4, must thus be considered when settling on a suitable deposit ratio. This is a complex task that cannot be objectively formalized. Note in particular that the level of the staking yield—when considered in isolation—will not be a determinant of the value of the ETH token and thus Ethereum’s economic security, as the yield comes from newly minted tokens, directly diluting holders.</p>\n<p>There comes a point where the <a href=\"https://www.reddit.com/r/ethereum/comments/14vpyb3/comment/jro1739/\">marginal increase in security</a> from adding another validator brings less utility than the utility loss stemming from the numerous downsides of excessive issuance previously outlined. This point hints at a desirable deposit ratio. Justin Drake <a href=\"https://www.reddit.com/r/ethereum/comments/191kke6/comment/kh79gh1\">suggested</a> that <span class=\"math\">d=0.25</span> (30M ETH) is appropriate in a recent AMA on Reddit. Vitalik Buterin concurred, <a href=\"https://www.reddit.com/r/ethereum/comments/191kke6/comment/kh7do9k/\">elaborating</a> on factors influencing the broader composition of the staking set along the lines of Section 4.3, but also added a personal note of finding <span class=\"math\">d=0.125</span> (15M ETH) fine. As the quantity of stake grows, the prospects for high economic security in the long term gradually begin to diminish. It seems perfectly reasonable to argue that Ethereum would have higher economic security twenty years from now with a reward curve that sees the deposit ratio settle on <span class=\"math\">d=0.25</span> than at <span class=\"math\">d=0.75</span>—as long as the composition of the staking set remains viable. When the deposit ratio grows beyond certain limits, even short-term security starts to degrade, in line with the reasoning in Section 2.2. The social layer may lose its neutrality and credibility as the ultimate arbitrator against attacks from dominant SSPs. At the other end, it also seems reasonable to ensure that the deposit size does not fall below 14M ETH, which was the prevailing size at The Merge (or more accurately, that the deposit ratio does not fall below <span class=\"math\">d\\approx0.12</span>). Such a lower boundary at least ensures that Ethereum never ventures into unknown territory in terms of stake participation (as previously discussed, it is impossible to ensure that the value of the stake is kept at some specific level relative to the value secured).</p>\n<p>The discussion of economic security has underscored the complexity involved in determining the correct deposit ratio. As a matter of fact, due to uncertainty regarding several key variables, there is not one specific ratio that always maximizes overall utility. The most suitable deposit ratio will arguably vary with the shape of the supply curve and the cost of providing a certain level of security. If the implied costs associated with staking are higher (as captured in Figure 1), then it seems reasonable to have a slightly lower deposit ratio than if the cost is lower. This is one of the reasons for using a reward curve in the first place—it allows Ethereum to adjust the security level based on the price of that security. Ethereum should thus target a <a href=\"https://x.com/weboftrees/status/1585641193982918656\">deposit ratio range</a>, which can be rather broad, allowing the supply curve to influence the equilibrium quantity of stake. The proposed reward curve—in the author’s view and under full implementation—balances the many needs of Ethereum, including viable economic security for the short term and possibly the long term (see Section 6.3 for additional nuances).</p>\n<p>Table 3 shows the yield that the protocol will provide at the previously discussed deposit sizes, given the current level of REV. In addition, the outcome if the REV was to completely vanish is also provided. Note that if Ethereum ever adopts MEV burn and there is a clear need for it, the associated hard fork can apply dedicated adjustments for re-calibrating issuance. On the other hand, should the supply curve fall over the next few years and there is an agreement within the community, then the introduction of MEV burn can be conceived as the last step in the moderation of the quantity staked.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">A: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n<th style=\"text-align:center\">B: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n<th style=\"text-align:center\">C: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>14M</strong></td>\n<td style=\"text-align:center\">3.14 %</td>\n<td style=\"text-align:center\">5.28 %</td>\n<td style=\"text-align:center\">2.83 %</td>\n<td style=\"text-align:center\">4.97 %</td>\n<td style=\"text-align:center\">2.22 %</td>\n<td style=\"text-align:center\">4.37 %</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>24M</strong></td>\n<td style=\"text-align:center\">1.98 %</td>\n<td style=\"text-align:center\">3.23 %</td>\n<td style=\"text-align:center\">1.88 %</td>\n<td style=\"text-align:center\">3.13 %</td>\n<td style=\"text-align:center\">1.70 %</td>\n<td style=\"text-align:center\">2.95 %</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>30M</strong></td>\n<td style=\"text-align:center\">1.60 %</td>\n<td style=\"text-align:center\">2.60 %</td>\n<td style=\"text-align:center\">1.58 %</td>\n<td style=\"text-align:center\">2.58 %</td>\n<td style=\"text-align:center\">1.52 %</td>\n<td style=\"text-align:center\">2.52 %</td>\n</tr>\n</tbody>\n</table>\n</div><p><strong>Table 3.</strong> Staking yield at various relevant deposit sizes under the full reduction in issuance.</p>\n<p>The first column indicates that the quantity staked will stay at healthy levels under Option A, even without REV. It seems reasonable to assume that at least 24M ETH would still be staked at a 2 % yield. Certainly, 14M ETH would still be staked if a 3.1 % yield is offered. The lower yield under Option C can be noted, and is one of the reasons why a base reward factor below <span class=\"math\">F=32</span> is undesirable from a security perspective for this option. Table 4 instead shows the outcome under a graduated approach.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:center\">Ag: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n<th style=\"text-align:center\">Bg: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n<th style=\"text-align:center\">Cg: <span class=\"math\">y_i</span></th>\n<th style=\"text-align:center\"><span class=\"math\">y_i+y_v</span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>14M</strong></td>\n<td style=\"text-align:center\">3.68 %</td>\n<td style=\"text-align:center\">5.82 %</td>\n<td style=\"text-align:center\">3.53 %</td>\n<td style=\"text-align:center\">5.67 %</td>\n<td style=\"text-align:center\">3.06 %</td>\n<td style=\"text-align:center\">5.20 %</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>24M</strong></td>\n<td style=\"text-align:center\">2.50 %</td>\n<td style=\"text-align:center\">3.75 %</td>\n<td style=\"text-align:center\">2.46 %</td>\n<td style=\"text-align:center\">3.70 %</td>\n<td style=\"text-align:center\">2.33 %</td>\n<td style=\"text-align:center\">3.58 %</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>30M</strong></td>\n<td style=\"text-align:center\">2.10 %</td>\n<td style=\"text-align:center\">3.10 %</td>\n<td style=\"text-align:center\">2.10 %</td>\n<td style=\"text-align:center\">3.10 %</td>\n<td style=\"text-align:center\">2.09 %</td>\n<td style=\"text-align:center\">3.09 %</td>\n</tr>\n</tbody>\n</table>\n</div><p><strong>Table 4.</strong> Staking yield at various relevant deposit sizes under a graduated approach.</p>\n<h3><a name=\"h-52-consensus-incentives-31\" class=\"anchor\" href=\"https://ethresear.ch#h-52-consensus-incentives-31\"></a>5.2 Consensus incentives</h3>\n<p>A reduction in issuance will alter the balance between the various roles that consensus participants are assigned to. In particular, the proposer will attain a larger proportion of all rewards, and this may <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-3-consensus-incentives-11\">threaten consensus</a> stability. If the yield provided for attestation duties <span class=\"math\">y_a</span> becomes a small proportion, <span class=\"math\">y_a/y</span>, of the staking yield, stakers can be expected to pursue irregular and adverse activities when profit-maximizing, and the consensus process may break down. They may as an example even <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/2\">stop attesting entirely to avoid the risk of slashing</a>. The proposed reward curve has been designed to give attesters at least half of the rewards at any deposit size under the current level of REV, as illustrated in Figure 15. Should the REV rise substantially, the penalty for a missed target vote (and potentially source vote) can be <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/2\">raised</a>, to give proper incentives for performing attester duties correctly.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/b/b2ece383e5859173dcd215d2c254e1b0f45dfb5d.png\" data-download-href=\"https://ethresear.ch/uploads/default/b2ece383e5859173dcd215d2c254e1b0f45dfb5d\" title=\"Figure 15\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/b/b2ece383e5859173dcd215d2c254e1b0f45dfb5d_2_690x432.png\" alt=\"Figure 15\" data-base62-sha1=\"pwQwkFvl5FwUw7ZWfoP2HsxkVAh\" width=\"690\" height=\"432\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/b/b2ece383e5859173dcd215d2c254e1b0f45dfb5d_2_690x432.png, https://ethresear.ch/uploads/default/optimized/2X/b/b2ece383e5859173dcd215d2c254e1b0f45dfb5d_2_1035x648.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/b/b2ece383e5859173dcd215d2c254e1b0f45dfb5d_2_1380x864.png 2x\" data-dominant-color=\"FAFAF9\"></a></div><p></p>\n<p><strong>Figure 15.</strong> Proportion of the staking yield provided for attestations (<span class=\"math\">y_a/y</span>) under 300k ETH REV/year for the analyzed options (graduated approach in dashed lines).</p>\n<h3><a name=\"h-53-discouragement-attacks-32\" class=\"anchor\" href=\"https://ethresear.ch#h-53-discouragement-attacks-32\"></a>5.3 Discouragement attacks</h3>\n<p>A discouragement attack is a malicious action against honest consensus participants of a blockchain, potentially at a cost for the attacker, to profit from the reduced competition for the remaining rewards. The traditional scenario <a href=\"https://github.com/ethereum/research/blob/09d9f34042262c8fb436171786ed6c62e1f57247/papers/discouragement/discouragement.pdf\">outlined by Buterin</a> involves a majority attack, but there are currently a few possible <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/11\">minority discouragement attacks</a> against Ethereum. These include the censorship of sync-committee attestations, withheld attestations during an inactivity leak, and censorship of the head and potentially source vote (picking up stray votes in subsequent slots). Withheld attestations during an inactivity leak are a special case, because the attack is directly profitable. Since the victim loses out on seven times more ETH than the attacker and also receives a penalty of equal size as its loss, censorship of sync-committee attestations has a griefing factor of <span class=\"math\">G=14</span>.</p>\n<p>The “<span class=\"math\">p</span>-elasticity”—capturing the negated inverse point-wise yield-elasticity of demand across a reward curve—is a relevant macro measure for examining its susceptibility to discouragement attacks. If the <span class=\"math\">p</span>-elasticity is high, then attacks become (more) profitable. Specifically, for a small epsilon attack, the condition for profitability is</p>\n<div class=\"math\">\na+Ga-1 &gt; \\frac{q}{p},\n</div>\n<p>where <span class=\"math\">G</span> is the griefing factor, <span class=\"math\">a</span> the proportion of stake held by an attacker, and <span class=\"math\">q</span> the point-wise inverse yield-elasticity of supply. This simplified expression does not say anything about the level of the profits, which may very well be small. The margin of this post is too narrow for a complete exposition of this complex topic, which is forthcoming. The purpose of this simplification is to encapsulate that as <span class=\"math\">p</span> rises, the required griefing factor or proportion of stake held by an attacker falls. The <span class=\"math\">p_i</span>-elasticity computed only across issuance yield can be determined by relating the percentage change in deposit size <span class=\"math\">\\Delta D/D</span> to a percentage change in issuance yield across the demand curve <span class=\"math\">\\Delta y_i/y_i</span></p>\n<div class=\"math\">\np_i = -\\frac{\\Delta y_i/y_i}{\\Delta D/D}.\n</div>\n<p>The <span class=\"math\">p_i</span>-elasticity can be used as a reference point when evaluating reward curves, because if it is modest, then the <span class=\"math\">p</span>-elasticity will be modest regardless of the size of the REV. Figure 16 plots <span class=\"math\">p_i</span>-elasticity across deposit size. For Option A, the <span class=\"math\">p_i</span>-elasticity rises smoothly, reaching a maximum slightly below 1.3 at 120M ETH staked. Lower is better from the perspective of discouragement attacks and cartelization attacks (described in Section 5.4), but a bit above 1 should be perfectly acceptable). Option B has <span class=\"math\">p_i&lt;1</span> since issuance never falls and Option C is identical to the current reward curve across deposit size. Note that for reward curves where the yield goes negative, the <span class=\"math\">p_i</span>-elasticity (and eventually the <span class=\"math\">p</span>-elasticity if the yield continues falling) goes to infinity (see <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-54-additional-properties-under-consideration-22\">Figure 40 in a previous post</a> showing the <span class=\"math\">p_i</span>-elasticity for approaches relying on economic capping). The equilibrium <span class=\"math\">p</span>-elasticity, and the profitability of discouragement attacks, will however also always depend on the supply curve.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/8/887ae886834a019a14ec9ba8f95528f0788b8063.png\" data-download-href=\"https://ethresear.ch/uploads/default/887ae886834a019a14ec9ba8f95528f0788b8063\" title=\"Figure 16\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/8/887ae886834a019a14ec9ba8f95528f0788b8063_2_690x418.png\" alt=\"Figure 16\" data-base62-sha1=\"jtmgtKHR0sO1pkCHUK07VcLKq55\" width=\"690\" height=\"418\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/8/887ae886834a019a14ec9ba8f95528f0788b8063_2_690x418.png, https://ethresear.ch/uploads/default/optimized/2X/8/887ae886834a019a14ec9ba8f95528f0788b8063_2_1035x627.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/8/887ae886834a019a14ec9ba8f95528f0788b8063_2_1380x836.png 2x\"></a></div><p></p>\n<p><strong>Figure 16.</strong> The point-wise negated inverse yield-elasticity of demand (<span class=\"math\">p_i</span>-elasticity) for the three reward curves examined in this post (lower is better).</p>\n<p>The best defense against a minority discouragement attack is to have a well-balanced consensus mechanism. Ethereum should therefore in the future fix the current incentives that allow for infinite profit margins during an inactivity leak and for attacks with <span class=\"math\">G=14</span>. The second best defense, particularly useful against larger attackers (including majorities), is some form of social intervention, as discussed in Section 5.1. The prospect of social intervention can make the risk-reward ratio rather unfavorable for discouragement attacks. The immediate gain is rather low (in fact negative in most cases), and profits vary with frictions in the decision to stake or unstake. Finally, note that the prospect of being able to rely on social intervention in the first place could also depend on quantity staked, as outlined in Section 2.2, making the problem multi-dimensional. To balance the various aspects discussed in this subsection, it is desirable with a reward curve that gives appropriate guarantees for a sufficient quantity staked without providing excessive levels of issuance, and then reduces the incentive to stake across a broad range, for example by gradually attenuating issuance. This was one of the design rationales for the proposed reward curve (Option A).</p>\n<h3><a name=\"h-54-cartelization-attacks-33\" class=\"anchor\" href=\"https://ethresear.ch#h-54-cartelization-attacks-33\"></a>5.4 Cartelization attacks</h3>\n<p>Cartelization attacks are hypothetical constructs related to and overlapping with discouragement attacks, that can differ in rationalization and execution. They will here be presented briefly. A cartelization attack consists of SSPs working together to try to reduce quantity staked both among themselves and others. When issuance increases with a reduction in quantity staked (<span class=\"math\">p_i&gt;1</span>), all stakers could try to agree to reduce their stake, and everyone would be better off. This framing can provide a suitable backdrop for convincing the social layer to not interfere when a staking cartel tries to inhibit Ethereum’s permissionlessness. Ideally for the cartel, it would be able to rely on some permissioned revenue outside of the consensus mechanism that a majority can extract to incentivize initial participation. However, if insufficient (in particular once the yield has risen), the cartel could resort to more sinister actions within the consensus mechanism. The actions need not completely break consensus formation to be effective. Modest discouragement attacks against “strikebreakers” to ensure that such entities “stop reducing everyone’s rewards” could be sufficient.</p>\n<p>If the reward curve is too deliberate about targeting some specific quantity staked, but still provides high issuance at lower quantities, then stakers may face a situation where cartelization and a reduction in quantity staked could lead to multiple times higher rewards for everyone. The proposed reward curve (Option A) incorporates a sufficiently small issuance reduction as <span class=\"math\">D</span> rises, so that the rationale for executing a cartelization attack is minimal/non-existent.</p>\n<h2><a name=\"h-6-conclusion-and-discussion-34\" class=\"anchor\" href=\"https://ethresear.ch#h-6-conclusion-and-discussion-34\"></a>6. Conclusion and discussion</h2>\n<h3><a name=\"h-61-factors-influencing-the-optimal-shape-of-the-reward-curve-35\" class=\"anchor\" href=\"https://ethresear.ch#h-61-factors-influencing-the-optimal-shape-of-the-reward-curve-35\"></a>6.1 Factors influencing the optimal shape of the reward curve</h3>\n<p>Ethereum must weigh many factors when deciding on a reward curve. A low issuance level:</p>\n<ul>\n<li>improves aggregate utility by not compelling users to incur unnecessary costs. This is of fundamental importance, and it is the reason for why every ETH holder can benefit from a reduced issuance level.</li>\n<li>keeps the quantity staked moderate. This reduces:\n<ul>\n<li>the risks posed by a compromised social layer,</li>\n<li>network externalities that entrench dominant SSPs,</li>\n<li>economies of scale of dominant SSPs.</li>\n</ul>\n</li>\n</ul>\n<p>However, an excessively low issuance level might sideline solo (home) stakers down the line, if the yield is reduced so much that staking on a reasonably efficient setup becomes unprofitable. Retention of a viable proportion of solo stakers will hinge on the distribution of reservation yields among all stakers, accounting for scenarios where initial exogenous incentives for solo staking (e.g., airdrops) have dried out and initial hardware investments have reached their depreciation horizon.</p>\n<p>From a security perspective, it is beneficial to keep the yield rather high at low quantities staked to ensure a sufficient quantity of stake and economic security. But to protect against discouragement attacks and cartelization attacks, it is also beneficial if issuance does not then fall too sharply at any point, i.e., it is best if the <span class=\"math\">p_i</span>-elasticity is kept rather moderate. This therefore also becomes a balancing act, where it is best that issuance is not too high and not too low at any deposit size.</p>\n<p>Additional complexities arise from MEV captured by block proposers:</p>\n<ul>\n<li>It raises the expected yield, so a lower issuance is required to enforce the same quantity staked.</li>\n<li>But issuance cannot be reduced too much without compromising consensus incentives under the current specification. Resolutions such as a staking fee could further debilitate solo staking, relative to delegated staking.</li>\n<li>It raises variability in the expected equilibrium yield at a macro level, complicating the effort to achieve any specific desirable equilibrium.</li>\n<li>It raises variability in the expected yield of individual solo stakers, leading to some utility degradation if the issuance is set too low.</li>\n</ul>\n<h3><a name=\"h-62-the-optimal-reward-curve-36\" class=\"anchor\" href=\"https://ethresear.ch#h-62-the-optimal-reward-curve-36\"></a>6.2 The optimal reward curve</h3>\n<h4><a name=\"h-621-option-a-the-best-alternative-for-ethereum-37\" class=\"anchor\" href=\"https://ethresear.ch#h-621-option-a-the-best-alternative-for-ethereum-37\"></a>6.2.1 Option A – the best alternative for Ethereum</h4>\n<p>The candidate reward curve, Option A, was designed to effectively moderate issuance while allowing Ethereum to retain proper consensus incentives and keep solo-staking variability acceptable. Section 2.1 highlighted the undeniable benefits of minimum viable issuance—the reduction in the implied cost to Ethereum’s users and the associated aggregate utility gain, which may very well make everyone better off under equilibrium. Section 2.2 further strengthened the case by deliberating on the clear benefits of a neutral social layer that can ensure that Ethereum operates under the intended consensus process. Option A will best attain these benefits, and it was in a <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448\">previous study</a> selected over even stricter issuance policies because of its balanced approach to various relevant trade-offs. It is not clear which issuance level that will maximize the proportion of solo stakers (and the outcome can vary with time scale considered), with arguments in both directions reviewed in Section 4.2. Importantly, a low quantity of stake is not strictly forced, ensuring that the cost of running a staking node will not be prohibitively high relative to the yield. This ultimately allows variety in preferences and circumstances between stakers to take a more central role in shaping the composition of the staking set. The proposed reward curve also ensures economic security in both the short run and long run while being sufficiently resilient against discouragement attacks and cartelization attacks, retaining an intact social layer by a gradual attenuation of issuance with modest <span class=\"math\">p_i</span>-elasticities.</p>\n<p>Another benefit of Option A is its ease of interpretation: a single adjustable variable defines both the peak issuance point as well as the point where issuance is halved relative to the current reward curve. As noted in Section 2.3, compromising the predictive capacity of economic agents undermines welfare. It is also desirable to accommodates reevaluation against uncertain future stake growth and solo-staking retention scenarios, in particular in light of a potential future MEV-burn implementation.  Therefore, a graduated reduction of issuance is preferable when possible, allowing for gradual adaptation.</p>\n<p><em>In conclusion, the author believes that a holistic approach to issuance policy makes Option A—the candidate reward curve—the most suitable reward curve for Ethereum:</em></p>\n<div class=\"math\">\ny_i=\\frac{cF}{\\sqrt{D}(1+D/k)}.\n</div>\n<p>The full envisioned reduction constitutes <span class=\"math\">k=2^{25}</span>.  In the author’s view, a graduated approach with <span class=\"math\">k=2^{26}</span> is preferable. This is still a sufficiently substantial improvement to warrant the multifaceted governance process associated with a change to issuance policy, and would position Ethereum much better going forward. From a security perspective, such a change would not pose risks, and Ethereum could thus proceed with it whenever the governance process has taken its course. The exact setting should be determined during that governance process, and will be based on circumstances that may evolve during the process. Alternatives such as setting <span class=\"math\">k</span> to <span class=\"math\">2^{25}</span>, <span class=\"math\">2^{27}</span> or <span class=\"math\">10^{8}</span> cannot definitely be ruled out at this point.</p>\n<h4><a name=\"h-622-option-c-the-backup-38\" class=\"anchor\" href=\"https://ethresear.ch#h-622-option-c-the-backup-38\"></a>6.2.2 Option C – the backup</h4>\n<p>The second best option is to reduce the base reward factor, i.e., Option C. Two things can be noted: (1) the consensus specification change is even more minimal, (2) the guaranteed yield for (solo) stakers is higher. Of course, to many, (2) would instead be considered a drawback, since it will lead to a higher equilibrium quantity of stake, making problematic outcomes in this regard much more likely as compared with Option A. Even if the endgame is Option A, the graduated first step can still be taken with Option C. But it would in the author’s be preferable to proceed with Option A, giving the community a clear path and roadmap. Option B, perhaps also with <span class=\"math\">F=64</span>, is a compromise between A and C, and can be called upon if agreement cannot be made between them.</p>\n<h3><a name=\"h-63-the-unknown-endgame-39\" class=\"anchor\" href=\"https://ethresear.ch#h-63-the-unknown-endgame-39\"></a>6.3 The unknown endgame</h3>\n<p>The optimal “endgame” of Ethereum staking economics is at this point unknown, and will remain so, probably for at least another decade. It depends on many aspects that have currently not been settled, one of them being the specification of the endgame consensus mechanism itself.</p>\n<p>There are however reasons to believe that the proposed reward curve can be viable for a long time, perhaps forever. For example, consider the scenario where the community feels that it is important to temper the quantity staked. The full reduction can then be implemented with <span class=\"math\">k=2^{25}</span> in the not-too-distant future, and kept when instigating MEV burn. The other two alternatives are to go back to <span class=\"math\">k=2^{26}</span> once MEV burn can be implemented, or to stop already at <span class=\"math\">k=2^{26}</span>: if MEV burn turns out to be viable and the community is satisfied with that as the second step. At <span class=\"math\">k=2^{25}</span> and with MEV burn, the staking yield would indeed become rather low (see the lime-colored curve in Figure 33 of <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-52-exploration-of-alternative-reward-curves-20\">this post</a>). As an example, the issuance yield is 0.77 % at 60M ETH staked. When accounting for risks (slashing, smart contracts, governance, etc.), and other costs of staking, it seems rather unlikely that the quantity staked would be pushed above 60M ETH at such a low yield. Yet, even if this turns out to hold true, it should not be interpreted as arguing that the proposed reward curve necessarily <em>must</em> remain in place indefinitely—just that it seems rather suitable as an endgame and offers clear improvement relative to the current reward curve. The optimal quantity staked ultimately depends on the shape of the supply curve (representing possible attainable yield–quantity combinations), and how the relative importance of the various trade-offs that Ethereum balances will evolve in the future.</p>\n<p>There is one thing that certainly remains for the endgame even after adopting the proposed reward curve. The long-run staking equilibrium under reward curves that adapt to <span class=\"math\">D</span> instead of <span class=\"math\">d</span> is ultimately also influenced by the <a href=\"https://ethresear.ch/t/circulating-supply-equilibrium-for-ethereum-and-minimum-viable-issuance-during-the-proof-of-stake-era/10954\">circulating supply equilibrium</a>, since the circulating supply will <a href=\"https://www.youtube.com/watch?v=LtEMabS0Oas&amp;t=1187s\">drift</a> to <a href=\"https://twitter.com/weboftrees/status/1710725744651825281\">balance</a> supply, demand, and protocol income. Therefore, Ethereum should transition to using <span class=\"math\">d</span> in the equation for the reward curve, which can simply be done by <a href=\"https://x.com/weboftrees/status/1710728179260731715\">swapping in the circulating supply</a>, once it <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751#how-to-set-the-target-in-relative-staking-ratio-instead-of-absolute-fixed-eth-amount-terms-20\">begins to be tracked</a>.</p>\n<p>The benefits of not issuing more tokens than what is <a href=\"https://notes.ethereum.org/@anderselowsson/MinimumViableIssuance\">strictly needed for security</a> are indeed clear and substantial. Schwarz-Shilling and Dietrich <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751\">present benefits and argue</a> for an endgame of targeting a low quantity staked, potentially through <a href=\"https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-deposits\">economic capping</a> (a yield that goes to negative infinity when too much ETH is staked). When it comes to solo staking, the analysis looks at a hypothetical <a href=\"https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751#implications-of-targeting-14\">scenario</a> where the reservation yield is 1.5 % at 30M ETH staked and 2 % at 120M ETH staked. Under a flat supply curve with high reservation yields, stricter targeting (a steeper reward curve) at low quantities staked indeed seems rather straightforward. Solo staking will with such supply curves always be viable, regardless of the shape of the reward curve. Under the supply curve of Figure 12, a strict targeting approach could instead force outcomes that may be unfavorable to the composition of the staking set. Priors regarding the possible shapes of the supply curve here matter. Discouragement attacks and cartelization attacks become more <a href=\"https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-deposits\">viable with targeting approaches</a> where the equilibrium <span class=\"math\">p</span>-elasticity is pushed up too high. To solo stakers, uncertainty itself regarding if the yield will go negative may make them hold off on investing in hardware. Indeed, certainty pertaining to either yield or quantity staked is always substituted via the shape of the reward curve. A flatter demand curve will smooth out fluctuations in yield, and can therefore decrease the equilibrium yield, ceteris paribus (at the same quantity staked), since economic agents may be willing to substitute lower variability for lower returns. But a steeper demand curve instead gives smaller fluctuations in quantity staked, and better assurances concerning its maximum level. The author has gradually changed position, from favoring strict deposit ratio targeting in <a href=\"https://ethresear.ch/t/circulating-supply-equilibrium-for-ethereum-and-minimum-viable-issuance-during-the-proof-of-stake-era/10954\">2021</a>, to gradually focusing on targeting a desirable deposit ratio range (where the range of plausible equilibria can be rather broad to balance the trade-offs that exist), settling on the proposed reward curve as the correct mechanism for balancing current circumstances pertaining to MEV, with the implementation of MEV burn allowing the same reward curve to potentially transition into a viable endgame policy. Yet, it is important to remain open to changes when new information comes in over the next decade, updating priors, and reflecting on evolving trade-offs.</p>\n<p>Finally note that there is no direct monetary purpose for staking when the <a href=\"https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448#h-21-supply-and-demand-9\">endogenous yield is 0</a> or negative. Therefore, a negative issuance yield should only ever be needed when MEV or, e.g., rewards for <a href=\"https://notes.ethereum.org/WLuNFaliQiqw7Zhd-7AnmQ\">preconfirmations</a> befall the proposer. Thus, in all current scenarios with a negative issuance yield, unpooled solo stakers would be forced to accept negative payouts each epoch while waiting on proposer assignment, while delegating stakers could reap small positive rewards at a regular basis. When it comes to negative issuance yields, the most interesting option would be very gradual transitions at particularly undesirable levels of stake, e.g., subtracting <span class=\"math\">(D/k)^p</span> from current constructions for <span class=\"math\">y_i</span>, with <span class=\"math\">p</span> set to 0.5, 1 or 2. Reward curves asymptotically approaching 0 are in this case however perhaps more viable as an option. The optimal shape will ultimately depend on how the consensus mechanism itself develops (e.g., the role of solo stakers). Constructions with an infinitely negative issuance yield (which may technically be unreachable due to the churn limit) will however bring even more uncertainty to stakers and may bring unneeded complexity into the protocol design space.</p>\n<p>Adding the dimension of <em>time</em> to the dimension of <em>quantity</em> is also worthy of consideration. Under a time–quantity policy, the reward curve is kept moderate in terms of elasticity, but the whole curve is allowed to <a href=\"https://x.com/weboftrees/status/1710728448543523219\">gradually adapt</a> to changes in the supply curve, implied by the equilibrium. Thus, under the proposed reward curve, <span class=\"math\">k</span> drifts when <span class=\"math\">d</span> ventures off desirable levels, with effects taking place at a time scale of decades. This would allow Ethereum to account for the supply curve when setting the reward curve. The mechanism would smooth out fluctuations in yield, and the delayed adjustment could make some discouragement attacks and cartelization attacks less attractive. Certain limits could be placed on how small <span class=\"math\">k</span> can become with this strategy, to avoid idiosyncratic outcomes. There is also a distinction here between automatically increasing the yield (opening up for discouragement attacks) and decreasing it (opening up for the familiar issues associated with low yields). Interestingly, while the protocol may not be able to determine who is at fault in a discouragement attack, it can still determine that it is in fact under attack, providing an avenue for safeguards through conditional logic.</p>\n<h3><a name=\"h-64-the-proportion-that-matters-to-eth-holders-40\" class=\"anchor\" href=\"https://ethresear.ch#h-64-the-proportion-that-matters-to-eth-holders-40\"></a>6.4 The proportion that matters to ETH holders</h3>\n<p>The insights presented in Sections 2.1, 2.2, and 4 have implications for Ethereum’s users, irrespective of if they hold significant amounts of ETH. Having a viable social layer—uncorrupted by any SSP—ultimately matters to credible neutrality. Having solo stakers matters, and having many viable options for delegated staking matters. These things also matter specifically to the ETH token holder. It is ultimately not the “proportional yield”, but rather the proportion of the world economy powered by Ethereum that will affect the ETH token holder the most, including the staker. If an issuance policy degrades Ethereum, there is little point in having maximized <span class=\"math\">y_p</span>, certainly not to users that do not hold ETH, and not even to ETH token holders, because the native token of a blockchain that has been degraded is not as valuable. The <em>real</em> “real yield” incorporates the change in value of the underlying ETH—including any staking yield—relative to a relevant consumer price index. However, it just so happens that it is indeed very useful to have sound native money in an economic system. And it so happens that the best sound money will not encumber its users to research the reliability of various SSPs, track staking income and see it taxed, or risk being wiped out in a slashing event or other failure.</p>\n<h3><a name=\"h-65-a-note-on-bounded-rationality-and-yield-41\" class=\"anchor\" href=\"https://ethresear.ch#h-65-a-note-on-bounded-rationality-and-yield-41\"></a>6.5 A note on bounded rationality and yield</h3>\n<p>The notion of <a href=\"https://en.wikipedia.org/wiki/Behavioral_economics#Bounded_rationality\">bounded rationality</a> helps to explain why some users may prefer a scenario with lower <span class=\"math\">y_p</span>, where the yield is raised but the supply inflation rate (which users have a harder time to track) rises even more. Behavioral economics can be helpful in this way for explaining why some economic agents act irrationally, perhaps for lack of education or time to deliberate on a topic. Recently, a twisted argument relying on bounded rationality has appeared in the writings of several representatives of SSPs or investors thereof. In essence, proponents suggest that Ethereum should harness people’s bounded understanding of yield, and keep it high to trick users into thinking that they gain something, when they do in fact not. Instead of educating people on these matters, user utility should be degraded for some short-term gain, which is unlikely to materialize. Such strategies must be avoided.</p>\n<h3><a name=\"h-66-next-step-42\" class=\"anchor\" href=\"https://ethresear.ch#h-66-next-step-42\"></a>6.6 Next step</h3>\n<p>The author hopes that this post has convinced the community of the benefits of adjusting the issuance policy, and is available for any questions you may have. The post will act as the long-form reference for the EIP on the proposed reward curve—Option A. Making the full reduction in a single hard fork seems unadvisable, and the outlined graduated approach favorable. That first step brings essentially no downsides, will improve Ethereum substantially, and if not the final step it is still a step in the right direction.</p>\n            <p><small>5 posts - 4 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171\">Read full topic</a></p>","link":"https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171","pubDate":"Mon, 01 Apr 2024 08:39:26 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19171"},"source":{"@url":"https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171.rss","#text":"Reward curve with tempered issuance: EIP research post"}},{"title":"Reduced Attestation Format for gossiping attestations","dc:creator":"Giulio2002","category":"Networking","description":"<p>At the current state, even after Deneb and the introduction of blobs, Attestations are responsible for 90% of the traffic on the Consensus Layer’s gossip network. Right now, the <code>Attestation</code> propagation format is the same as the one used during internal operation within the Consensus Client. which is as follows:</p>\n<pre><code class=\"lang-python\">class Attestation(Container):\n    aggregation_bits: Bitlist[MAX_VALIDATORS_PER_COMMITTEE]\n    data: AttestationData\n    signature: BLSSignature\n</code></pre>\n<p>where AttestationData is just:</p>\n<pre><code class=\"lang-python\">class AttestationData(Container):\n    slot: Slot\n    index: CommitteeIndex\n    # LMD GHOST vote\n    beacon_block_root: Root\n    # FFG vote\n    source: Checkpoint\n    target: Checkpoint\n```.\n\nThis format totals a maximum of 256 bytes for each attestation (assuming that `len(aggregation_bits)=32`).\n\nHowever, it could be possible to reduce this size by at least a 15ish% by defining a different format for `AttestationData`, which could be as follows:\n\n```python\nclass NetworkAttestationData(Container):\n    slot: Slot\n    index: CommitteeIndex\n    # LMD GHOST vote\n    beacon_block_root: Root\n    # FFG vote\n    source_digest: BytesVector8\n    target_digest: BytesVector8\n</code></pre>\n<p>where source_digest = source. HashTreeRoot () [0:8] and target_digest = target. HashTreeRoot () [0:8]. This format requires clients to keep track of an internal map of possible <code>CheckpointDigest</code> (<code>BytesVector8</code>) as they sync, and maps them to their equivalent <code>Checkpoint</code>. This reduction would save 64 bytes per attestation which is equivalent to &gt;25ish% of a single attestation. If this is also applied to <code>aggregates and proofs</code>, it should also decrease the bandwidth for the average node as well. Potentially, bandwidth-wise, something like this can allow for a doubling of the current Blob per block. A consideration to make is that perhaps <code>BytesVector8</code> as a digest size might open up for possible collision attacks. However, an attacker needs to do so in the 12 seconds of slot time to create a collision with 2 recent <code>CheckpointDigests</code>. Probably <code>16</code> is a better size for something like this (but I am not a cryptographer). this would also require that at each block, each consensus client would need to generate some digests for some potential future checkpoints as well, e.g., generates 4 checkpoints for block root <code>0xabcd</code> spanning 4 epochs into the future.</p>\n            <p><small>3 posts - 3 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/reduced-attestation-format-for-gossiping-attestations/19157\">Read full topic</a></p>","link":"https://ethresear.ch/t/reduced-attestation-format-for-gossiping-attestations/19157","pubDate":"Sun, 31 Mar 2024 08:18:28 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19157"},"source":{"@url":"https://ethresear.ch/t/reduced-attestation-format-for-gossiping-attestations/19157.rss","#text":"Reduced Attestation Format for gossiping attestations"}},{"title":"Blob Preconfirmations with Inclusion Lists to Mitigate Blob Contention and Censorship","dc:creator":"chrmatt","category":"Economics","description":"<p>Thanks to my collaborators <a class=\"mention\" href=\"https://ethresear.ch/u/murat\">@murat</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/ckartik\">@ckartik</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/evan-kim2028\">@Evan-Kim2028</a>, and <a class=\"mention\" href=\"https://ethresear.ch/u/bemagri\">@bemagri</a>. Further thanks to the ETHGlobal London community for early feedback and in particular Nethermind for awarding a prize at the hackathon for our credible preconfirmation leader auction.</p>\n<h1><a name=\"introduction-1\" class=\"anchor\" href=\"https://ethresear.ch#introduction-1\"></a>Introduction</h1>\n<p>In this post, we describe an out-of-protocol mechanism for blob inclusion preconfirmations. It allows preconfirmation providers to bid in an auction to become the leader for the subsequent slot. The auction winner can then accept bids on blob inclusions and issue preconfirmations to the bidders. The preconfirmed blobs then act as an inclusion list that needs to be respected by all participants. The goals of this design are to enable L2 sequencers and other entities relying on blob inclusion to gain certainty about their inclusion, prevent censorship, and possibly mitigate latency issues of blocks with many blobs in the future. Our out-of-protocol design can be implemented right now and serve as a starting point to measure and understand blob inclusion lists in practice until they are available natively in the Ethereum protocol.</p>\n<p>Given recent issues with blob contention [1,2], we believe it is timely to implement an out-of-protocol solution as the one described here.</p>\n<p>We next provide an overview of the entities involved in the protocol and then describe the protocol in more detail. We then provide more details on the payment and slashing mechanism. We conclude with discussions on the <span class=\"math\">N+1</span> slot design, the leader auction, and how to handle premature blob inclusion.</p>\n<h1><a name=\"actors-2\" class=\"anchor\" href=\"https://ethresear.ch#actors-2\"></a>Actors</h1>\n<p>We assume there is a sidechain (with a faster block time than L1) that is used to settle payments among the protocol participants. This chain in the following is called <em>mev-commit chain</em>.</p>\n<p>The following actors participate in the protocol:</p>\n<ul>\n<li>L1 proposers. We assume a subset of L1 validators opt-in to participate in the protocol and stake a collateral on the mev-commit chain.</li>\n<li>Relays. The opted-in proposers need to exclusively work with relays that participate in the protocol and only forward blocks from builders that also participate in the protocol.</li>\n<li>Preconfirmation providers. These are the actors bidding to become the blob preconfirmation leaders and issue the blob inclusion lists. They could be the proposers themselves, builders, or relays. For this write-up, we assume the relays play the role of preconfirmation providers.</li>\n<li>Preconfirmation bidders. The entities who want blobs to be included in a block, such as L2 sequencers.</li>\n<li>Builders. The builders need to be aware of the blob inclusion lists and include the corresponding blobs in their blocks.</li>\n</ul>\n<h1><a name=\"protocol-description-3\" class=\"anchor\" href=\"https://ethresear.ch#protocol-description-3\"></a>Protocol Description</h1>\n<p>We next describe the protocol execution in more detail. Let <span class=\"math\">N</span> be the current L1 slot and consider preconfirmation bidders want to include blobs in a block by slot <span class=\"math\">N+1</span> (see below for a justification of the one-slot delay).</p>\n<p>The protocol description is divided into three steps. The first is done during slot <span class=\"math\">N</span>, the second at the beginning of slot <span class=\"math\">N+1</span>, and the last one during the rest of slot <span class=\"math\">N+1</span>. See also the figures below for graphical overviews of the corresponding steps.</p>\n<h2><a name=\"protocol-execution-in-slot-n-4\" class=\"anchor\" href=\"https://ethresear.ch#protocol-execution-in-slot-n-4\"></a>Protocol Execution in Slot <span class=\"math\">N</span></h2>\n<ol>\n<li>During L1‘s slot <span class=\"math\">N</span>, preconfirmation bidders send their bids to the providers. A bid contains the hash of the KZG commitment of the blob, the bid amount, and the target slot <span class=\"math\">N+1</span>, and is signed by the bidder.</li>\n<li>Preconfirmation providers collect preconfirmation bids during L1 slot <span class=\"math\">N</span>.</li>\n<li>The relays further submit leader bids for slot <span class=\"math\">N+1</span> to the leader auction.</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/7/78d6d4a75c61c8924502b41d72fa6adfa2853f0f.png\" data-download-href=\"https://ethresear.ch/uploads/default/78d6d4a75c61c8924502b41d72fa6adfa2853f0f\" title=\"Fig. 1: Protocol overview for Slot N.\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/7/78d6d4a75c61c8924502b41d72fa6adfa2853f0f_2_689x304.png\" alt=\"Fig. 1: Protocol overview for Slot N.\" data-base62-sha1=\"heZzht0aKd1q7ORqmY08PTei1MX\" width=\"689\" height=\"304\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/7/78d6d4a75c61c8924502b41d72fa6adfa2853f0f_2_689x304.png, https://ethresear.ch/uploads/default/optimized/2X/7/78d6d4a75c61c8924502b41d72fa6adfa2853f0f_2_1033x456.png 1.5x, https://ethresear.ch/uploads/default/original/2X/7/78d6d4a75c61c8924502b41d72fa6adfa2853f0f.png 2x\" data-dominant-color=\"FAFAFA\"></a></div><p></p>\n<h2><a name=\"protocol-execution-at-the-beginning-of-slot-n1-5\" class=\"anchor\" href=\"https://ethresear.ch#protocol-execution-at-the-beginning-of-slot-n1-5\"></a>Protocol Execution at the Beginning of Slot <span class=\"math\">N+1</span></h2>\n<ol>\n<li>At the beginning of slot <span class=\"math\">N+1</span>, the leader auction declares the provider with the highest bid as the leader for slot <span class=\"math\">N+1</span> by publishing the leader together with the auction price on the mev-commit chain. The auction further settles the payment from the leader to the proposer.</li>\n<li>The elected leader can now issue preconfirmations. Note that the leader has already received all preconfirmation bids for that slot and, therefore, can issue all preconfirmations immediately. They do so by publishing a blob inclusion list on the mev-commit chain. This list is final at this point and includes all bids including the blob KZG commitment hashes the leader commits to. To avoid timing issues in the next step, we can require the inclusion list to be published sufficiently early, e.g., within the first 6 seconds of the slot (and ignore lists published too late).</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/4/4ed8dfebb950c5c7877ade27b2d878d918a04cb0.png\" data-download-href=\"https://ethresear.ch/uploads/default/4ed8dfebb950c5c7877ade27b2d878d918a04cb0\" title=\"Fig. 2: Protocol overview for beginning of slot N+1.\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/4/4ed8dfebb950c5c7877ade27b2d878d918a04cb0_2_690x486.png\" alt=\"Fig. 2: Protocol overview for beginning of slot N+1.\" data-base62-sha1=\"bfvTsKG1Mhs0oMXI0ur6XlFdMYw\" width=\"690\" height=\"486\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/4/4ed8dfebb950c5c7877ade27b2d878d918a04cb0_2_690x486.png, https://ethresear.ch/uploads/default/original/2X/4/4ed8dfebb950c5c7877ade27b2d878d918a04cb0.png 1.5x, https://ethresear.ch/uploads/default/original/2X/4/4ed8dfebb950c5c7877ade27b2d878d918a04cb0.png 2x\" data-dominant-color=\"F8F9FA\"></a></div><p></p>\n<h2><a name=\"protocol-execution-during-slot-n1-6\" class=\"anchor\" href=\"https://ethresear.ch#protocol-execution-during-slot-n1-6\"></a>Protocol Execution During Slot <span class=\"math\">N+1</span></h2>\n<ol>\n<li>The builders receive from the mev-commit chain the inclusion list of blobs that are mandated to be in the block. Then, the builders build a block containing those blobs (in an order of their choice) and send it to the relays. Note that the builder can also include additional blobs if they choose to do so.</li>\n<li>The relays only forward to the L1 proposer the blocks from builders that opted-in to the protocol. The relays can also optionally verify that the blocks respect the blob inclusion list (or simply trust the builders in case of optimistic relays).</li>\n<li>The proposer signs a block header received from a relay (this can be done optimistically without checking for blob inclusion).</li>\n</ol>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/5/5498d249fa6e64846cf1c2a555e5b2c93a003873.png\" data-download-href=\"https://ethresear.ch/uploads/default/5498d249fa6e64846cf1c2a555e5b2c93a003873\" title=\"Fig. 3: Protocol overview for slot N+1.\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/5/5498d249fa6e64846cf1c2a555e5b2c93a003873_2_690x330.png\" alt=\"Fig. 3: Protocol overview for slot N+1.\" data-base62-sha1=\"c4nwBJAuDWGKL6ny48ygchh73YD\" width=\"690\" height=\"330\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/5/5498d249fa6e64846cf1c2a555e5b2c93a003873_2_690x330.png, https://ethresear.ch/uploads/default/optimized/2X/5/5498d249fa6e64846cf1c2a555e5b2c93a003873_2_1035x495.png 1.5x, https://ethresear.ch/uploads/default/original/2X/5/5498d249fa6e64846cf1c2a555e5b2c93a003873.png 2x\" data-dominant-color=\"F8F9FA\"></a></div><p></p>\n<h2><a name=\"l1-monitoring-7\" class=\"anchor\" href=\"https://ethresear.ch#l1-monitoring-7\"></a>L1 Monitoring</h2>\n<ol>\n<li>An oracle monitors the L1 chain for blocks and reports to the mev-commit chain when a block is proposed by an opted-in proposer, who the proposer is, and whether this block (or a previous block) contained the blobs from the inclusion list. The oracle may want to wait for L1 finality to avoid reorg issues.</li>\n<li>If the oracle reports a blob inclusion list violation, slashing is executed (see below for details).</li>\n</ol>\n<h2><a name=\"payments-and-slashing-8\" class=\"anchor\" href=\"https://ethresear.ch#payments-and-slashing-8\"></a>Payments and Slashing</h2>\n<p>We consider the following rules for payments and slashing.</p>\n<p>The following two types of payments are always executed (even if blobs are not included, slots get missed, etc.):</p>\n<ol>\n<li>The preconfirmation leader pays the amount for winning the leader auction to the L1 proposer (regardless of whether any preconfirmations are issued; this is because they participated in the auction and won the rights to become the leader).</li>\n<li>For all blobs in the inclusion list, the preconfirmation bidders pay the corresponding amount to the preconfirmation providers (regardless of whether the blob actually gets included; bidders may get reimbursed via slashing of proposers as described below).</li>\n</ol>\n<p>If the oracle reports that a blob from an inclusion list is not included in an L1 block in slot <span class=\"math\">N+1</span> or earlier, we need to execute slashing. There are different scenarios that can lead to a blob from the inclusion list not being included on L1:</p>\n<ol>\n<li>An opted-in relay sends a block not containing the blob.</li>\n<li>The proposer includes a block from an external relay.</li>\n<li>The proposer proposes their own block.</li>\n<li>The proposer misses the slot.</li>\n<li>The block gets proposed but then orphaned in a reorg.</li>\n</ol>\n<p>In the first case, the relay or the builder violated the protocol, while in cases 2, 3, and 4, it is the proposer’s fault. Without additional mechanisms, the proposer cannot prove which relay has sent what block. We therefore always slash the proposer. If it was indeed the relay’s fault, the relay’s reputation with the proposer gets “slashed” in the same way as the relay sending invalid blocks. If in turn the relay has received that block from an opted-in builder, that builder’s reputation with the relay is “slashed” and they can settle the dispute out-of-protocol with existing mechanisms.</p>\n<p>The last case is special since it may not be the fault of anyone involved and constitutes a general reorg risk the proposers need to consider. The slashing amount therefore needs to be set such that proposers still can make profit overall.</p>\n<p>The slashed amount is distributed to the preconfirmation bidders proportionally to their bid amounts since they are the ones harmed by the protocol violation.</p>\n<h1><a name=\"further-details-and-discussions-9\" class=\"anchor\" href=\"https://ethresear.ch#further-details-and-discussions-9\"></a>Further Details and Discussions</h1>\n<h2><a name=\"n1-slot-design-10\" class=\"anchor\" href=\"https://ethresear.ch#n1-slot-design-10\"></a><span class=\"math\">N+1</span> Slot Design</h2>\n<p>In our protocol, preconfirmation bidders bid in slot <span class=\"math\">N</span> for blob inclusion in slot <span class=\"math\">N+1</span>. This means that there is an expected one-slot delay between bidding and blob inclusion. While this would be unacceptable for time-sensitive transactions, e.g., for mev extraction, blob inclusion is substantially less time-sensitive.</p>\n<p>We further note that this next-slot inclusion list design is also used in EIP-7547 [3]. The lack of an out-of-protocol next-slot design and consequently the lack of real-world data from such designs has recently been criticized in the context of L1 inclusion lists [4]. Hence, the availability of this via mev-commit can be used to gather data about the efficacy of next-slot inclusion lists and can serve the Ethereum Foundation to make an effective decision based on the obtained empirical data.</p>\n<p>The purpose of the delay is to ensure that at the time the block builders want to build the block, the blob inclusion list is available to them. Furthermore, this allows the preconfirmation leader of slot <span class=\"math\">N+1</span> to preconfirm blobs at the beginning of the slot. By doing so, all participants know which blobs are going to be included in the block of slot <span class=\"math\">N+1</span> way ahead of the end time of that slot. In particular, the L1 validators could in the future use this information to pre-fetch the blob data at this time, thereby mitigating reorg risks due to long blob propagation (see, e.g., [5]). Having a predetermined leader also means that once the leader issues a preconfirmation, all participants can immediately rely on the blob inclusion, which allows for synchronous composability.</p>\n<h2><a name=\"leader-auction-11\" class=\"anchor\" href=\"https://ethresear.ch#leader-auction-11\"></a>Leader Auction</h2>\n<p>The auction to determine the preconfirmation leaders should ideally be credible, i.e., not require a trusted auctioneer. There are different ways to achieve this, and the precise implementation is orthogonal to our preconfirmation design. One option using SUAVE was explored by the Primev team, which has built a prototype auction at ETHGlobal London and was awarded a prize from Nethermind [6]. Another option is to use cryptographic tools such as timed commitments to realize the auction [7]. As an intermediate solution, the auction can also be run by a trusted actor.</p>\n<h2><a name=\"premature-inclusion-of-blobs-12\" class=\"anchor\" href=\"https://ethresear.ch#premature-inclusion-of-blobs-12\"></a>Premature Inclusion of Blobs</h2>\n<p>Leaders can issue preconfirmations for blobs to be included in slot <span class=\"math\">N+1</span>. However, before slot <span class=\"math\">N+1</span>, some builder (possibly outside of our protocol) may have already included this blob in a block that is now part of L1. In such a case, all payments are executed as described above and no slashing takes place. The preconfirmation bidders got their blobs included even earlier than expected and nobody else is harmed in this scenario.</p>\n<h1><a name=\"conclusion-13\" class=\"anchor\" href=\"https://ethresear.ch#conclusion-13\"></a>Conclusion</h1>\n<p>We have presented an out-of-protocol mechanism for blob inclusion lists. As long as inclusion lists are not available as part of the Ethereum protocol, we believe our solution offers a viable solution to the current issues with blob contention. Since it is a next-slot design, findings from this solution can further help to improve the understanding of such designs, which are also considered for L1 inclusion lists.</p>\n<p>Currently, mev-commit for transaction preconfirmations is live on the Holesky testnet and we are excited to add an implementation of the design discussed here. We are looking forward to feedback to further refine and improve this system.</p>\n<h1><a name=\"references-14\" class=\"anchor\" href=\"https://ethresear.ch#references-14\"></a>References</h1>\n<p>[1] <a href=\"https://twitter.com/bertkellerman/status/1773031698222989623?s=46\" rel=\"noopener nofollow ugc\">https://twitter.com/bertkellerman/status/1773031698222989623?s=46</a><br>\n[2] <a href=\"https://twitter.com/mcutler/status/1773033173573628009\" rel=\"noopener nofollow ugc\">https://twitter.com/mcutler/status/1773033173573628009</a><br>\n[3] <a href=\"https://github.com/ethereum/EIPs/blob/30fec793f3cb6769cb44d2d0daa5238451f67c48/EIPS/eip-7547.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">EIPs/EIPS/eip-7547.md at 30fec793f3cb6769cb44d2d0daa5238451f67c48 · ethereum/EIPs · GitHub</a><br>\n[4] <a href=\"https://notes.ethereum.org/@mikeneuder/the-case-for-ilectra\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">The Case for ILECTRA - HackMD</a><br>\n[5] <a href=\"https://ethresear.ch/t/validator-timing-game-post-eip4844/18129\" class=\"inline-onebox\">Validator Timing Game Post EIP4844</a><br>\n[6] <a href=\"https://ethglobal.com/showcase/blobpreconf-auction-qfdco\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">BlobPreconf Auction | ETHGlobal</a><br>\n[7] <a href=\"https://eprint.iacr.org/2023/1336\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Riggs: Decentralized Sealed-Bid Auctions</a></p>\n            <p><small>15 posts - 4 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150\">Read full topic</a></p>","link":"https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150","pubDate":"Fri, 29 Mar 2024 11:36:38 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19150"},"source":{"@url":"https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150.rss","#text":"Blob Preconfirmations with Inclusion Lists to Mitigate Blob Contention and Censorship"}},{"title":"Introducing Accrual-Based Recurring Payments for Decentralized Platforms","dc:creator":"grybniak","category":"EVM","description":"<p><img src=\"https://ethresear.ch/uploads/default/original/2X/1/1928a38c42bccb97e4d24ca767786d6cd62d55d9.jpeg\" alt=\"Image1\" data-base62-sha1=\"3Az0jF2NUUJqPM3esOAlDkJ9NfH\" width=\"634\" height=\"369\"></p>\n<h1><a name=\"key-takeaways-1\" class=\"anchor\" href=\"https://ethresear.ch#key-takeaways-1\"></a>Key Takeaways:</h1>\n<ol>\n<li>The proposed solution introduces a payment system based on accrual accounting, reflecting revenue and expenses before actual payment transfers.</li>\n<li>Advantages of the presented solution include convenience, instant access to payment revenues, regular debentures, and significantly lower transaction fees.</li>\n<li>The lazy evaluation approach is employed to efficiently process a large number of transactions and minimize computing power usage.</li>\n<li>The solution utilizes smart contracts on Ethereum or Ethereum-compatible networks to implement the new token standard.</li>\n<li>The implementation of the solution follows the currently developing IEEE standard for recurring transactions on distributed ledger technologies.</li>\n</ol>\n<p>Automatic recurring payments have become a critical revenue stream for businesses in almost every sector, providing a reliable incremental cash flow to support business processes. Some real-world use cases are displayed in the following figure.</p>\n<p><img src=\"https://ethresear.ch/uploads/default/original/2X/f/f9102e6e07fba56330da01693b7849466106ba60.png\" alt=\"Image3\" data-base62-sha1=\"zxjyD6ngDCyX9uI078Q948FiChG\" width=\"681\" height=\"391\"></p>\n<p>However, customer payments made on centralized platforms are subject to data breaches, and automated payments can easily be disrupted due to insufficient funds, expired debit or credit cards, and delays imposed by centralized banks. High transaction fees can take a bite out of payments, amounting to a significant reduction in revenues.</p>\n<p>For consumers, the convenience of automatic payments is offset by risks to sensitive data, making them vulnerable to identity theft and other mischief, and subjecting them to unauthorized sale of data to advertisers and other entities.</p>\n<p>While decentralized smart-contract payment systems do exist, they rely on a cash-based accounting system that is inadequate for executing ongoing recurring payments.</p>\n<p>Learn how accrual-based accounting can offer a solution that eliminates or significantly reduces the drawbacks of existing decentralized payment systems via smart contracts on the blockchain/Web 3.0 networks.</p>\n<h1><a name=\"challenges-of-recurring-payments-2\" class=\"anchor\" href=\"https://ethresear.ch#challenges-of-recurring-payments-2\"></a>Challenges of Recurring Payments</h1>\n<p>Subscription-based business models have been thriving globally for years, as exemplified by familiar centralized platforms such as streaming services, mobile service providers, and a variety of other platforms with automated recurring monthly fees.</p>\n<p>However, in decentralized public networks, a system for ongoing recurring payments has not been well thought out. Crypto wallet users currently face challenges when it comes to remitting and receiving recurring payments – they lack convenient, fast, and efficient payment methods, and they often involve transaction fees.</p>\n<p>But imagine if your recurring decentralized payments were made automatically, with minimal transaction fees, saving you time and money. We present a solution that has the potential to significantly impact decentralized transactions.</p>\n<p>Recurring transactions can be defined in terms of payment frequency (weekly, biweekly, monthly, etc.), fixed amounts, the prolongation of payments, the number of persons involved (individual, family, corporate subscriptions), a list of provided services, termination rules, and other conditions.</p>\n<p>However, problems arise when a customer does not have enough available funds to make a timely payment. In that case, we need to take into account the possibility of:</p>\n<ul>\n<li>debt formation​ – a necessary procedure to keep payments up-to-date and to charge late fees for late payments;</li>\n<li>debt repayment;​</li>\n<li>early termination​.</li>\n</ul>\n<h1><a name=\"the-status-quo-vs-our-approach-3\" class=\"anchor\" href=\"https://ethresear.ch#the-status-quo-vs-our-approach-3\"></a>The Status Quo vs Our Approach</h1>\n<h2><a name=\"current-options-for-decentralized-transactions-4\" class=\"anchor\" href=\"https://ethresear.ch#current-options-for-decentralized-transactions-4\"></a>Current options for decentralized transactions</h2>\n<p>Let’s recall that a <em>smart contract</em> is a self-executing contract with the terms of the agreement directly written into code. It is typically built on a blockchain platform and allows for the automation of transactions and agreements without the need for intermediaries.</p>\n<p>Smart contracts are executed by nodes. The process of running a smart contract involves the following steps:</p>\n<ol>\n<li>Choosing a suitable blockchain platform that supports smart contracts.</li>\n<li>Writing code for the smart contract using a programming language that is compatible with the chosen blockchain platform.</li>\n<li>Compiling the contract using the appropriate compiler for the chosen programming language. This step generates the bytecode that can be executed on the blockchain.</li>\n<li>Deploying the compiled smart contract onto the blockchain. This process involves creating a transaction that contains the bytecode and sending it to the network for inclusion in a block.</li>\n<li>Interacting with the contract: once the smart contract is deployed, it becomes a part of the blockchain and can be accessed and interacted with by users. Users can send transactions to the contract, triggering the execution of the predefined code.</li>\n<li>Executing the contract. When a transaction is sent to the smart contract, the code within the contract is executed on the blockchain nodes. The contract’s logic is automatically enforced, and the contract performs the actions specified in the code.</li>\n<li>Verifying and validating the contract. The decentralized nature of blockchain ensures that every node in the network verifies and validates the execution of the smart contract.</li>\n</ol>\n<p>The problem with popular smart contract platforms is that they are not designed to accept ongoing recurring payments. Decentralized public networks use a cash-based accounting system for payments, whose main advantages are ease of tracking and accurate reflection of account balances. The cash method of accounting records transactions whenever cash is received or paid. This approach is typical for small businesses with a relatively small turnover of funds and a small customer base.</p>\n<p>There currently exist two types of payment solutions:</p>\n<ul>\n<li>Custodial solutions – these solutions depend on the crypto-wallet owner depositing funds into a smart contract account, making it possible for the funds to be freely used without the consent of their true owner. This method creates an opportunity to establish a system for regular or on-demand payments.</li>\n<li>Non-custodial solutions – here, the customer sends a batch of transactions to the supplier, who stores them off-chain. For each billing period, the supplier selects and submits a single transaction to the Ethereum blockchain or an EVM-compatible network. A smart contract verifies the transaction’s validity and initiates the payment. While this approach does not reduce transaction fees, it offers the convenience of fully automated crypto wallets.</li>\n</ul>\n<h2><a name=\"our-proposed-solution-5\" class=\"anchor\" href=\"https://ethresear.ch#our-proposed-solution-5\"></a>Our proposed solution</h2>\n<p>An alternative to a cash-based accounting system is the accrual system. Accrual accounting has long been used by traditional financial institutions, but it has not yet been used in decentralized networks. We propose an accrual-based system that operates in a non-custodial manner. In our proposed system, revenue and expenses appear whenever a product or service is delivered to a customer, but before the payment amount is actually transferred. Our proposed smart contract on Ethereum or Ethereum-compatible networks provides a new token standard.</p>\n<p>Advantages, especially for enterprises and state authorities as well as social interaction purposes, include:</p>\n<ul>\n<li>convenience and ease of use;</li>\n<li>instant access to payment revenues;</li>\n<li>regular debentures and recurring payments;</li>\n<li>significantly lower transaction fees.</li>\n</ul>\n<h1><a name=\"our-high-level-design-6\" class=\"anchor\" href=\"https://ethresear.ch#our-high-level-design-6\"></a>Our High-Level Design</h1>\n<h2><a name=\"conventional-blockchain-financial-information-flow-7\" class=\"anchor\" href=\"https://ethresear.ch#conventional-blockchain-financial-information-flow-7\"></a>Conventional blockchain financial information flow</h2>\n<p>Here is how financial information is typically processed on the blockchain:</p>\n<ol>\n<li>Financial and other transactions flow from users to nodes on the network, forming a common transaction pool.</li>\n<li>Following a specific consensus protocol, transactions from the pool end up in blockchain blocks. In effect, the blockchain acts as a payment transaction ledger.</li>\n<li>Each node receives a new block and sequentially applies transactions from the block to its version of the blockchain state.</li>\n<li>The blockchain state records the amount of funds in the accounts of all users.</li>\n</ol>\n<p>In blockchain transactions, nodes perform calculations and remember the results only when transactions from the next block are applied. Until there is a new block, the nodes do nothing with the blockchain state. Put simply, the blockchain state is a ledger storing the number of tokens in the accounts of all users.</p>\n<h2><a name=\"how-our-solution-differs-8\" class=\"anchor\" href=\"https://ethresear.ch#how-our-solution-differs-8\"></a>How our solution differs</h2>\n<p>Our proposed approach to making regular payments does not change the blockchain scheme described above. As before, the amounts in the accounts are updated only when transactions are processed. Even if a regular payment is made once every second, the system does not update the account amounts with the same frequency.</p>\n<p>For example: If Alice pays Bob one token per second, the system does not process the payments every second. The status of both Alice’s and Bob’s accounts are recalculated all at once (so-called <em>lazy evaluation</em> or call-by-need method), for a given period, at the moment when any transaction from Bob or Alice requires knowledge of their account status.</p>\n<p>In other words, to process regular payments, our solution adds a recursive algorithm for finding and accounting for all regular payments associated with the participating accounts, at the moment of transaction processing. All linked regular payments are applied in their correct chronological order. This coincides with the concept of lazy computation in programming – the value of a variable is not computed until the variable is used.</p>\n<h2><a name=\"activity-diagram-9\" class=\"anchor\" href=\"https://ethresear.ch#activity-diagram-9\"></a>Activity Diagram</h2>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/d/d98593b3774f8abb6e9c19293051e966347ddf46.png\" data-download-href=\"https://ethresear.ch/uploads/default/d98593b3774f8abb6e9c19293051e966347ddf46\" title=\"Image2\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/d/d98593b3774f8abb6e9c19293051e966347ddf46_2_356x500.png\" alt=\"Image2\" data-base62-sha1=\"v2hNv2G03aA3FMDYyspezHv3dwq\" width=\"356\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/d/d98593b3774f8abb6e9c19293051e966347ddf46_2_356x500.png, https://ethresear.ch/uploads/default/optimized/2X/d/d98593b3774f8abb6e9c19293051e966347ddf46_2_534x750.png 1.5x, https://ethresear.ch/uploads/default/original/2X/d/d98593b3774f8abb6e9c19293051e966347ddf46.png 2x\" data-dominant-color=\"E8EAED\"></a></div><p></p>\n<h1><a name=\"payment-logic-design-10\" class=\"anchor\" href=\"https://ethresear.ch#payment-logic-design-10\"></a>Payment Logic Design</h1>\n<p>Unlike unsecured transfer transactions that frequently result in payment delays, our proposed solution enables regular payments without freezing funds. Payments that are nearing their due date, but for which there are insufficient available funds, are called “short-term payment commitments,” which are sent to the debt queue. When funds are insufficient, suppliers can decide whether to extend credit or terminate the contract. To terminate, they must send a termination transaction, to prevent a default to granting credit.</p>\n<p>In the same way, customers may send a transaction to terminate their subscription and stop future payments.</p>\n<p>To implement this system, certain elements must be considered:</p>\n<ul>\n<li>the final balance after completed payments;</li>\n<li>a provision for partial payments;</li>\n<li>a procedure for late payments.</li>\n</ul>\n<p>The table represents an example where transactions on a customer’s account gradually pay off her debt. A capital letter indicates the payee and an asterisk* marks the separable transaction – in this case, it is the first in the queue. When funds appear in the account, the account is reviewed and the oldest debt is paid first. Subsequent debts remain in the account queue and are paid when funds appear, from oldest to newest, until all are paid in full.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>Debt queue</th>\n<th>Funds added to Alice’s account</th>\n<th>Alice’s account status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>В*(20), С(100), B(1), C(2)</td>\n<td>5</td>\n<td>0</td>\n</tr>\n<tr>\n<td>В*(15), С(100), B(1), C(2)</td>\n<td>17</td>\n<td>1</td>\n</tr>\n<tr>\n<td>С(100), C(2)</td>\n<td>50</td>\n<td>49</td>\n</tr>\n<tr>\n<td>С(100)</td>\n<td>50</td>\n<td>99</td>\n</tr>\n<tr>\n<td>С(100)</td>\n<td>10</td>\n<td>9</td>\n</tr>\n</tbody>\n</table>\n</div><p>Let’s look at the first row. Alice adds 5 tokens to her account, and they are applied to her oldest debt: В*(20). In the second row, we see that Alice is able to pay off her first debt, and also the third one. At that time, she cannot pay off the second debt, so it remains the same. In subsequent rows, we see that Alice is able to pay off all her debts over time.</p>\n<h1><a name=\"implementation-and-future-work-11\" class=\"anchor\" href=\"https://ethresear.ch#implementation-and-future-work-11\"></a>Implementation and Future Work</h1>\n<p>The Recurring Transactions on the Distributed Ledger Technologies (DLTs) Working Group for the development of a <a href=\"https://standards.ieee.org/ieee/3228/11069/\" rel=\"noopener nofollow ugc\">token standard (project P3228)</a> has been approved by the IEEE Computer Society/Blockchain and Distributed Ledgers (C/BDL) Standards Committee. The purpose of this standard is to provide a resource for implementing blockchain and distributed ledger-based recurring payment methods in relevant industries, including public services, banking, finance, insurance, real estate, commercial payments, payrolls, and online services.</p>\n<p>Our proposed payment and token accounting solution is implemented as a smart contract on the Ethereum network, or on any system with a compatible virtual machine. Two smart contract versions were developed for backward compatibility with ERC-20 and ERC-777 standards, respectively. The tokens issued on their basis have successfully demonstrated the declared properties.</p>\n<p>Our idea <a href=\"https://doi.org/10.1109/iGETblockchain56591.2022.10087077\" rel=\"noopener nofollow ugc\">was presented</a> at the 2022 IEEE 1st Global Emerging Technology Blockchain Forum: Blockchain &amp; Beyond (iGETblockchain), in Irvine, CA, USA.</p>\n<p>Future functionality of our solution may expand to include:</p>\n<ul>\n<li>suspension of subscriptions;</li>\n<li>accrual of late fees on debts;</li>\n<li>recalculation of payments based on fiat exchange rates;</li>\n<li>creation of “oracles” to enable changes in the payment amount during the subscription period;</li>\n<li>confirmation of work performed;</li>\n<li>creation of web applications.</li>\n</ul>\n<p>Decentralized solutions like the one we propose can expand the scope of opportunities and services provided to users of cryptocurrency platforms, without sacrificing important advantages such as transparency and security.</p>\n<p><em>Learn more about</em> <a href=\"https://github.com/waterfall-network/recurring-payment-contract\" rel=\"noopener nofollow ugc\"><em>recurring payment contracts</em></a><em>.</em></p>\n            <p><small>3 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/introducing-accrual-based-recurring-payments-for-decentralized-platforms/19147\">Read full topic</a></p>","link":"https://ethresear.ch/t/introducing-accrual-based-recurring-payments-for-decentralized-platforms/19147","pubDate":"Fri, 29 Mar 2024 06:49:33 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19147"},"source":{"@url":"https://ethresear.ch/t/introducing-accrual-based-recurring-payments-for-decentralized-platforms/19147.rss","#text":"Introducing Accrual-Based Recurring Payments for Decentralized Platforms"}},{"title":"Supporting decentralized staking through more anti-correlation incentives","dc:creator":"vbuterin","category":"Proof-of-Stake","description":"<p><em>Content note: preliminary research. Would love to see independent replication attempts.</em></p>\n<p><em>Code: <a href=\"https://github.com/ethereum/research/tree/master/correlation_analysis\">https://github.com/ethereum/research/tree/master/correlation_analysis</a></em></p>\n<p>One tactic for incentivizing better decentralization in a protocol is to <em>penalize correlations</em>. That is, if one actor misbehaves (including accidentally), the penalty that they receive would be greater the more other actors (as measured by total ETH) misbehave at the same time as them. The theory is that if you are a single large actor, any mistakes that you make would be more likely to be replicated across all “identities” that you control, even if you split your coins up among many nominally-separate accounts.</p>\n<p>This technique is already employed in Ethereum <a href=\"https://github.com/ethereum/annotated-spec/blob/master/phase0/beacon-chain.md#aside-anti-correlation-penalties-in-eth2\">slashing (and arguably inactivity leak) mechanics</a>. However, edge-case incentives that only arise in a highly exceptional attack situation that may never arise in practice are perhaps not sufficient for incentivizing decentralization.</p>\n<p><strong>This post proposes to extend a similar sort of anti-correlation incentive to more “mundane” failures, such as missing an attestation</strong>, that nearly all validators make at least occasionally. The theory is that larger stakers, including both wealthy individuals and staking pools, are going to run many validators on the same internet connection or even on the same physical computer, and this will cause disproportionate correlated failures. Such stakers <em>could</em> always make an independent physical setup for each node, but if they end up doing so, it would mean that we have completely eliminated economies of scale in staking.</p>\n<h2><a name=\"sanity-check-are-errors-by-different-validators-in-the-same-cluster-actually-more-likely-to-correlate-with-each-other-1\" class=\"anchor\" href=\"https://ethresear.ch#sanity-check-are-errors-by-different-validators-in-the-same-cluster-actually-more-likely-to-correlate-with-each-other-1\"></a>Sanity check: are errors by different validators in the same “cluster” actually more likely to correlate with each other?</h2>\n<p>We can check this by combining two datasets: (i) <strong>attestation data</strong> from some recent epochs showing which validators were supposed to have attested, and which validators actually did attest, during each slot, and (ii) data mapping validator IDs to publicly-known <strong>clusters</strong> that contain many validators (eg. “Lido”, “Coinbase”, “Vitalik Buterin”). You can find a dump of the former <a href=\"https://data.ethpandaops.io/efresearch/attesters.txt\">here</a>, <a href=\"https://data.ethpandaops.io/efresearch/immediate_attesters.txt\">here</a> and <a href=\"https://data.ethpandaops.io/efresearch/committees.txt\">here</a>, and the latter <a href=\"https://data.ethpandaops.io/efresearch/clusters.csv\">here</a>.</p>\n<p>We then run a script that computes the total number of <strong>co-failures</strong>: instances of two validators within the same cluster being assigned to attest during the same slot, and failing in that slot.</p>\n<p>We also compute <strong>expected co-failures</strong>: the number of co-failures that “should have happened” if failures were fully the result of random chance.</p>\n<p>For example, suppose that there are ten validators with one cluster of size 4 and the others independent, and three validators fail: two within that cluster, and one outside it.</p>\n<br>\n<p><img src=\"https://ethresear.ch/uploads/default/original/2X/e/e103e9e08c8e2aedd5d5fa0e004b8429f5cb2af2.png\" alt=\"\" data-base62-sha1=\"w6zOzplJ28Kqbpxs8yvJvje00hk\" role=\"presentation\" width=\"610\" height=\"102\"></p>\n<br>\n<p>There is one co-failure here: the second and fourth validators within the first cluster. If all four validators in that clusters had failed, there would be <em>six</em> co-failures, one for each six possible pairs.</p>\n<p>But how many co-failures “should there” have been? This is a tricky philosophical question. A few ways to answer:</p>\n<ul>\n<li>For each failure, assume that the number of co-failures equals the failure rate across the other validators in that slot times the number of validators in that cluster, and halve it to compensate for double-counting. For the above example, this gives <span class=\"math\">\\frac{2}{3}</span>.</li>\n<li>Calculate the global failure rate, square it, and then multiply that by <span class=\"math\">\\frac{n * (n-1)}{2}</span> for each cluster. This gives <span class=\"math\">(\\frac{3}{10})^2 * 6 = 0.54</span>.</li>\n<li>Randomly redistribute each validator’s failures among their entire history.</li>\n</ul>\n<p>Each method is not perfect. The first two methods fail to take into account different clusters having different quality setups. Meanwhile, the last method fails to take into account correlations arising from different slots having different <em>inherent difficulties</em>: for example, slot <a href=\"https://beaconcha.in/slot/8103681\">8103681</a> has a very large number of attestations that don’t get included within a single slot, possibly because the block was published unusually late.</p>\n<br>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/c/c34994d5a8fe647e304a91b98a72361eeb532c48.png\" data-download-href=\"https://ethresear.ch/uploads/default/c34994d5a8fe647e304a91b98a72361eeb532c48\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/original/2X/c/c34994d5a8fe647e304a91b98a72361eeb532c48.png\" alt=\"\" data-base62-sha1=\"rRAKKRSTWmSK8UQ24Qpk612CFug\" role=\"presentation\" width=\"690\" height=\"177\" data-dominant-color=\"422038\"></a></div><p></p>\n<p><em>See the “10216 ssfumbles” in this python output.</em></p>\n<br>\n<p>I ended up implementing three approaches: the first two approaches above, and a more sophisticated approach where I compare “actual co-failures” with “fake co-failures”: failures where each cluster member is replaced with a (pseudo-) random validator that has a similar failure rate.</p>\n<p>I also explicitly separate out <strong>fumbles</strong> and <strong>misses</strong>. I define these terms as follows:</p>\n<ul>\n<li><strong>Fumble</strong>: when a validator misses an attestation during the current epoch, but attested correctly during the previous epoch</li>\n<li><strong>Miss</strong>: when a validator misses an attestation during the current epoch and also missed during the previous epoch</li>\n</ul>\n<p>The goal is to separate the two very different phenomena of (i) network hiccups during normal operation, and (ii) going offline or having longer-term glitches.</p>\n<p>I also simultaneously do this analysis for two datasets: <strong>max-deadline</strong> and <strong>single-slot-deadline</strong>. The first dataset treats a validator as having failed in an epoch only if an attestation was never included at all. The second dataset treats a validator as having failed if the attestation does not get included <em>within a single slot</em>.</p>\n<p>Here are my results for the first two methods of computing expected co-failures. SSfumbles and SSmisses here refer to fumbles and misses using the single-slot dataset.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Fumbles</th>\n<th>Misses</th>\n<th>SSfumbles</th>\n<th>SSmisses</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Expected (algo 1)</td>\n<td>8602090</td>\n<td>1695490</td>\n<td>604902393</td>\n<td>2637879</td>\n</tr>\n<tr>\n<td>Expected (algo 2)</td>\n<td>937232</td>\n<td>4372279</td>\n<td>26744848</td>\n<td>4733344</td>\n</tr>\n<tr>\n<td>Actual</td>\n<td>15481500</td>\n<td>7584178</td>\n<td>678853421</td>\n<td>8564344</td>\n</tr>\n</tbody>\n</table>\n</div><p>For the first method, the <code>Actual</code> row is different, because a more restricted dataset is used for efficiency:</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Fumbles</th>\n<th>Misses</th>\n<th>SSfumbles</th>\n<th>SSmisses</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Fake clusters</td>\n<td>8366846</td>\n<td>6006136</td>\n<td>556852940</td>\n<td>5841712</td>\n</tr>\n<tr>\n<td>Actual</td>\n<td>14868318</td>\n<td>6451930</td>\n<td>624818332</td>\n<td>6578668</td>\n</tr>\n</tbody>\n</table>\n</div><p>The “expected” and “fake clusters” columns show how many co-failures within clusters there “should have been”, if clusters were uncorrelated, based on the techniques described above. The “actual” columns show how many co-failures there actually were. Uniformly, we see strong evidence of “excess correlated failures” within clusters: two validators in the same cluster are significantly more likely to miss attestations at the same time than two validators in different clusters.</p>\n<h2><a name=\"how-might-we-apply-this-to-penalty-rules-2\" class=\"anchor\" href=\"https://ethresear.ch#how-might-we-apply-this-to-penalty-rules-2\"></a>How might we apply this to penalty rules?</h2>\n<p>I propose a simple strawman: in each slot, let <code>p</code> be the current number of missed slots divided by the average for the last 32 slots. That is, <span class=\"math\">p[i] = \n\\frac{misses[i]}{\\sum_{j=i-32}^{i-1}\\ misses[j]}</span>. Cap it: <span class=\"math\">p \\leftarrow min(p, 4)</span>. Penalties for attestations of that slot should be proportional to <span class=\"math\">p</span>. That is, <strong>the penalty for not attesting at a slot should be proportional to how many validators fail in that slot <em>compared to other recent slots</em></strong>.</p>\n<p>This mechanism has a nice property that it’s not easily attackable: there isn’t a case where failing <em>decreases</em> your penalties, and manipulating the average enough to have an impact requires making a large number of failures yourself.</p>\n<p>Now, let us try actually running it. Here are the total penalties for big clusters, medium clusters, small clusters and all validators (including non-clustered) for four penalty schemes:</p>\n<ul>\n<li><strong><code>basic</code></strong>: Penalize one point per miss (ie. similar to status quo)</li>\n<li><strong><code>basic_ss</code></strong>: the same but requiring single-slot inclusion to not count as a miss</li>\n<li><strong><code>excess</code></strong>: penalize <code>p</code> points with <code>p</code> calculated as above</li>\n<li><strong><code>excess_ss</code></strong>: penalize <code>p</code> points with <code>p</code> calculated as above, requiring single-slot inclusion to not count as a miss</li>\n</ul>\n<p>Here is the output:</p>\n<pre><code class=\"lang-auto\">                   basic          basic_ss       excess         excess_ss    \nbig                0.69           2.06           2.73           7.96           \nmedium             0.61           3.00           2.42           11.54         \nsmall              0.98           2.41           3.81           8.77           \nall                0.90           2.44           3.54           9.30\n</code></pre>\n<p>With the “basic” schemes, big has a ~1.4x advantage over small (~1.2x in the single-slot dataset). With the “excess” schemes, this drops to ~1.3x (~1.1x in the single-slot dataset). With multiple other iterations of this, using slightly different datasets, <strong>the excess penalty scheme uniformly shrinks the advantage of “the big guy” over “the little guy”</strong>.</p>\n<h2><a name=\"whats-going-on-3\" class=\"anchor\" href=\"https://ethresear.ch#whats-going-on-3\"></a>What’s going on?</h2>\n<p>The number of failures per slot is small: it’s usually in the low dozens. This is much smaller than pretty much any “large staker”. In fact, it’s smaller than the number of validators that a large staker would have active <em>in a single slot</em> (ie. 1/32 of their total stock). If a large staker runs many nodes on the same physical computer or internet connection, then any failures will plausibly affect all of their validators.</p>\n<p>What this means is: when a large validator has an attestation inclusion failure, they single-handedly move the current slot’s failure rate, which then in turn increases their penalty. Small validators do not do this.</p>\n<p>In principle, a big staker can get around this penalty scheme by putting each validator on a separate internet connection. But this sacrifices the economies-of-scale advantage that a big staker has in being able to reuse the same physical infrastructure.</p>\n<h2><a name=\"topics-for-further-analysis-4\" class=\"anchor\" href=\"https://ethresear.ch#topics-for-further-analysis-4\"></a>Topics for further analysis</h2>\n<ul>\n<li>Find other strategies to confirm the size of this effect where validators in the same cluster are unusually likely to have attestation failures at the same time</li>\n<li>Try to find the ideal (but still simple, so as to not overfit and not be exploitable) reward/penalty scheme to minimize the average big validator’s advantage over little validators.</li>\n<li>Try to prove safety properties about this class of incentive schemes, ideally identify a “region of design space” within which risks of weird attacks (eg. strategically going offline at specific times to manipulate the average) are too expensive to be worth it</li>\n<li>Cluster by geography. This could determine whether or not this mechanism also creates an incentive to geographically decentralize.</li>\n<li>Cluster by (execution and beacon) client software. This could determine whether or not this mechanism also creates an incentive to use minority clients.</li>\n</ul>\n<h2><a name=\"mini-faq-5\" class=\"anchor\" href=\"https://ethresear.ch#mini-faq-5\"></a>Mini-FAQ</h2>\n<p><strong>Q</strong>: But wouldn’t this just lead to staking pools architecturally decentralizing their infra without politically decentralizing themselves, and isn’t the latter what we care about more at this point?</p>\n<p><strong>A</strong>: If they do, then that increases the cost of their operations, making solo staking relatively more competitive. The goal is not to single-handedly force solo staking, the goal is to make the economic part of the incentives more balanced. Political decentralization seems very hard or impossible to incentivize in-protocol; for that I think we will just have to count on social pressure, starknet-like airdrops, etc. But if economic incentives can be tweaked to favor architectural decentralization, that makes things easier for politically decentralized projects (which cannot avoid being architecturally decentralized) to get off the ground.</p>\n<p><strong>Q</strong>: Wouldn’t this hurt the “middle-size stakers” (wealthy individuals who are not big exchanges/pools) the most, and encourage them to move to pools?</p>\n<p><strong>A</strong>: In the table above, the “small” section refers to stakers with 10-300 validators, ie. 320-9600 ETH. That includes most wealthy people. And as we can see, those stakers suffer significantly higher penalties than pools today, and the simulation shows how the proposed adjusted reward scheme would equalize things between precisely those validators and the really big ones. Mathematically speaking, someone with 100 validator slots would only have 3 per slot, so they would not be greatly affecting the penalty factor for a round; only validators that go far above that would be.</p>\n<p><strong>Q</strong>: Post-MAXEB, won’t big stakers get around this by consolidating all their ETH into one validator?</p>\n<p><strong>A</strong>: The proportional penalty formula would count total amount of ETH, not number of validator IDs, so 4000 staked ETH that acts the same way would be treated the same if it’s split between 1 validator or 2 or 125.</p>\n<p><strong>Q</strong>: Won’t adding even more incentives to be online create further pressure to optimize and hence centralize, regardless of the details?</p>\n<p><strong>A</strong>:The parameters can be set so that on average, the size of the incentive to be online is the same as it is today.</p>\n            <p><small>13 posts - 9 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116\">Read full topic</a></p>","link":"https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116","pubDate":"Tue, 26 Mar 2024 23:23:16 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19116"},"source":{"@url":"https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116.rss","#text":"Supporting decentralized staking through more anti-correlation incentives"}},{"title":"[RFC] [DRAFT] Anoma as the universal intent machine for Ethereum","dc:creator":"cwgoes","category":"Architecture","description":"<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/269f3eb4c2a042598c3ffc03d97de6e966192830.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/269f3eb4c2a042598c3ffc03d97de6e966192830\" title=\"Ethereum intent network\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/269f3eb4c2a042598c3ffc03d97de6e966192830_2_500x500.jpeg\" alt=\"Ethereum intent network\" data-base62-sha1=\"5vFk7LbWxdZIoq2pIpcr7DMHwvC\" width=\"500\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/269f3eb4c2a042598c3ffc03d97de6e966192830_2_500x500.jpeg, https://ethresear.ch/uploads/default/optimized/2X/2/269f3eb4c2a042598c3ffc03d97de6e966192830_2_750x750.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/269f3eb4c2a042598c3ffc03d97de6e966192830_2_1000x1000.jpeg 2x\" data-dominant-color=\"523670\"></a></div><p></p>\n<p><em>Thanks to <a class=\"mention\" href=\"https://ethresear.ch/u/0xapriori\">@0xapriori</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/adrianbrink\">@adrianbrink</a>, <a class=\"mention\" href=\"https://ethresear.ch/u/awasunyin\">@awasunyin</a>, and <a class=\"mention\" href=\"https://ethresear.ch/u/0xemperor\">@0xemperor</a> for reviewing this post. This is an active draft and further feedback (both solicited and unsolicited) is very welcome. All opinions and errors within are my own.</em></p>\n<p><strong>One-line summary</strong></p>\n<p>Anoma brings a universal intent machine to Ethereum, allowing developers to write applications in terms of intents, which can be ordered, solved, and settled anywhere in the Ethereum ecosystem.</p>\n<p><strong>tl; dr summary</strong></p>\n<ul>\n<li>An <em>intent</em> is a commitment to user preferences and constraints over the space of possible state transitions.</li>\n<li>The Anoma protocol brings a universal intent machine to Ethereum, allowing developers to write applications in terms of intents instead of transactions.</li>\n<li>Anoma is an <em>interface</em>, not an <em>intermediary</em> - it’s not another MEV redirection device.</li>\n<li>Anoma provides a universal intent standard which does not constrain what kinds of intents can be expressed, but allows for built-in state, network, and application interoperability.</li>\n<li>Intents and applications written with Anoma can be ordered, solved, and settled anywhere - on the Ethereum main chain, on EVM and non-EVM rollups, on Eigenlayer AVSs, on Cosmos chains, Solana, or any sufficiently programmable state machine.</li>\n<li>Anoma provides four key affordances: <em>permissionless intent infrastructure</em>, <em>intent-level composability</em>, <em>information flow control</em>, and <em>heterogeneous trust</em> - using three mechanisms: the <em>resource machine</em>, the <em>heterogeneous trust node architecture</em>, and <em>languages for explicit service commitments</em>.</li>\n<li>Anoma is compatible with any topology the Ethereum network chooses.</li>\n</ul>\n<h2><a name=\"table-of-contents-1\" class=\"anchor\" href=\"https://ethresear.ch#table-of-contents-1\"></a>Table of Contents</h2>\n<ul>\n<li><a href=\"https://ethresear.ch#introduction-2\">Introduction</a>\n<ul>\n<li><a href=\"https://ethresear.ch#motivations-3\">Motivations</a></li>\n<li><a href=\"https://ethresear.ch#personal-interlude-4\">Personal interlude</a></li>\n<li><a href=\"https://ethresear.ch#some-definitions-5\">Some definitions</a></li>\n<li><a href=\"https://ethresear.ch#interfaces-not-intermediaries-6\">Interfaces not intermediaries</a></li>\n<li><a href=\"https://ethresear.ch#where-are-we-at-7\">Where are we at?</a></li>\n<li><a href=\"https://ethresear.ch#what-does-a-universal-intent-machine-mean-for-ethereum-8\">What does a “universal intent machine” mean for Ethereum?</a></li>\n<li><a href=\"https://ethresear.ch#why-use-anoma-9\">Why use Anoma?</a></li>\n</ul>\n</li>\n<li><a href=\"https://ethresear.ch#intent-centric-applications-with-anoma-and-ethereum-10\">Intent-centric applications with Anoma and Ethereum</a>\n<ul>\n<li><a href=\"https://ethresear.ch#architecture-11\">Architecture</a>\n<ul>\n<li><a href=\"https://ethresear.ch#affordances-12\">Affordances</a>\n<ul>\n<li><a href=\"https://ethresear.ch#permissionless-intent-infrastructure-13\">Permissionless intent infrastructure</a></li>\n<li><a href=\"https://ethresear.ch#intent-level-composability-14\">Intent-level composability</a></li>\n<li><a href=\"https://ethresear.ch#information-flow-control-15\">Information flow control</a></li>\n<li><a href=\"https://ethresear.ch#heterogeneous-trust-16\">Heterogeneous trust</a></li>\n</ul>\n</li>\n<li><a href=\"https://ethresear.ch#mechanisms-17\">Mechanisms</a>\n<ul>\n<li><a href=\"https://ethresear.ch#resource-machine-18\">Resource machine</a></li>\n<li><a href=\"https://ethresear.ch#heterogeneous-trust-node-architecture-20\">Heterogeneous trust node architecture</a></li>\n<li><a href=\"https://ethresear.ch#service-commitment-languages-21\">Service commitment languages</a></li>\n</ul>\n</li>\n<li><a href=\"https://ethresear.ch#example-applications-22\">Example applications</a>\n<ul>\n<li><a href=\"https://ethresear.ch#multichat-23\">Multichat</a></li>\n<li><a href=\"https://ethresear.ch#public-signal-24\">Public Signal</a></li>\n<li><a href=\"https://ethresear.ch#scale-free-money-25\">Scale-free money</a></li>\n<li><a href=\"https://ethresear.ch#promise-graph-26\">Promise Graph</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"https://ethresear.ch#topology-27\">Topology</a>\n<ul>\n<li><a href=\"https://ethresear.ch#rollups-and-l2s-28\">Rollups and L2s</a></li>\n<li><a href=\"https://ethresear.ch#plasma-29\">Plasma</a></li>\n<li><a href=\"https://ethresear.ch#eigenlayer-and-service-providers-30\">EigenLayer and service providers</a></li>\n<li><a href=\"https://ethresear.ch#topology-implementation-requirements-31\">Topology implementation requirements</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"https://ethresear.ch#challenges-and-tradeoffs-32\">Challenges and tradeoffs</a></li>\n<li><a href=\"https://ethresear.ch#request-for-comment-33\">Request for comment</a></li>\n</ul>\n<h2><a name=\"introduction-2\" class=\"anchor\" href=\"https://ethresear.ch#introduction-2\"></a>Introduction</h2>\n<p>In this post, I will describe how Anoma can provide a universal intent machine for Ethereum - both the Ethereum base chain and the Ethereum ecosystem of rollups, searchers/solvers, and other network participants. What <em>is</em> a universal intent machine, you might ask? In what follows I shall attempt to clearly define this concept and what it means for the Ethereum ecosystem - but first I want to explain my motivations, tell you a bit about my personal history with Ethereum, and clarify some essential background context.</p>\n<h3><a name=\"motivations-3\" class=\"anchor\" href=\"https://ethresear.ch#motivations-3\"></a>Motivations</h3>\n<p>I have three key motivations in writing this piece. First, I want to establish a conceptual and discursive bridge to the Ethereum research community, which Anoma has historically operated somewhat separately from. I think that this separation was necessary in order for us to independently develop useful concepts, but the time has now come to reunite. Second, I want to clearly articulate to potential developers and users of applications built with Anoma what affordances Anoma can provide and why. I do this in order to set accurate expectations for what I think the technology - and often, any intent technology - can and cannot do, so that developers and users can make informed choices. Third, I want to reach out to Ethereum application developers in order to better understand their needs, see which of our ideas might be most helpful, and map out who specifically might be interested in collaborating on what.</p>\n<h3><a name=\"personal-interlude-4\" class=\"anchor\" href=\"https://ethresear.ch#personal-interlude-4\"></a>Personal interlude</h3>\n<p><em>Forgive me a bit of self-indulgence here, but I think it will help contextualize the history.</em></p>\n<p>My blockchain development journey actually started with Ethereum. In the summer of 2017, I started playing around with the system, and I was looking for a good starter Solidity development project to learn how smart contracts worked. These were the early days of decentralized exchanges (pre-Uniswap). At the time, I briefly used a since-defunct exchange called EtherDelta, and I thought it was a shame that someone had gone to all the trouble to build a complicated smart contract, orderbook server, and web frontend to support only ERC20 fungible tokens, when - to me - a key benefit of Ethereum’s fully-featured VM was the ability to generalize and support any asset representation a user wanted. I thought the best way to test this hypothesis was to try to implement it myself, so <a href=\"https://github.com/ProjectWyvern/wyvern-ethereum/commit/32af652eda2aedab82749c5c5479bc375f382a1b\" rel=\"noopener nofollow ugc\">I did</a> - and I decided to call it “Wyvern”.</p>\n<p>Wyvern was really a proto-intent system - and the whitepaper I wrote at the time <a href=\"https://github.com/ProjectWyvern/wyvern-protocol/blob/master/build/whitepaper.pdf\" rel=\"noopener nofollow ugc\">uses the word</a> - but I didn’t have a clear mathematical concept in mind then, nor an understanding of what a generalized intent system would really entail. Nevertheless, working on Wyvern taught me quite a bit about how Ethereum and the EVM worked, and also that they might not be the best fit for intents - or, at least, didn’t seem to have been designed for them. Around the time I published the first version of Wyvern, <a href=\"https://www.crunchbase.com/organization/opensea\" rel=\"noopener nofollow ugc\">a startup company</a> was founded by Devin Finzer and Alex Atallah called OpenSea. OpenSea - aiming to create a marketplace for non-fungible collectibles, and thus in need of a more generalized exchange protocol - became the first (and more-or-less only) user of Wyvern, which they used <a href=\"https://opensea.io/blog/articles/introducing-seaport-protocol\" rel=\"noopener nofollow ugc\">until 2022</a>. I didn’t do much work on Wyvern after 2018 - but luckily, since it was already generalized, OpenSea could add features such as batch sales and multi-asset payments without needing any changes to the core protocol.</p>\n<blockquote>\n<p>Aside: Believe it or not, the Wyvern contracts are <a href=\"https://www.paradigm.xyz/2024/03/how-to-raise-the-gas-limit-1\" rel=\"noopener nofollow ugc\">apparently still #1 in Ethereum DEX state consumption</a>. In retrospect, I really wish I had optimized my Solidity code. (I also looked for historical gas consumption data, but didn’t easily find it)</p>\n</blockquote>\n<p>After building Wyvern, I wanted to explore other aspects of blockchain systems design - particularly interoperability - and I was lucky enough to land a position at the (now defunct) Tendermint company, where I worked on the <a href=\"https://cosmos.network\" rel=\"noopener nofollow ugc\">Cosmos</a> project, specifically IBC, until the launch of IBC <a href=\"https://cointelegraph.com/news/cosmos-launches-stargate-paving-the-way-for-interoperable-defi-applications\" rel=\"noopener nofollow ugc\">in 2021</a>. After Wyvern and IBC, I felt like I had a few key pieces of the protocol puzzle, but not the whole picture - so I decided to co-found Anoma with <a class=\"mention\" href=\"https://ethresear.ch/u/awasunyin\">@awasunyin</a> and <a class=\"mention\" href=\"https://ethresear.ch/u/adrianbrink\">@adrianbrink</a> to figure out if I could piece together the rest. Anoma started with <a href=\"https://anoma.net/vision-paper.pdf\" rel=\"noopener nofollow ugc\">a vision</a>, but little idea of how exactly to implement it. This is the primary reason why we didn’t engage with the Ethereum ecosystem earlier on - we didn’t have a clear idea of what we wanted to do, and we didn’t know what Anoma could offer. Through years of research and design - most of it not by myself but rather by the brilliant and compassionate folks in the Anoma research ecosystem - we’ve come to a much better understanding of what Anoma is, and we now have a much better idea of what Anoma can bring to the Ethereum ecosystem. I’m happy to be coming back.</p>\n<h3><a name=\"some-definitions-5\" class=\"anchor\" href=\"https://ethresear.ch#some-definitions-5\"></a>Some definitions</h3>\n<p>Before discussing Anoma and Ethereum, I want to clarify what I mean by those words. In common language, words for blockchain networks, such as “Ethereum”, “Cosmos”, and “Anoma”, are commonly used to bundle together six distinct components:</p>\n<ul>\n<li>A <em>protocol</em>, defining what transactions do - in Ethereum’s case, the EVM.</li>\n<li>A specific <em>security model</em>, defining how blocks are produced - in Ethereum’s case, Gasper.</li>\n<li>A <em>network</em> or <em>ecosystem</em> of connected machines (physical and virtual) - in Ethereum’s case, the Ethereum ecosystem, including the base chain validators, rollups/L2s, bridges, off-chain services, etc.</li>\n<li>A <em>history</em> (all blocks since genesis)</li>\n<li>A nominal <em>asset</em> - in Ethereum’s case, ETH.</li>\n<li>A <em>community</em> of people who self-identify as members - in Ethereum’s case, the Ethereum community.</li>\n</ul>\n<p>In this post - which is addressed to the Ethereum <em>community</em> - I shall be talking <em>only</em> about possible relationships between the Ethereum and Anoma <em>protocols</em> and <em>networks</em> - so when I use the word “Ethereum” or “Anoma”, I mean only these components. Possible relationships between <em>histories</em>, <em>assets</em>, and <em>security models</em> are a fascinating topic, but one which I think had better be covered in a separate post.</p>\n<h3><a name=\"interfaces-not-intermediaries-6\" class=\"anchor\" href=\"https://ethresear.ch#interfaces-not-intermediaries-6\"></a>Interfaces not intermediaries</h3>\n<p>I also want to clarify that Anoma aims to provide a universal intent machine <em>interface</em> for applications - <em>not</em> an intent <em>intermediary</em>. What’s the difference? An <em>interface</em>, as I use the word here, is simply a protocol which translates, or represents, one semantics - in this case, declarative intent semantics - in terms of another - in this case, imperative ordering, compute, and storage semantics of underlying machines. TCP/IP, for example, is an interface - TCP translates the semantics of declarative ordered packet delivery into imperative send, retry, and window management semantics of underlying network hardware. An <em>intermediary</em>, on the other hand, is a particular network participant (possibly a chain or network) through which data (such as intents) flow. Many bridges in the Ethereum ecosystem - multisignature and chain alike - are intermediaries, as are, for example, banks in the US banking system which simply reissue dollars. <em>Interfaces</em> are simply code - freely copied, implemented anywhere, and usable by everybody. <em>Intermediaries</em>, however, are actors in a network - sometimes valuable ones - but their privileged positions often allow to extract rents, introduce additional security assumptions, or add unnecessary latency and complexity. The Anoma protocol is an interface - not an intermediary. There is no “Anoma chain” to which you must send intents.</p>\n<h3><a name=\"where-are-we-at-7\" class=\"anchor\" href=\"https://ethresear.ch#where-are-we-at-7\"></a>Where are we at?</h3>\n<p>The final (I promise!) clarifying note: Anoma is in active development and not yet finished. Ongoing research will continue to evolve the live system. We’ve finished enough research (indexed <a href=\"https://art.anoma.net\" rel=\"noopener nofollow ugc\">here</a>) that the overall design is pretty clear, but some details and priorities in implementation and deployment are not yet fixed. We think the design is at a stage which is possible to articulate and communicate, and we want to get feedback on it from Ethereum’s perspective (hence this post). The first full implementation of Anoma (in Elixir!) is also in the works, and will be open source soon.</p>\n<h3><a name=\"what-does-a-universal-intent-machine-mean-for-ethereum-8\" class=\"anchor\" href=\"https://ethresear.ch#what-does-a-universal-intent-machine-mean-for-ethereum-8\"></a>What does a “universal intent machine” mean for Ethereum?</h3>\n<p>At a high level, three things:</p>\n<ol>\n<li>Using Anoma, developers can write applications in terms of intents and distributed intent machines, instead of transactions and specific state machines. These intents can request particular network actors to perform roles such as computational search, data storage, intent matching, and transaction ordering, and they can disclose specific information to selected parties chosen either initially by the user authoring the intent, or programmatically during the intent matching and settlement process.</li>\n<li>Anoma provides a universal standard for intent and application formats which does not constrain what kinds of intents can be expressed (beyond the fundamental constraints - e.g. intents must be computable functions), but allows for state, network, and application interoperability. Broadly, Anoma standardizes what it takes to verify that an intent has been satisfied - but not how the solution is computed.</li>\n<li>These intents and applications written with Anoma can be ordered, solved, and settled anywhere - on the Ethereum main chain, on EVM and non-EVM rollups, on Eigenlayer AVSs, on Cosmos chains, Solana, etc. - anywhere an Anoma protocol adapter (which the post will cover in more detail later) is deployed.</li>\n</ol>\n<p>The rest of this post will expand on the details here - but first, I want to motivate why we think this kind of universal intent machine standard may be compelling.</p>\n<h3><a name=\"why-use-anoma-9\" class=\"anchor\" href=\"https://ethresear.ch#why-use-anoma-9\"></a>Why use Anoma?</h3>\n<p>In my view, a universal intent machine standard has three key benefits: intent-level and intent machine <em>composability</em>, application <em>portability</em>, and the availability of permissionless <em>intent infrastructure</em>. I’ll expect upon these aspects further in what follows, but in brief:</p>\n<ul>\n<li>Intent-level composability allows applications to compose interactions at the intent level, not just the transaction level. This unifies liquidity (as much as possible given heterogeneous preferences) and allows users to precisely select which decisions they would like to make themselves, which decisions they would like to delegate to specific network operators, and what constraints they would like to be enforced on those delegated decisions.</li>\n<li>Intent machine composability allows users to treat a distributed system of many computers, chains, and networks, as if it were a single intent machine, while that intent machine is internally composed of many smaller or special-purpose intent machines networked together.</li>\n<li>Application portability allows applications to move freely across concurrency and security domains without additional development work or protocol incompatibility barriers. Applications written for Anoma can treat the entire Anoma network as a virtualized state space - they do not need to be deployed separately to different chains, integrate different bridges, or pick any specific security model.</li>\n<li>Permissionless intent infrastructure allows applications to make use of existing nodes and chains running the Anoma protocol. Of course, what nodes choose to do is up to them - but a standardized protocol allows application developers to think only about their application, make use of services provided by existing node operators, and not spend any time building complicated, custom off-chain infrastructure - and it allows node operators to focus purely on the services they want to provide and the conditions under which they want to provide them, without needing to care (or even know) which applications are using those services.</li>\n</ul>\n<p>Now, I’d like to hope that maybe you’re interested (or, if not, you probably wouldn’t be reading this line of text anyways). What do intent-centric applications actually look like?</p>\n<h2><a name=\"intent-centric-applications-with-anoma-and-ethereum-10\" class=\"anchor\" href=\"https://ethresear.ch#intent-centric-applications-with-anoma-and-ethereum-10\"></a>Intent-centric applications with Anoma and Ethereum</h2>\n<blockquote>\n<p>For more information on what Anoma means by the word “intent”, see <a href=\"https://anoma.net/blog/abstract-intent-machines\" rel=\"noopener nofollow ugc\">this blog post</a>.</p>\n</blockquote>\n<p>I’m going to split this section into two parts: <em>architecture</em> and <em>topology</em>. Let me first define what I mean by those concepts. The <em>architecture</em> of a protocol is a mathematical specification of what the protocol is and does - typically, what (complex) pattern of messages will be sent in response to (complex) patterns of messages received. The <em>topology</em> of a network is the specific structure of connections - in the case of intent-based systems, connections induced by user choices of what intents to craft and where to send them. I find drawing a clear line between <em>architecture</em> and <em>topology</em> very helpful in designing and analyzing distributed, networked systems, for three reasons:</p>\n<ul>\n<li>The <em>architecture</em> and <em>topology</em> are always cleanly separable. Particular identities or connections can only be configuration parameters of a particular protocol - one could always copy the protocol (in design or in code), and change the particular parameters of who to connect to - thus keeping the same <em>architecture</em> but picking an arbitrarily different <em>topology</em>. More limited architectures may support only a certain subset of topologies, or may provide certain guarantees only for a certain subset of topologies - but the particular topology is always a matter of runtime configuration.</li>\n<li>The <em>architecture</em> and <em>topology</em> are chosen by different parties - the <em>architecture</em> of a particular protocol is chosen by whoever designed the protocol, while the <em>topology</em> of a network using that protocol is chosen (in a distributed fashion) by the users of that network making choices. Wearing my protocol designer hat, I consider it my responsibility to clearly define the <em>architecture</em> - but I have neither desire nor ability to influence the <em>topology</em>, which is a function of decisions made by network participants, themselves often influenced by cryptoeconomic parameters.</li>\n<li>Although the protocol designers may be subject to incentives of their own, the <em>architecture</em> of a particular protocol is fixed - in a sense, it is what defines the protocol - so one can easily analyze a particular architecture as a discrete, static mathematical object. The <em>topology</em> of a live network, however, changes all the time, and is subject to incentives both inside and outside the domain of what is legible to the protocol. In other words, <em>architectural definition</em> precedes <em>topological analysis</em> (using game theory, mechanism design, or similar). In order to understand how participants might use a language, one must first define the semantics which that language can express.</li>\n</ul>\n<h3><a name=\"architecture-11\" class=\"anchor\" href=\"https://ethresear.ch#architecture-11\"></a>Architecture</h3>\n<p>Let’s start with Anoma’s architecture. What kind of architecture does Anoma have, and what can this architecture provide? In this section, I will define the architecture in two levels: the <em>affordances</em> which Anoma’s architecture offers to applications, and the <em>mechanisms</em> with which Anoma provides these affordances. I will then detail a few <em>example applications</em> which I’m particularly excited about.</p>\n<blockquote>\n<p>Note: I have tried to select a level of abstraction which will provide a solid intuition for how Anoma works and why without getting lost in extraneous implementation details - but I certainly will not have selected optimally for all audiences (or even any), so please let me know where you would like more detail and which parts don’t make sense.</p>\n</blockquote>\n<h4><a name=\"affordances-12\" class=\"anchor\" href=\"https://ethresear.ch#affordances-12\"></a>Affordances</h4>\n<p>I’ve borrowed the word “affordance” from <a href=\"https://en.wikipedia.org/wiki/Affordance\" rel=\"noopener nofollow ugc\">cognitive psychology</a> - in this context it means, simply, what application developers can <em>do</em> with Anoma - what capabilities of application design and instantiation Anoma offers that they didn’t have before. In contrast to, for example, the <a href=\"https://barnabe.substack.com/p/seeing-like-a-protocol\" rel=\"noopener nofollow ugc\">perspective of the protocol</a>, affordances describe the perspective of the application developer. To applications, Anoma provides four key affordances: <em>permissionless intent infrastructure</em>, <em>intent-level composability</em>, <em>information flow control</em>, and <em>heterogeneous trust</em>. I will detail each of these in turn.</p>\n<h5><a name=\"permissionless-intent-infrastructure-13\" class=\"anchor\" href=\"https://ethresear.ch#permissionless-intent-infrastructure-13\"></a>Permissionless intent infrastructure</h5>\n<p><em>Permissionless intent infrastructure</em> means that - once Anoma is live - developers will be able to write complex intent-centric applications, which might need solvers, various intent pools, and multiple consensi, and deploy them to the Anoma network directly without needing to develop or operate any bespoke off-chain infrastructure of their own. The word “permissionless” can be a bit misleading - in any multi-user interaction, you’re interacting with <em>someone</em>, and they could always choose not to interact with you - but here I mean simply that Anoma provides intent infrastructure with no <em>specific</em> party (or parties) whose permission you must seek in order to use it.</p>\n<p>This is possible because Anoma nodes are topology-agnostic. Depending on the operator’s configuration and the intents received, they can act as consensus nodes, storage providers, solvers, gossip forwarders, or any other role - not just for one chain but for any number. For Anoma, topology is a matter of runtime configuration - often even negotiated over the network. What consensi users want shifts as demand shifts for particular applications and atomicity between particular partitions of state, and consensus providers must themselves shift to meet this demand.</p>\n<p>One concern with intent systems raised by, among others, <a href=\"https://www.paradigm.xyz/2023/06/intents\" rel=\"noopener nofollow ugc\">Paradigm and Flashbots</a>, is that intent systems could lead to centralization if specific parts of the intent lifecycle are performed by designated trusted parties (who would then have an undue influence). On the other hand, Chitra, Kulkarni, Pai, and Diamandis <a href=\"https://arxiv.org/abs/2403.02525\" rel=\"noopener nofollow ugc\">recently showed</a> that competitive solver markets could drive most solvers out and lead to oligopoly. Permissionless intent infrastructure does not change the mechanism design landscape, but it does remove all protocol barriers to decentralization and mechanism experimentation. The likelihood of designated trusted infrastructure or oligopoly is much lower when intents are built into the core protocol and nodes can be spun up on demand, and tracking intent satisfaction in the protocol allows for users to much more easily automatically switch between providers (or credibly threaten to) when their interests aren’t being sufficiently optimized for.</p>\n<h5><a name=\"intent-level-composability-14\" class=\"anchor\" href=\"https://ethresear.ch#intent-level-composability-14\"></a>Intent-level composability</h5>\n<p><em>Intent-level composability</em> means that application interactions can be composed at the intent level instead of at the transaction level. If applications use intents, but can be composed only with transactions, liquidity is fragmented between applications, and users cannot access the entire intent pool without writing an application intent aggregation interface on top of all the applications which provide liquidity of a relevant nature. Intent-level composability unifies this intent liquidity pool, such that users’ intents can be composed even with intents from another application the user has never heard of and never needs to think about - arbitrary composition is possible as long as the criteria in the user’s intent are satisfied.</p>\n<p>Intent-level composability also opens up efficiency improvements possible only when users can articulate precisely the nature and granularity of their preferences, such that their intents can be more flexibly composed - and more surplus returned back - than if the user had articulated more specific preferences than they actually have. Suppose that I want to swap USDC for ETH, and I’m happy to receive ETH on either the main chain, Optimism, or zkSync. With intent-level composability, my intent can be matched with the best offer available to settle on any of those chains - or perhaps even partially settled in multiple places, if I’m willing to accept the promise of a staked solver with liquidity in multiple places.</p>\n<h5><a name=\"information-flow-control-15\" class=\"anchor\" href=\"https://ethresear.ch#information-flow-control-15\"></a>Information flow control</h5>\n<p><em>Information flow control</em> means that developers of Anoma applications - and users of these applications - can reason precisely about what information actions taken in their application disclose to whom. Anoma provides information flow control at three distinct levels of the system:</p>\n<ul>\n<li><em>State-level information flow control</em> describes what can be seen by whom after transaction creation and execution. For example, a shielded transaction (as in <a href=\"https://z.cash\" rel=\"noopener nofollow ugc\">Zcash</a>) only reveals specific state changes and a proof that they satisfied required invariants, while a transparent transaction reveals all involved data to all observers.</li>\n<li><em>Intent-level information flow control</em> describes what can be seen by whom during intent solving, intent composition, and transaction creation. For example, a user may elect to disclose certain information to well-known solvers in order to help those solvers find valid matches quickly, but elect not to disclose that information to other solvers which they do not know.</li>\n<li><em>Network-level information flow control</em> describes what metadata going around the network can be seen by whom. For example, a user may elect to disclose certain physical network addresses and transport options - the Bluetooth ID of a phone, for example - only to a few well-known friends, lest the information revealed by the address render the user vulnerable to denial-of-service or deanonymization.</li>\n</ul>\n<p>Information flow control is a declarative specification of what should be disclosed to whom under which conditions. Desired information flow control properties constrain, but do not fix, the choice of specific cryptographic primitives such as regular encryption, succinct zero-knowledge proofs, or partially or fully homomorphic encryption - as long as the primitives chosen preserve the desired properties, the choice can be made on the basis of implementation availability, computational efficiency, and cryptographic interoperability. This is not a new concept - it is pretty well-covered in existing computer science research literature. In particular, the framework used by Anoma has been inspired and informed by the <a href=\"https://dl.acm.org/doi/pdf/10.1145/3453483.3454074\" rel=\"noopener nofollow ugc\">Viaduct paper</a>, although Anoma differs in providing a dynamic runtime instead of a one-shot compiler.</p>\n<h5><a name=\"heterogeneous-trust-16\" class=\"anchor\" href=\"https://ethresear.ch#heterogeneous-trust-16\"></a>Heterogeneous trust</h5>\n<p><em>Heterogeneous trust</em> means that Anoma application developers and users can make their own assumptions about the behavior of other participants on the network and their own choices about who to entrust with specific service-provisioning roles in the operation of their application, while reasoning about these assumptions and choices explicitly and detecting when their assumptions do not match their observations. In particular, most applications need three basic services: reliable <em>ordering</em> of intents and transactions related to the application, reliable <em>storage</em> of application data, and efficient <em>compute</em> of new application states and temporal statistics. Anoma makes all three of these services programmable:</p>\n<ul>\n<li>Using <em>programmable ordering</em>, users and developers can choose who will order their intents and transactions. These choices may be made independently for each intent, and conditionally delegated to third parties. For example, a user may request their intent to be ordered by A or B, and delegate the choice of whether it is in fact ordered by A or B to a solver, to be made on the basis of relative price.</li>\n<li>Using <em>programmable storage</em>, users and developers can choose who will store the data needed by their application. These choices may be made independently for each intent and each piece of data, conditionally delegated to third parties, and changed over time. For example, an application may choose to store recently-used data with the same nodes who will order its transactions, but move stale data to a cheaper long-term storage provider.</li>\n<li>Using <em>programmable compute</em>, users and developers can choose who will perform the computation required for their intents, transactions, and ongoing application usage. For example, an application may choose to pay low-latency solver nodes for the compute required to match intents, but pay higher-latency but cheaper-per-FLOP server farms for long-term statistical indexing.</li>\n</ul>\n<p>Heterogeneous trust is also a pre-existing concept in the academic research literature, from which we’ve been lucky to draw many ideas, such as <a href=\"https://arxiv.org/abs/2011.08253\" rel=\"noopener nofollow ugc\">Heterogeneous Paxos</a>. A lot of study still remains here, however - and I’m hopeful that blockchain projects (who desperately need this research) can step up a bit more to help organize and fund it.</p>\n<h4><a name=\"mechanisms-17\" class=\"anchor\" href=\"https://ethresear.ch#mechanisms-17\"></a>Mechanisms</h4>\n<p>How is all of this implemented? This post is already long enough without fully specifying exactly how Anoma works, but I will detail three key mechanisms here: the <em>resource machine</em>, which implements intents, the <em>heterogeneous trust node architecture</em>, which supports many networks with one piece of node software, and <em>languages for explicit service commitments</em>, which match user requests and operator offers for ordering, compute, and storage services.</p>\n<h5><a name=\"resource-machine-18\" class=\"anchor\" href=\"https://ethresear.ch#resource-machine-18\"></a>Resource machine</h5>\n<p>The Anoma <em>resource machine</em> implements intents without loss of generality. In relation to the affordances above, the resource machine provides state-level and intent-level information flow control, intent-level composability, and the programming framework for ordering, storage, and compute services required for heterogeneous trust. Heterogeneous trust also requires cross-domain state synchronization and verification, which the resource machine’s state architecture is designed to make simple and efficient.</p>\n<blockquote>\n<p>Note: I’ve chosen to simplify some of the definitions here for conceptual legibility of the key intuitions. For full details, please see the <a href=\"https://zenodo.org/records/10498991\" rel=\"noopener nofollow ugc\">resource machine ART report</a>.</p>\n</blockquote>\n<p>The basic concept of the resource machine is to organize state around <em>resources</em>. Resources are immutable: they can only be created and consumed exactly once. The current state of the system can be defined as the set of resources which have been created but not yet consumed. Each resource has an associated predicate called a <em>resource logic</em> that specifies the conditions under which the resource can be created and consumed. These conditions could include, for example, the creation or consumption of other resources, data such as a signature over a specific payload, or a proof that state elsewhere in the system satisfies a certain property. A transaction is considered valid only if the logics associated with all resources created and consumed in the transaction are satisfied, the transaction balances (enforcing e.g. linearity of currency), and no resources consumed in the transaction have been consumed before (no double-spends).</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/1/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee.png\" data-download-href=\"https://ethresear.ch/uploads/default/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee\" title=\"Resource logic examples\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/1/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee_2_690x369.png\" alt=\"Resource logic examples\" data-base62-sha1=\"3KYL5VfPeSVSDYddpInofM2Lsp8\" width=\"690\" height=\"369\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/1/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee_2_690x369.png, https://ethresear.ch/uploads/default/optimized/2X/1/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee_2_1035x553.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/1/1a560ae66942cc03fa5434d35fa54aa5cb46b2ee_2_1380x738.png 2x\" data-dominant-color=\"EEEEEE\"></a></div><p></p>\n<p><em>Diagram credit Yulia Khalniyazova</em></p>\n<h6><a name=\"formal-definitions-19\" class=\"anchor\" href=\"https://ethresear.ch#formal-definitions-19\"></a>Formal definitions</h6>\n<p>A resource is a tuple <span class=\"math\">R = (l, label, q, v, nonce)</span> where:</p>\n<ul>\n<li><span class=\"math\">Resource = \\mathbb{F}_{l} \\times \\mathbb{F}_{label} \\times \\mathbb{F}_Q \\times \\mathbb{F}_{v} \\times \\mathbb{F}_{nonce}</span></li>\n<li><span class=\"math\">l: \\mathbb{F}_{l}</span> is a succinct representation of the predicate associated with the resource (resource logic)</li>\n<li><span class=\"math\">label: \\mathbb{F}_{label}</span> specifies the fungibility domain for the resource</li>\n<li><span class=\"math\">q: \\mathbb{F}_Q</span> is an number representing the quantity of the resource</li>\n<li><span class=\"math\">v: \\mathbb{F}_{v}</span> is the fungible data of the resource (data which does not affect fungibility)</li>\n<li><span class=\"math\">nonce: \\mathbb{F}_{nonce}</span> guarantees the uniqueness of the resource computable components</li>\n</ul>\n<p>From a resource <span class=\"math\">r</span> may be computed:</p>\n<ul>\n<li><span class=\"math\">r.kind = h_{kind}(r.l, r.label)</span></li>\n<li><span class=\"math\">r.\\Delta = h_{\\Delta}(r.kind, r.q)</span></li>\n</ul>\n<p>A transaction is a composite structure <span class=\"math\">TX = (rts, cms, nfs, \\Pi, \\Delta, extra)</span>, where:</p>\n<ul>\n<li><span class=\"math\">rts \\subseteq \\mathbb{F}_{rt}</span> is a set of roots of the commitment tree</li>\n<li><span class=\"math\">cms \\subseteq  \\mathbb{F}_{cm}</span> is a set of created resources’ commitments.</li>\n<li><span class=\"math\">nfs \\subseteq \\mathbb{F}_{nf}</span> is a set of consumed resources’ nullifiers.</li>\n<li><span class=\"math\">\\Pi: \\{ \\pi: ProofRecord\\}</span> is a set of proof records.</li>\n<li><span class=\"math\">\\Delta_{tx}: \\mathbb{F}_{\\Delta}</span> is computed from <span class=\"math\">\\Delta</span> parameters of created and consumed resources. It represents the total delta change induced by the transaction.</li>\n<li><span class=\"math\">extra: \\{(k, d): k \\in \\mathbb{F}_{key}, d \\subseteq \\mathbb{F}_{d}\\}</span> contains extra information requested by the logics of created and consumed resources</li>\n</ul>\n<p>A transaction is considered <em>valid</em> with respect to a previous state if and only if:</p>\n<ul>\n<li><span class=\"math\">rts</span> contains valid commitment tree roots that are correct inputs for the membership proofs</li>\n<li><span class=\"math\">nfs</span> contains valid nullifiers that correspond to consumed resources, and none of these nullifiers have been previously revealed</li>\n<li>input resources have valid resource logic proofs and the compliance proofs associated with them</li>\n<li>output resources have valid resource logic proofs and the compliance proofs associated with them</li>\n<li><span class=\"math\">\\Delta</span> is computed correctly</li>\n</ul>\n<p>A transaction is considered <em>balanced</em> if and only if <span class=\"math\">\\Delta = 0</span>.</p>\n<p>Applying a transaction to the state simply entails adding new commitments and nullifiers to their respective Merkle tree and set. <em>Transaction candidates</em> - functions which generate transactions - are provided access to the current state and can look up resources by kind, which allows for post-ordering state-dependent updates without conflicts.</p>\n<p>Compared to the EVM (and other blockchain VMs such as the SVM and Move), the resource machine unbundles three aspects which these VMs intertwine: the <em>state architecture</em>, the <em>instruction set</em>, and the <em>message-passing model</em>. The EVM, for example, specifies:</p>\n<ul>\n<li>A <em>state architecture</em> where state is read and written in 256-bit blocks, partitioned by smart contract addresses, and encoded into a Merkle-Patricia Trie.</li>\n<li>An <em>instruction set</em> for stack-based computations with a 256-bit native word type and an assortment of specially optimized Ethereum-related instructions (e.g. <code>ecrecover</code>).</li>\n<li>A <em>message-passing model</em> where one smart contract owns the execution frame at a time, and sending a message to another contract switches control of the execution frame to the message recipient.</li>\n</ul>\n<p>The resource machine, by contrast, specifies <em>only</em> the state architecture. Different instruction sets can be chosen by different operators as long as valid state updates are ultimately produced, and messages can be passed in whatever fashion is most efficient in each particular case. This unbundling is necessary for native intent support, as with intents, much of the computation (expressed in an instruction set) and communication (expressed by a message-passing model) happens <em>before</em> final transaction execution and state change verification. With the resource machine, the instruction set can be chosen by whomever is performing the computation in question, and the message-passing model can simply reflect the actual intent-matching topology.</p>\n<h5><a name=\"heterogeneous-trust-node-architecture-20\" class=\"anchor\" href=\"https://ethresear.ch#heterogeneous-trust-node-architecture-20\"></a>Heterogeneous trust node architecture</h5>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/f/f70d2a9b2dae614e776808b0562601a340536cd9.png\" data-download-href=\"https://ethresear.ch/uploads/default/f70d2a9b2dae614e776808b0562601a340536cd9\" title=\"P2P overlay diagram\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/f/f70d2a9b2dae614e776808b0562601a340536cd9_2_690x417.png\" alt=\"P2P overlay diagram\" data-base62-sha1=\"zfw8W6su6OCn4FyLdGHNC3qXapX\" width=\"690\" height=\"417\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/f/f70d2a9b2dae614e776808b0562601a340536cd9_2_690x417.png, https://ethresear.ch/uploads/default/optimized/2X/f/f70d2a9b2dae614e776808b0562601a340536cd9_2_1035x625.png 1.5x, https://ethresear.ch/uploads/default/original/2X/f/f70d2a9b2dae614e776808b0562601a340536cd9.png 2x\" data-dominant-color=\"DFDDE1\"></a></div><p></p>\n<p><em>Diagram credit Naqib Zarin</em></p>\n<p>Anoma’s <em>heterogeneous trust node architecture</em> weaves together the key ordering, storage, and compute functionalities needed to provide permissionless intent infrastructure into a single piece of node software. The base of the node stack is a generalized heterogeneous P2P network stack with support for network-level information flow control. The node architecture can be split into two components: the <em>networking machine</em>, which implements the heterogeneous P2P network stack and provides interfaces for storage and compute resource provisioning, and the <em>ordering machine</em>, which implements heterogeneous consensus (total ordering), heterogeneous mempools (partial ordering), and parallel transaction execution.</p>\n<p>The <em>networking machine</em> consists of a set of communicating sub-processes which are responsible for message-passing between nodes. Anoma’s network architecture, based on <a href=\"https://arxiv.org/abs/2306.16153\" rel=\"noopener nofollow ugc\">P2P Overlay Domains with Sovereignty</a>, assumes <em>heterogeneous P2P preferences</em>: different nodes want to broadcast and subscribe to different types of intents, participate in different domains of consensus, storage, and compute, and choose different bandwidth, latency, and resource usage tradeoffs in their network connection choices. The networking machine is designed to abstract this complexity and the ever-changing physical and overlay network topologies behind an interface which simply allows sending a message to any other node or topic in the network - the internal processes within the networking machine are responsible for using network metadata to figure out where it should go and how to route it there efficiently. Generic interfaces are also provided for provisioning and requesting storage and compute.</p>\n<p>The <em>ordering machine</em> consists of a set of communicating sub-processes which are responsible for receiving transactions, partially ordering those transactions in the mempool, coming to consensus over a total order for each logical consensus clock, executing the transactions, updating the state accordingly, and sending updated state to the appropriate recipients. Both the mempool and consensus are heterogeneous - implementing <a href=\"https://github.com/anoma/typhon/blob/heterogeneous-narwhal/pubs/HeterogeneousNarwhal.pdf\" rel=\"noopener nofollow ugc\">Heterogeneous Narwhal</a> and <a href=\"https://arxiv.org/abs/2011.08253\" rel=\"noopener nofollow ugc\">Heterogeneous Paxos</a>, respectively - and the execution engine based on <a href=\"https://cs.yale.edu/homes/thomson/publications/calvin-sigmod12.pdf\" rel=\"noopener nofollow ugc\">CalvinDB</a> is capable of n-processor parallel scale-out.</p>\n<p>Heterogeneous chains are operationally expensive if you have to run a separate node for each one - so Anoma’s node architecture supports <em>many networks with a single node</em>. The operator simply configures which networks they’d like to participate in and the node software takes care of all the bookkeeping. Processes within the ordering machine, for example, can be spun up or spun down automatically based on which consensi the operator is participating in and how much throughput each needs at the moment.</p>\n<p>A full paper on the heterogeneous trust node architecture is still in the works, but the curious reader may be interested in <a href=\"https://anoma.net/blog/heterogeneous-paxos-and-multi-chain-atomic-commits\" rel=\"noopener nofollow ugc\">more about multi-chain atomic commits</a> or <a href=\"https://anoma.net/blog/anomas-p2p-layer\" rel=\"noopener nofollow ugc\">a brief introduction to Anoma’s P2P layer</a>.</p>\n<h5><a name=\"languages-for-explicit-service-commitments-21\" class=\"anchor\" href=\"https://ethresear.ch#languages-for-explicit-service-commitments-21\"></a>Languages for explicit service commitments</h5>\n<p><em>Languages for explicit service commitments</em> provide a way for clients (requesting a service) and servers (providing a service) to automatically negotiate the terms of that service in a way which is legible to the network, so that records can be kept of services performed as promised - and promises broken. For example, service commitments could include</p>\n<ul>\n<li>“I will vote in consensus XYZ”</li>\n<li>“I will store your data D for T weeks”</li>\n<li>“I will spend N units of CPU time searching for an answer to problem P”</li>\n</ul>\n<p>Generally, these commitments will be comprised of aspects classifiable into one of two categories: <em>safety</em> - roughly, promising not to send any messages which violate a certain invariant, and <em>liveness</em> - roughly, promising to send responses promptly when queried. Initially, I think three kinds of services are particularly important in the context of distributed systems: <em>ordering</em> services, <em>storage</em> services, and <em>compute</em> services. I will expand a bit upon each of these in turn.</p>\n<p><em>Ordering services</em> are perhaps the most basic historical function of blockchains. Satoshi actually <a href=\"https://bitcoin.org/bitcoin.pdf\" rel=\"noopener nofollow ugc\">uses the term</a> “timestamping server”. In order for multiple observers to agree on the history of a particular piece of state, they must agree on a particular party whose local order of observations will determine the order in which events (transactions) are applied to that state. This party must attest to the order in which it has received events, from which we can derive the desired liveness property: signing updates to the event graph (blocks of transactions). Consistency for other observers requires consistency of ordering attestations, from which we can derive the desired safety property: never signing two conflicting updates. Other properties of interest here could include censorship resistance - perhaps promising to construct blocks in a certain fashion (connecting directly to <a href=\"https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879\">PEPC</a>).</p>\n<p><em>Storage services</em> are recently in the spotlight thanks to the concept of “data availability”, which illuminates an important nuance: it is not enough for observers that data be <em>stored</em>, it must be <em>available</em> - they must be able to retrieve it. In order to make data available, though, one must store it. I think storage services need only a liveness property: responding with the requested data, perhaps only within a certain span of time from the initial request. Thanks to content-addressing, the recipients of that data can quickly check that the correct bits were provided. Storage markets are very heterogeneous - different data needs to be retrieved by different parties, at different frequencies, and stored with different level of redundancy and distribution.</p>\n<p><em>Compute services</em> are currently split across a few different areas: <em>searching</em> performed in the Ethereum MEV supply chain, <em>indexing</em> still typically performed by web2-style services, and <em>historical statistics</em> calculated on the backend by explorers or specialized providers. I think that these various specific services are variants of one basic unit: the provision of computational infrastructure to search for a solution satisfying a particular relation, which may include network history. Safety for compute means providing the correct result, and liveness means getting a result quickly and with high likelihood.</p>\n<p>We’re still in the design process for these service commitment languages, and I see a lot of potential for collaboration. In particular, several folks in the Ethereum research community have been exploring relevant concepts: <a href=\"https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879\">protocol-enforced proposer commitments</a>, whereby Ethereum block proposers can make commitments which are enforced by the core protocol, and <a href=\"https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683\">rainbow staking</a>, where staking services are split into “heavy” and “light” categories (the names follow from expected node operator resource requirements). I expect that clear specification of various flavors of heavy and light services as described in the post, and negotiation of who is to perform those services, how they are to be compensated, and how other network actors can tell whether or not they are performing as promised will require some form of service commitment language, and PEPC would allow these commitments to be legible to and enforceable by the core protocol. <a href=\"https://markburgess.org/promises.html\" rel=\"noopener nofollow ugc\">Promise Theory</a> may also provide helpful theoretical ammunition. I hope to develop a better understanding of the Ethereum ecosystem’s requirements here and see whether it is possible to develop a common standard.</p>\n<h4><a name=\"example-applications-22\" class=\"anchor\" href=\"https://ethresear.ch#example-applications-22\"></a>Example applications</h4>\n<p>What kinds of applications can be built with these affordances and mechanisms? I’ll save a comprehensive survey for a separate discussion, but I want to list a few here which I’m particularly excited about.</p>\n<h5><a name=\"multichat-23\" class=\"anchor\" href=\"https://ethresear.ch#multichat-23\"></a>Multichat</h5>\n<p>Multichat is a distributed chat network without any specially designated server operators. Like Slack or Discord, multichat supports permissioned channels in complex topologies. Like Signal, multichat encrypts messages and metadata. Unlike Signal, Slack, or Discord, multichat can run offline, or in an isolated physical subnetwork, using direct connections between chat participants. Unlike Slack or Discord, multichat cleanly separates protocol, operators, and interfaces, allowing different interfaces to be designed for different user needs while retaining protocol compatibility, and allowing users to choose which operators they want to trust with what roles.</p>\n<p>For more details on this application concept, see <a href=\"https://research.anoma.net/t/dreaming-of-multichat-a-chat-application-built-with-anoma/515\" rel=\"noopener nofollow ugc\">this forum thread</a>.</p>\n<h5><a name=\"public-signal-24\" class=\"anchor\" href=\"https://ethresear.ch#public-signal-24\"></a>Public Signal</h5>\n<p>Public Signal is a double-sided version of Kickstarter implemented with intents. Kickstarter is a supply-side driven platform: a group or individual wishing to produce a particular good or service and in need of funding posts a description of their product or service and organizes a campaign to raise small donations/payments in order to cover their capital expenditure requirements and labor costs. Public Signal, by contrast, is <em>demand-side driven</em>: potential purchasers of a good or beneficiaries of a service describe their preferences and are gradually matched together, generating a demand signal which potential suppliers can use to decide what to produce. The demand-side approach is particularly appealing because it can generate an otherwise difficult-to-observe signal for <em>public</em> or <em>hybrid</em> goods.</p>\n<p>For more details on this application concept, see the <a href=\"https://anoma.net/blog/publicsignal\" rel=\"noopener nofollow ugc\">Public Signal blog post</a>.</p>\n<h5><a name=\"scale-free-money-25\" class=\"anchor\" href=\"https://ethresear.ch#scale-free-money-25\"></a>Scale-Free Money</h5>\n<p>Scale-free money is a hypothetical monetary system design which allows anyone to create arbitrary denominations of money at any time for any purpose and provides the necessary infrastructure to unbundle the three key functions of money (store of value, means of exchange, and unit of account) and allow for the choice of what money to use to be made differently by different network participants without compromising their ability to enact voluntary economic interchange. To me, scale-free money is the natural synthesis of the experimental practice of <em>decentralized cryptocurrencies</em>, the anthropological record of <em>heterogeneous credit</em>, and the cybernetic approach to <em>coordination systems design</em>.</p>\n<p>For more details on this application concept, see <a href=\"https://pluranimity.org/2022/09/26/towards-heterotopia/\" rel=\"noopener nofollow ugc\">this blog post</a>.</p>\n<h5><a name=\"promise-graph-26\" class=\"anchor\" href=\"https://ethresear.ch#promise-graph-26\"></a>Promise Graph</h5>\n<p>Promise Graph, inspired in part by the <a href=\"https://galois.com/wp-content/uploads/2016/06/CW-picmet-proceedings.pdf\" rel=\"noopener nofollow ugc\">Collaborative Web</a> model of Galois, and Informal Systems’ <a href=\"https://workflow.informal.systems/\" rel=\"noopener nofollow ugc\">Workflow</a>, is a language and structured accounting logic for making and managing promises in order to effectively synchronize causally-interwoven workstreams across a distributed organization and demonstrate to customers that the organization can keep its promises. Heliax has been dogfooding the promise graph system internally for awhile now, but it is designed in particular to facilitate coordination irrespective of, and even without knowledge of, organizational boundaries. Similar to how Anoma splits the architecture of an intent-centric system from the particular topology users choose, Promise Graph splits the architecture of promise-based coordination from the particular topology of promises necessary to achieve a particular aim.</p>\n<p>For more details on this application concept, see <a href=\"https://promisegrapheliax.click\" rel=\"noopener nofollow ugc\">this description of the system</a>.</p>\n<h3><a name=\"topology-27\" class=\"anchor\" href=\"https://ethresear.ch#topology-27\"></a>Topology</h3>\n<p>Now, let’s talk topology. How does Anoma relate to the topology of the Ethereum network today? As a refresher, by <em>topology</em>, I mean specific network connections, specific security relations, and specific service providers performing specific network roles. My understanding is that the Ethereum network is still figuring out what topology it wants to have, as evidenced by the fervent discussions around shared sequencing for rollups/L2s, EigenLayer, and rainbow staking. I think the existence of such discussions is evidence of a healthy network - a network with a static topology is a network which can no longer adapt to changes in the world outside.</p>\n<p>There are infinitely many possible topologies, and I don’t know of any finite framework to classify them - so here I will simply list a few topologies under discussion in the Ethereum ecosystem and explain at a high level how Anoma could be used with them. I will also discuss how Anoma could interface with specific specialized ordering, compute, and storage service providers which already exist, and how service commitments could be made using existing assets. Finally, I will detail two components which I believe sufficient to connect Anoma to any and all of these topologies.</p>\n<h4><a name=\"rollups-and-l2s-28\" class=\"anchor\" href=\"https://ethresear.ch#rollups-and-l2s-28\"></a>Rollups and L2s</h4>\n<p>For several years now, the Ethereum ecosystem has been following the rollup-centric roadmap, where different sequencers order transactions for different rollup chains, which then post proofs and some data to Ethereum. Most rollups use the EVM, although a few have developed distinct VMs with different properties designed for particular kinds of applications. Recent proposals have brought forth the idea that many rollups may wish to share a sequencer, which is subsequently referred to as a “shared sequencer”. The Ethereum main chain could in fact play this role of the shared sequencer.</p>\n<p>Anoma could be useful for rollups in two ways:</p>\n<ul>\n<li>The resource machine could be used as a rollup execution environment instead of or in addition to the EVM, providing the rollup’s users with intent-level and transaction-level information flow control, intent-level composability, and parallel transaction execution.</li>\n<li>The heterogeneous node architecture could be used to simply run the EVM, which would allow rollup operators to participate in a shared heterogeneous P2P network on which they could connect to other rollups, Ethereum main chain validators, searchers, and other intent infrastructure operators. Heterogeneous Paxos, in particular, may be interesting for rollups with frequent cross-traffic, because it <a href=\"https://anoma.net/blog/chimera-chains\" rel=\"noopener nofollow ugc\">generalizes shared sequencers</a>.</li>\n</ul>\n<h4><a name=\"plasma-29\" class=\"anchor\" href=\"https://ethresear.ch#plasma-29\"></a>Plasma</h4>\n<p>Plasma is the name for a family of Ethereum scaling solutions which require only posting deposit transactions, withdrawal transactions, and updated state Merkle roots to the main chain, while keeping all data and compute happening “within Plasma” off-chain. The basic concept assumes a block-producing operator who publishes state roots for each new block to the main chain and sends to individual users any state updates affecting them (e.g. tokens they’ve received). Should the operator misbehave, users can themselves publish proof of state they own to the main chain in order to withdraw it. In the original Plasma design, this forced withdrawal requires a 7-day challenge period, but the addition of validity proofs (where the operator proves that each new state root is the valid result of block execution) allows for withdrawals referring to the latest state root to be processed instantly. For a comprehensive summary of Plasma research and recent work, I recommend <a href=\"https://vitalik.eth.limo/general/2023/11/14/neoplasma.html\" rel=\"noopener nofollow ugc\">Vitalik’s blog post on the topic</a>.</p>\n<p>As discussed in that blog post, even with validity proofs, several challenges remain for Plasma:</p>\n<ul>\n<li><em>Dependency tracking</em>: The EVM does not attempt to limit or explicitly track state change dependencies, so (for example) ETH held in an account in block n + 1 could have come from anywhere block n. Exiting may then require publication of the entire history, which would incur prohibitive gas costs - and this worst-case exit game would likely entail limitations on the compute and storage bandwidth of Plasma, since it must be possible to replay everything on the main chain.</li>\n<li><em>Incentive-compatible generalization</em>: Plasma works well with state objects which have a clear economic owner, such as fungible or non-fungible tokens, but it’s not clear how to adapt the incentive model to objects without a clear economic owner such as a CDP, which a user might want to pretend to have forgotten the data for if the price of ETH goes below the DAI they’ve withdrawn.</li>\n<li><em>Developer-facing complexity</em>: Plasma application developers must reason about state ownership graphs and data storage/publication incentives, adding mental overhead and introducing whole new classes of potential bugs.</li>\n</ul>\n<p>What happens if we try to build a Plasma-like construction on top of the Resource Machine, instead of the EVM? Let’s call it <em>Resource Plasma</em>. In Resource Plasma, the operator executes transactions and publishes only the Merkle root of the commitment tree, the Merkle root of the nullifier set, and a proof of correct transaction execution to the main chain. Withdrawals function as follows:</p>\n<ul>\n<li>Withdrawals with a proof made against the latest nullifier set Merkle root can be processed immediately. They also reveal the nullifier of the resource being withdrawn (so that it can no longer be withdrawn again).</li>\n<li>Withdrawals against older Merkle roots require a delay period. When the withdrawal is requested, the Plasma contract starts a “double spend” challenge game, where anyone can submit a proof that the nullifier for the resource being withdrawn was included in a later nullifier set than the Merkle root used for the withdrawal request. After the challenge period, if no conflicting nullifier has been found, the withdrawal is processed.</li>\n</ul>\n<p>Thanks to the dual commitment-nullifier system used by the resource machine, client data storage requirements are minimal - the client need only store their resources, proofs that the commitments corresponding to those resources were included in the commitment Merkle tree root, and proofs that the nullifiers corresponding to those resources were not revealed at whatever height the client last synced at. Clients wanting to withdraw instantly must update these latter proofs, but have the option to exit if the operator withholds data (in this case, the latest nullifier set). Resource Plasma thus removes the need for separate <em>dependency tracking</em> - clients need not track dependencies, only the latest state relevant to them and proofs associated with it. <em>Developer-facing complexity</em> is also reduced because this state architecture, including commitments and nullifiers, is built into the resource machine and requires no additional effort on the part of developers.</p>\n<p><em>Incentive-compatible generalization</em> is a trickier beast. One option is to have each resource designate a particular highly-available party whose signature over an attestation that they have stored the resource data is required in order to construct a valid transaction. For example, in the CDP example, perhaps it would be suitable for a quorum of operators elected by MKR holders to store data associated with all CDPs. If the CDP is to be liquidated and the owner pretends not to have the data, this quorum could then reveal the data, allowing for the liquidation of the CDP. MKR holders have an incentive to store and publish this data in order to keep the system on which their value flows depend credible. In a version of MakerDAO without governance, it is less clear what to do in this scenario. Perhaps the data could also be sent to a party who might want to liquidate the CDP, or more generally one with the opposite economic incentive. Perhaps systems such as Maker really do need a designated party (which could be a dynamic, distributed operator set) whose job it is to store the data. The resource machine makes it easy to designate who should store what state, but it doesn’t change the game design problem.</p>\n<p>Resource Plasma is no panacea. Application developers must still reason about storage handoff, and users who want to be able to receive payments while offline must pick a highly available operator who they trust to temporarily store data on their behalf (or pay the main chain itself to do so). These limitations, however, are fundamental - they could not be alleviated by a different virtual machine - and other scaling solutions such as L2s or rollups will be faced with the same constraints. This is just a sketch of stirring the Plasma and Resource Machine models together, and seeing what emerges from the resulting conceptual melange. I think there may be some compelling options here, and I plan to explore this design space further in a separate post.</p>\n<h4><a name=\"eigenlayer-and-service-providers-30\" class=\"anchor\" href=\"https://ethresear.ch#eigenlayer-and-service-providers-30\"></a>EigenLayer and service providers</h4>\n<p>Many blockchains today - including, typically, those who self-identify as data availability layers, in the modular conceptual framework - provide both <em>ordering</em> and <em>storage</em> services. Ordering services are mostly distinguished by the validator set and consensus mechanism, the combination of which determine latency, costs, and security. Storage services are often distinguished by how long the storage is to be provided for - blob storage on Ethereum, Celestia, and EigenDA, for example, is short-term, while file storage on Filecoin or Arweave is (at least nominally) permanent. Storage services are also distinguished by operators, redundancy, and optimization for specific patterns of retrieval. Many applications will likely want to use multiple storage providers with different specialties with different purposes. <em>Compute</em> services today are mostly provided by off-chain actors, as it is not typically necessary to replicate compute (since the results can be verified). I understand Ethereum ecosystem searchers/builders, indexers, and statistical data providers to all be providing compute services of various specialized flavors.</p>\n<p><a href=\"https://www.eigenlayer.xyz/\" rel=\"noopener nofollow ugc\">EigenLayer</a> provides a set of smart contracts and coordination infrastructure with which Ethereum validators can make commitments to operate additional services (AVSs), and “restake” their existing ETH staking bonds to provide security for those services (in the sense that these bonds can be slashed if the services are not performed as promised). The services performed by these validators could include ordering, storage, and compute as described here.</p>\n<p>Anoma’s service commitment languages can help both users and operators - the demand and supply sides of this service provisioning market - detail what services they are willing to provide, navigate through the services on offer, bargain for a mutually acceptable price, detect if service commitment properties have been violated, and publish evidence of defection in a standard way that can be embedded into network history and preserved as a reputation signal for future participants.</p>\n<h4><a name=\"topology-implementation-requirements-31\" class=\"anchor\" href=\"https://ethresear.ch#topology-implementation-requirements-31\"></a>Topology implementation requirements</h4>\n<p>What would be required to support these varied possible topologies? Just two main ingredients, I think: an Anoma <em>protocol adapter</em> and an Anoma <em>node sidecar</em>. I will describe each of these in turn.</p>\n<p>The Anoma <em>protocol adapter</em> is a smart contract or set of smart contracts - primarily written for the EVM, but variants could be written for other VMs or execution environments - which emulate the resource machine and thus allow for execution of Anoma-formatted transactions, synchronization of Anoma-formatted state, and verification of state changes executed elsewhere on the Anoma network.<br>\nThere may be some efficiency loss in execution emulation, but there shouldn’t be too much: since the resource machine does not fix a particular instruction set or message-passing architecture, these transactions can simply use EVM bytecode to compute new resource values and the EVM’s message-passing architecture to pass messages between different contracts required for the computation. Verification with succinct ZKPs is constant-cost anyways, so no problems there. Should the Anoma application model prove safe and popular, the EVM could easily enshrine it with a few precompiles for native performance.</p>\n<blockquote>\n<p>Slight aside: solvers will get to have some fun in this model in a pro-public-good way: now they get to compete on optimizing JIT EVM compilers, the software created for which could probably aid other languages and systems trying to target the EVM.</p>\n</blockquote>\n<p>The Anoma <em>node sidecar</em> is a process which would run alongside and communicate bidirectionally with Ethereum execution &amp; consensus clients, rollup sequencer processes, solver/searcher algorithms, etc. The node sidecar process runs all the Anoma network protocols, allowing nodes running the sidecar to connect to other Anoma nodes, subscribe to intents which are of interest to them, and solve, order, and execute as desired. This sidecar would be fully opt-in and configurable per the node operator’s preferences in terms of who they want to connect to (or not), what services they want to offer, what intents they want to receive (or even send), and how they want to process or forward them. If the node operator solves two intents to create an EVM transaction with the protocol adapter, they can submit it directly to their local web3 HTTP API - minimum latency, maximum throughput!</p>\n<p>What would this intent dataflow look like visually? Something like this:</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/3/3294ba703a672efe0a0f167477ede160368535de.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/3294ba703a672efe0a0f167477ede160368535de\" title=\"Intent dataflow\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/3/3294ba703a672efe0a0f167477ede160368535de_2_689x485.jpeg\" alt=\"Intent dataflow\" data-base62-sha1=\"7dswo2fyFraOw4kejIqWoDw4Xgi\" width=\"689\" height=\"485\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/3/3294ba703a672efe0a0f167477ede160368535de_2_689x485.jpeg, https://ethresear.ch/uploads/default/optimized/2X/3/3294ba703a672efe0a0f167477ede160368535de_2_1033x727.jpeg 1.5x, https://ethresear.ch/uploads/default/original/2X/3/3294ba703a672efe0a0f167477ede160368535de.jpeg 2x\" data-dominant-color=\"EEEDEC\"></a></div><p></p>\n<p><em>Diagram credit <a class=\"mention\" href=\"https://ethresear.ch/u/0xapriori\">@0xapriori</a></em></p>\n<h2><a name=\"challenges-and-trade-offs-32\" class=\"anchor\" href=\"https://ethresear.ch#challenges-and-trade-offs-32\"></a>Challenges and trade-offs</h2>\n<p>Nothing new is without challenges or trade-offs. I don’t want to paint with too rosy a brush here - plenty remains to be figured out, and plenty could go wrong. I see three main challenges (and I’m sure there are many which I miss):</p>\n<ul>\n<li><em>Implementation risk</em>: Anoma, although mathematically characterized at a high-level, is not yet fully implemented. We’re working to reduce uncertainty and risk here by conducting and publishing more research, writing a formal model of the protocol stack in Isabelle/HOL, and developing an initial node implementation in Elixir (to be released soon) - but there could still be mistakes in our current understanding, and there are plenty of details we need to get right (which will always be the case with any new architecture)</li>\n<li><em>Hardware requirements</em>: compared to just running a vanilla Ethereum full node, running an Ethereum full node plus the Anoma sidecar will increase resource usage somewhat. Different node operators can pick and choose which kinds of extra messages they want to receive and process, which should help, but perhaps full node operators and solo stakers are already strained to the limit. An interesting option could be to enmesh the two protocols more closely together in order to support more points in the spectrum in between light nodes and full nodes (related to the rainbow staking concept).</li>\n<li><em>Developer education</em>: writing applications for Anoma is very different not only from writing applications for the EVM or other blockchains, but even from writing applications in imperative, computation-ordering-oriented languages at all - in a certain sense, it’s more akin to a kind of declarative object-oriented programming, where you define which kinds of objects exist (resource kinds), how they can change (resource logics), and what actions users can take with them (application actions). Personally, I find this model much easier to work with after getting used to it - it provides a lot of expressive power - but it will take developers some time to learn.</li>\n</ul>\n<h2><a name=\"request-for-comment-33\" class=\"anchor\" href=\"https://ethresear.ch#request-for-comment-33\"></a>Request for comment</h2>\n<p>Thank you for reading this far! These are my initial thoughts, and I’d love to know what you think. I have four specific questions - or respond with anything you like.</p>\n<ol>\n<li>Of what I describe here, what makes sense to you? What doesn’t make sense?</li>\n<li>What challenges, risks, or trade-offs do you see that I didn’t cover?</li>\n<li>What do you think would be most valuable to the Ethereum community for us to focus on?</li>\n<li>What would you - or a team or project you know - like to collaborate on? Who should we talk to?</li>\n</ol>\n<p>Cheers!</p>\n            <p><small>13 posts - 6 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/rfc-draft-anoma-as-the-universal-intent-machine-for-ethereum/19109\">Read full topic</a></p>","link":"https://ethresear.ch/t/rfc-draft-anoma-as-the-universal-intent-machine-for-ethereum/19109","pubDate":"Mon, 25 Mar 2024 22:13:49 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19109"},"source":{"@url":"https://ethresear.ch/t/rfc-draft-anoma-as-the-universal-intent-machine-for-ethereum/19109.rss","#text":"[RFC] [DRAFT] Anoma as the universal intent machine for Ethereum"}},{"title":"Towards Scalable Ethereum Staking: The Imperative of Stateless Clients with Compact Proof Sizes","dc:creator":"sogolmalek","category":"Economics","description":"<p><strong>TL;DR:</strong> Ethereum’s scalability and security hinge on addressing the burgeoning state size issue and mitigating the risks posed by consensus bugs. Choosing less prevalent clients becomes crucial for stakers to minimize correlated failures. Transitioning to stateless clients with compact proof sizes offers a promising solution, decoupling historical state storage from transaction processing and enhancing scalability while preserving network integrity.</p>\n<p><strong>Introduction:</strong><br>\nTo address Ethereum’s scalability and security imperatives, a paradigm shift towards stateless clients with compact proof sizes is imperative. Stateless clients offer a pragmatic approach to alleviating the burden of state size on network participants by decoupling historical state storage from transaction processing.</p>\n<p>Furthermore,  picking the right Ethereum client is really important. If many validators using the same client mess up, the consequences get worse. So, people who stake Ethereum and use less popular clients reduce their risk of losing everything. But if they stick with the popular clients, they could lose everything if things go wrong. So, it’s important for responsible stakers to choose less common clients to protect against big problems in the system.</p>\n<p>The different Ethereum clients add another layer of difficulty, especially because of the constant worry about “consensus bugs.” These bugs, like the one that caused the “infinite money supply,” can mess up the network and make Ether less valuable. Although people are trying to make the clients stronger, there’s still a risk of everything going wrong because there’s no way to directly fix the problems caused by too much data.</p>\n<p>So, picking the right Ethereum client is a big deal for staking. If lots of validators using the same client make mistakes, the punishments get worse. That’s why people need to choose less popular clients to reduce the risks and keep the network running smoothly.</p>\n<p>Dankrad Feist has an <a href=\"https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html\" rel=\"noopener nofollow ugc\">inisghtful article</a> explains the concerns in details.</p>\n<p><strong>Evolution Towards Stateless Clients with Compact Proof Sizes:</strong><br>\nAddressing Ethereum’s scalability and resilience imperatives demands a transformative shift towards stateless clients augmented by compact proof sizes. Stateless clients, by decoupling historical state data storage from transaction processing, offer a promising avenue to alleviate the burden of burgeoning state size on network participants.</p>\n<p>At the core of this transition lies the imperative to devise mechanisms for succinctly representing transaction validity, while minimizing computational overhead using Zero-Knowledge proofs. we recognize that the slashing protection history is a critical database that records a validator’s local signing history. This database plays a vital role in preventing validators from signing slashable messages by keeping track of previously signed messages. The failure to migrate this database during system upgrades or client switches puts validators at risk of duplicative actions, potentially leading to severe penalties under the slashing protocol.</p>\n<p>Our EIP-X proposal centers around Creating a peer-to-peer (P2P) network of light clients leveraging Zero-Knowledge Proofs (ZKPs) for the validation of Ethereum block headers, specifically the last finalized block at the beacon chain and  presents a novel approach to enhancing the scalability, security, and efficiency of the Ethereum network without changing the core structure. It can be considered as a PIC of Verkle tree plans. This proposal outlines the technical foundation and goals for implementing such a system, with an emphasis on the Ethereum Portal Network and its potential to support this innovative solution.</p>\n<p>Integrating Zero-Knowledge Proofs (ZKPs) can significantly enhance this framework by offering a more scalable and secure approach to managing and verifying the slashing protection history without compromising on privacy or the integrity of validators’ signing history. ZKPs can allow validators to prove that they have not signed any slashable messages in the past without revealing the specific details of the messages they have signed. This capability is particularly relevant in the context of stateless clients, where the emphasis is on minimizing the storage requirements and computational overhead on validators.</p>\n<p><strong>Integrating zk-SNARK proofs of witness could potentially save both gas and disk space:</strong></p>\n<p>There’s a significant reduction in gas costs, which can lead to lower transaction fees and improved efficiency on the network.<br>\nThe disk space savings, while smaller, contribute to reducing the storage requirements, which can be particularly beneficial for nodes with limited resources.<br>\nThis analysis doesn’t account for the computational cost and time of generating zk-SNARK proofs, which is significant (around 3 seconds and 106 MB of memory for generation). These factors would need to be considered when evaluating the overall benefits and trade-offs of implementing such a system.<br>\n<a href=\"https://eips.ethereum.org/EIPS/eip-2929\" rel=\"noopener nofollow ugc\">EIP-2929</a> introduces a  simpler gas cost schedule that directly charges for accessing  subtree  and an element within the subtree. however Its interesting to explore the pptential optimization of gas cost used and disc resources for ZKP of blockwitness in the meanwhile where Verkle tries are under development.</p>\n<p>Comparing with Verkle tries, which aim to optimize storage and access through a different approach, zk-SNARKs offer a complementary strategy by providing privacy and compression benefits. The choice between using Verkle tries and zk-SNARKs (or a combination of both) would depend on the specific requirements of the application, including the need for privacy, the amount of data to be stored, and the computational resources available for proof generation.</p>\n<p>Vitalik has a brilliant and insightful <a href=\"https://notes.ethereum.org/@vbuterin/witness_gas_cost_2#Simple-Summary\" rel=\"noopener nofollow ugc\">proposal</a> on redesign how witness gas costs would work in a more principled way that covers accounts, storage slots and contract code and the witness lengths of each one after a switch to Verkle trees.<br>\nI’ve used that insight to estiamte **potential improvement in gas cost and resrouce usage of ZKP **(snark) of witness for EIP-x proposal:</p>\n<p><strong>Step 1:</strong> Calculate Traditional Witness Gas Costs<br>\nAverage Gas Per Byte (Traditional): Given as 9.5 gas.<br>\nAverage Witness Size: Given as 200 bytes.<br>\nCalculate Gas Cost for Traditional Witness:<br>\nFormula: Average Gas Per Byte (Traditional) * Average Witness Size<br>\nCalculation: 9.5 gas/byte * 200 bytes = 1,900 gas</p>\n<p><strong>Step 2:</strong> Estimate zk-SNARKs Gas Costs<br>\nFor zk-SNARKs, the direct gas cost per byte wasn’t provided, so we used the same average gas per byte as the traditional method for comparison purposes.</p>\n<p>Assumed Average Gas Per Byte (zk-SNARKs): 9.5 gas (same as traditional for comparison).<br>\nzk-SNARK Proof Size: Given as 128 bytes.<br>\nCalculate Gas Cost for zk-SNARKs:<br>\nFormula: Average Gas Per Byte (zk-SNARKs) * zk-SNARK Proof Size<br>\nCalculation: 9.5 gas/byte * 128 bytes = 1,216 gas</p>\n<p><strong>Step 3:</strong> Calculate Gas Savings with zk-SNARKs<br>\nDifference in Gas Costs: Subtract the zk-SNARKs gas cost from the traditional witness gas cost.<br>\nCalculation: 1,900 gas (Traditional) - 1,216 gas (zk-SNARKs) = 684 gas saved<br>\nStep 4: Calculate Disk Space Savings<br>\nDifference in Disk Space Requirements: Subtract the zk-SNARK proof size from the average traditional witness size.<br>\nCalculation: 200 bytes (Traditional) - 128 bytes (zk-SNARKs) = 72 bytes saved</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/4/4f908d60e6a78d6ba84791bd463325d3c679036c.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/4f908d60e6a78d6ba84791bd463325d3c679036c\" title=\"Bildschirmfoto 2024-03-24 um 13.43.51\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/4/4f908d60e6a78d6ba84791bd463325d3c679036c_2_690x415.jpeg\" alt=\"Bildschirmfoto 2024-03-24 um 13.43.51\" data-base62-sha1=\"blRq9ZpXXQ0RPnkTscC3Ljgs4CE\" width=\"690\" height=\"415\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/4/4f908d60e6a78d6ba84791bd463325d3c679036c_2_690x415.jpeg, https://ethresear.ch/uploads/default/optimized/2X/4/4f908d60e6a78d6ba84791bd463325d3c679036c_2_1035x622.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/4/4f908d60e6a78d6ba84791bd463325d3c679036c_2_1380x830.jpeg 2x\" data-dominant-color=\"E9C1C1\"></a></div><p></p>\n<p>Here’s a summary of the comparison between traditional witness data and using zk-SNARKs, displayed in both a table and a chart:<br>\n</p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/b/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1.png\" data-download-href=\"https://ethresear.ch/uploads/default/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1\" title=\"Bildschirmfoto 2024-03-24 um 13.44.03\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/b/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1_2_690x110.png\" alt=\"Bildschirmfoto 2024-03-24 um 13.44.03\" data-base62-sha1=\"p74WtAOYQBqGDj4neEP5QdjdFvz\" width=\"690\" height=\"110\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/b/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1_2_690x110.png, https://ethresear.ch/uploads/default/optimized/2X/b/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1_2_1035x165.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/b/b0033976833d63ca0a55b8da6eb6fdf840cc1ef1_2_1380x220.png 2x\" data-dominant-color=\"F3F3F3\"></a></div><p></p>\n<p>**Futhre Comprehension between  ZKP and Verkle trie: **<br>\nVerkle trees provide a more efficient method for generating and verifying proofs in scenarios involving a large number of operations, with their verification process being fast and cost-effective for adding additional proofs. zk-SNARKs, while offering strong privacy and succinct proofs, require more time for proof generation and incur a significant cost for verification. The choice between the two would depend on the specific application requirements, including the importance of proof generation time, verification costs, and the scalability needs for handling multiple proofs or commitments.To compare the computational and verification costs between Verkle trees and zk-SNARKs, we’ll outline the key metrics for each method based on the provided data. The comparison will focus on the proof generation time, verification time, and the verification cost where applicable.</p>\n<h3><a name=\"verkle-trees-1\" class=\"anchor\" href=\"https://ethresear.ch#verkle-trees-1\"></a>Verkle Trees</h3>\n<h4><a name=\"prover-cost-2\" class=\"anchor\" href=\"https://ethresear.ch#prover-cost-2\"></a>Prover Cost:</h4>\n<ul>\n<li><strong>Operations per Opening:</strong> 256 * 4 field operations.</li>\n<li><strong>Total for 25,000 Openings:</strong> Based on 5,000 proofs leading to 25,000 openings (an extrapolation from the data provided), the total operations would be significantly higher. However, the exact operations for 25,000 openings aren’t directly provided but can be inferred to require substantial computational effort.</li>\n<li><strong>Proof Generation Time:</strong> Approximately 750 milliseconds for 5,000 proofs.</li>\n</ul>\n<h4><a name=\"verifier-cost-3\" class=\"anchor\" href=\"https://ethresear.ch#verifier-cost-3\"></a>Verifier Cost:</h4>\n<ul>\n<li><strong>Multi-Scalar Multiplications (MSM) Size:</strong> For 5,000 proofs leading to 15,000 commitments, the MSM size is 15,000.</li>\n<li><strong>Verification Time:</strong> Approximately 50-150 milliseconds.</li>\n<li><strong>Marginal Cost for Another Opening:</strong> Very low, in the order of hundreds of nanoseconds.</li>\n</ul>\n<h3><a name=\"zk-snarks-4\" class=\"anchor\" href=\"https://ethresear.ch#zk-snarks-4\"></a>zk-SNARKs</h3>\n<h4><a name=\"prover-cost-5\" class=\"anchor\" href=\"https://ethresear.ch#prover-cost-5\"></a>Prover Cost:</h4>\n<ul>\n<li><strong>Proof Generation Time:</strong> On average, 10-15 minutes (a significant difference compared to Verkle trees).</li>\n<li><strong>Note:</strong> The computational cost in terms of field operations isn’t directly provided for zk-SNARKs but is known to be substantial due to the complex cryptographic computations involved.</li>\n</ul>\n<h4><a name=\"verifier-cost-6\" class=\"anchor\" href=\"https://ethresear.ch#verifier-cost-6\"></a>Verifier Cost:</h4>\n<ul>\n<li><strong>Verification Cost:</strong> 500,000 GWEI.</li>\n</ul>\n<h3><a name=\"comparison-summary-7\" class=\"anchor\" href=\"https://ethresear.ch#comparison-summary-7\"></a>Comparison Summary</h3>\n<ul>\n<li><strong>Proof Generation Time:</strong> Verkle trees are significantly faster in proof generation (milliseconds vs. minutes for zk-SNARKs).</li>\n<li><strong>Verifier Efficiency:</strong> Verkle trees offer a fast verification process (50-150 ms) without specifying a cost in GWEI, whereas zk-SNARK verification costs 500,000 GWEI. The time for zk-SNARK verification isn’t provided but is generally considered to be fast, often in the milliseconds range.</li>\n<li><strong>Scalability for Multiple Proofs:</strong> Verkle trees have a very low marginal cost for additional openings, enhancing scalability within the same commitment. zk-SNARKs have a fixed proof size and verification cost, independent of the number of operations proved.</li>\n</ul>\n<p><strong>Objectives</strong></p>\n<p>The Ethereum network is evolving to enhance scalability and minimize the burden on nodes by reducing the volume of data they need to handle. Traditional approaches where light clients individually request data from full nodes can significantly strain the network, especially when multiple clients make concurrent requests. To address this, a new method proposed in EIP-X focuses on leveraging the beacon chain’s events. When a new block is finalized, a witness of the previous block is generated, and a zero-knowledge proof (ZKP) of that witness is created. This ZKP is then sent in a single message over the Ethereum communication protocol, Discv5, effectively disseminating all the necessary data to all participating peer-to-peer (P2P) nodes in the Trin portal network with a single call. Stateless clients, which rely on proofs rather than storing the entire state for transaction execution, are fundamental to this advancement. This solution aims to utilize ZKPs to authenticate block headers and the transitions of state they imply, within a P2P network of light clients operating on the Portal Network, thereby streamlining data verification and transmission across the network.</p>\n<p><strong>Technical Proposal Overview</strong></p>\n<ul>\n<li>\n<p>Portal Network as the Foundation: The Portal Network is designed to improve the scalability and decentralization of the Ethereum network by allowing nodes to store and serve only a subset of the entire blockchain state. It’s a network of light clients that support Ethereum’s vision of a more accessible and efficient blockchain. By leveraging the Portal Network, we can facilitate a distributed environment where light clients efficiently verify and relay block information without needing the complete blockchain state【Portal Network Introduction】.</p>\n</li>\n<li>\n<p>Integration with Zero-Knowledge Proofs: At the heart of this proposal is the use of ZKPs to ensure the integrity and correctness of the block headers shared among the light clients. ZKPs can compactly prove that a block header is correct and that the transactions it contains have been accurately processed, without revealing the entire transaction data or state changes. This mechanism significantly enhances privacy and efficiency, as it allows for the verification of transactions with minimal data requirements. (Using geth ) challenge: new fork</p>\n</li>\n</ul>\n<p><strong>Communication protocol:</strong></p>\n<p>To effectively utilize the Discv5 messaging protocol for propagating Zero-Knowledge Proofs (ZKPs) across all light client recipients on the Portal Network, it is necessary to introduce a custom message type specifically designed for ZKP dissemination. The Discv5 protocol accommodates various message types, facilitating a range of network activities including peer discovery, information sharing, and data synchronization. Each message type is associated with a request and a corresponding response, ensuring a coherent communication flow.<br>\nProposed Enhancement:<br>\nCustom ZKP Message Type Implementation:<br>\nDefinition of a Custom Message Type for ZKPs: To streamline the propagation of ZKPs, a new custom message type within the Discv5 protocol must be defined. This message type will be exclusively used for transmitting encrypted ZKP data to light clients on the Portal Network.<br>\nUnique Message ID for ZKP Messages: Upon receiving a ZKP message, nodes will identify the message type through a distinct message ID designated for ZKP content. This identification process is crucial for nodes to recognize the received data as a ZKP and to respond appropriately.<br>\nNetwork Adaptation to Support New Message Type: For the seamless integration and support of the new ZKP message type, the entire P2P network must update to recognize and process the new message ID. This adaptation ensures that ZKP messages are correctly handled and propagated across the network.<br>\nRole of Custom Messages in Network Connectivity:<br>\nThese custom messages are pivotal in enhancing the network’s connectivity and efficiency. By allowing nodes to accurately locate peers, exchange ZKPs, and maintain up-to-date state information, the network can achieve higher levels of security and scalability. The integration of ZKPs, coupled with the Discv5 messaging protocol, enables a robust framework for stateless client operation within the Ethereum ecosystem.</p>\n<ul>\n<li>\n<p>P2P Network of Light Clients Using ZKPs: Light clients on this network will operate by receiving ZKPs of the last finalized block’s header. This header includes a root hash that represents the state changes made by transactions within the block. The clients will use these proofs to verify the integrity and correctness of the state transitions, ensuring they are consistent with the Ethereum protocol rules.</p>\n</li>\n<li>\n<p>Portal Subnetwork for State Verification: To facilitate consensus and state verification in a stateless manner, the plan includes the creation of a Portal subnetwork dedicated to comparing ZKPs of the last known state with the current state. This comparison verifies that state transitions are legitimate and that the block being proposed for inclusion in the blockchain is valid. This subnetwork will play a crucial role in maintaining the security and integrity of the blockchain while minimizing the computational and storage overhead for participants.</p>\n</li>\n</ul>\n<p>For more details on the Portal Network and its potential, refer to the Ethereum Portal Network documentation and resources:</p>\n<ul>\n<li><a href=\"https://ethereum.github.io/trin/introduction/index.html\" rel=\"noopener nofollow ugc\">Ethereum Portal Network Introduction</a></li>\n<li><a href=\"https://ethereum.org/de/developers/docs/networking-layer/portal-network/\" rel=\"noopener nofollow ugc\">Ethereum Developers Portal Network</a></li>\n<li><a href=\"https://github.com/sogolmalek/EIP-x\" rel=\"noopener nofollow ugc\">EIP-x github</a></li>\n<li><a href=\"https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html\" rel=\"noopener nofollow ugc\">Ethereum Merge: Run the majority client at your own peril!-Dankrad Feist</a></li>\n</ul>\n            <p><small>2 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/towards-scalable-ethereum-staking-the-imperative-of-stateless-clients-with-compact-proof-sizes/19105\">Read full topic</a></p>","link":"https://ethresear.ch/t/towards-scalable-ethereum-staking-the-imperative-of-stateless-clients-with-compact-proof-sizes/19105","pubDate":"Mon, 25 Mar 2024 08:44:16 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19105"},"source":{"@url":"https://ethresear.ch/t/towards-scalable-ethereum-staking-the-imperative-of-stateless-clients-with-compact-proof-sizes/19105.rss","#text":"Towards Scalable Ethereum Staking: The Imperative of Stateless Clients with Compact Proof Sizes"}},{"title":"How to purchase Ethereum GAS in advance","dc:creator":"web3skeptic","category":"Applications","description":"<h2><a name=\"abstract-1\" class=\"anchor\" href=\"https://ethresear.ch#abstract-1\"></a>Abstract</h2>\n<p>This topic introduces a method for purchasing gas on Ethereum. Technically it is a fully on-chain Ethereum gas futures market. The volatility of gas prices, primarily driven by network demand fluctuations, significantly obstructs user experience on Ethereum due to unpredictable costs. This solution aims to mitigate that issue.</p>\n<h2><a name=\"protocol-description-2\" class=\"anchor\" href=\"https://ethresear.ch#protocol-description-2\"></a>Protocol Description</h2>\n<h3><a name=\"general-3\" class=\"anchor\" href=\"https://ethresear.ch#general-3\"></a>General</h3>\n<p>The protocol users might be divided into to parties, gas purchasers (Purchaser) and gas providers (Executors)</p>\n<p>The general protocol workflow has these stages:</p>\n<ol>\n<li>Purchaser: Listing order</li>\n<li>Executor: Accepting order</li>\n<li>Purchaser: Requesting transaction execution</li>\n<li>Executor: Executing transaction</li>\n<li>Anyone: Liquidating executor</li>\n</ol>\n<h4><a name=\"listing-order-4\" class=\"anchor\" href=\"https://ethresear.ch#listing-order-4\"></a>Listing order</h4>\n<p>It is required to place order conditions onchain regarding the execution timeframe, gas price, and the expected security from the Executor, also the Purchaser locks the reward tokens responsible of paying the gas: <code>gasCost * gasAmount</code>.</p>\n<p>The GasOrder should include such fields:</p>\n<pre data-code-wrap=\"sol\"><code class=\"lang-plaintext\">struct GasOrder {\n    uint256 gasAmount; // The amount of Gas to book for future executions\n    uint256 executionPeriodStart; // Start timestamp when it is possible to use the gas within the order\n    uint256 executionPeriodDeadline; // End timestamp when it is possible to use the gas within the order\n    uint256 executionWindow; // This variable defines a window, measured in blocks, within which a\n    // transaction must be executed. This constraint is designed to optimize timing and prevent delays, while \n    // also safeguarding against the exploitation of gas price fluctuations by malicious actors.\n    TokenTransfer gasCost; // The cost of one Gas unit\n    TokenTransfer guarantee; // The guarantee security required from the Executor\n}\n</code></pre>\n<h4><a name=\"accepting-order-5\" class=\"anchor\" href=\"https://ethresear.ch#accepting-order-5\"></a>Accepting order</h4>\n<p>Some Executor accept the conditions of the GasOrder, and locks the guarantee. The guarantee security is execpected to be proportional to the purchased amount of Gas.</p>\n<h4><a name=\"requesting-transaction-execution-6\" class=\"anchor\" href=\"https://ethresear.ch#requesting-transaction-execution-6\"></a>Requesting transaction execution</h4>\n<p>When the GasOrder execution timeframe comes, the user might request transaction execution by signing the data structure with the transaction details.</p>\n<pre data-code-wrap=\"solidity\"><code class=\"lang-plaintext\">Message {\n  address from;\n  uint256 nonce;\n  uint256 gasOrder; // number of the employed order\n  uint256 deadline; // deadline of the msg execution, should be within the range of order execution\n  address to; // the contract which is being called\n  uint256 gas; // gas limit to spend\n  uint256 tips; // tips to the party which pushes the tx request onchain\n  bytes data; // execution request details\n  bytes signature; // the signature by the sender\n}\n</code></pre>\n<p>After the transaction is signed the hash of it should be published onchain. It might be done by transaction requester itself, or by anyone else. To incentives the posting the transaction request onchain the signer specifies the <code>tips</code>. The tips represents the Gas within the GasOrder which will be burned and the respective share of reward will be directed to the transaction request submitter.</p>\n<p>Executor takes the signed data and calls the <code>to</code> contract from function within the protocol which executes the call with the <code>data</code> from the <code>Message</code>. Consecuently the call unlocks the share of the reward and the guarantee for the Executor.</p>\n<p>If the transaction is not Executed because it is not profitable for the Executor than the Executor might be liquidated, it might be implemented in few ways, centralized and decentralized, lets review the decentralized version.</p>\n<h4><a name=\"decentralized-liquidation-logic-7\" class=\"anchor\" href=\"https://ethresear.ch#decentralized-liquidation-logic-7\"></a>Decentralized liquidation logic</h4>\n<p>During the transaction request, the transaction hash is posted on-chain, also the signature and remaining <code>Message</code> data posted as a calldata to be publicly available.</p>\n<p>If the Executor fails to execute the transaction before the <code>Message.deadline</code>, anyone can do so by providing the necessary data from the <code>Message</code> before the <code>deadline + CONSTANT_LIQUIDATION_TIME</code>. In return, the executor’s guarantee is partially forfeited, and the Liquidator requester receives a reward.</p>\n<h3><a name=\"bottlenecks-8\" class=\"anchor\" href=\"https://ethresear.ch#bottlenecks-8\"></a>Bottlenecks</h3>\n<h4><a name=\"executor-incentive-9\" class=\"anchor\" href=\"https://ethresear.ch#executor-incentive-9\"></a>Executor incentive</h4>\n<p>Executor incentives rely on adjusting GasCost to accommodate risk. As gas prices are unpredictable, Executors mitigate risks by charging extra. This flexible pricing model, determined by Executors, may evolve from sporadic agreements to a more standardized market, resulting in better price averages over time.</p>\n<h4><a name=\"gas-consumption-10\" class=\"anchor\" href=\"https://ethresear.ch#gas-consumption-10\"></a>Gas consumption</h4>\n<p>The protocol’s viability hinges on surpassing a certain threshold, as it necessitates gas for order publication, acceptance, signature verification, and transaction execution.</p>\n<h4><a name=\"split-of-liquidity-11\" class=\"anchor\" href=\"https://ethresear.ch#split-of-liquidity-11\"></a>Split of liquidity</h4>\n<p>Tokenizing each Gas order is straightforward, yet trading shares between orders poses a challenge due to their differing parameters. While securitization of long-term orders seems a plausible solution, preventing liquidity fragmentation remains elusive at present.</p>\n<h4><a name=\"lock-of-guarantee-12\" class=\"anchor\" href=\"https://ethresear.ch#lock-of-guarantee-12\"></a>Lock of guarantee</h4>\n<p>Executors must lock guarantees to deter liquidation risks, yet this restricts their flexibility. The locked guarantee could otherwise be utilized for liquidity elsewhere to generate yield. One potential solution is to lock tokens which represent shares in farming pools, enabling yield generation while locked. However, this introduces additional risks for gas Purchasers parties, as farming protocols entail additional security assumptions and associated risks.</p>\n<p>P.S. I’m really interested to get the feedback on the proposed mechanism</p>\n            <p><small>6 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/how-to-purchase-ethereum-gas-in-advance/19069\">Read full topic</a></p>","link":"https://ethresear.ch/t/how-to-purchase-ethereum-gas-in-advance/19069","pubDate":"Thu, 21 Mar 2024 17:34:01 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19069"},"source":{"@url":"https://ethresear.ch/t/how-to-purchase-ethereum-gas-in-advance/19069.rss","#text":"How to purchase Ethereum GAS in advance"}},{"title":"Addressing systemic risks – discouragement attacks against centralized validator sets","dc:creator":"themandalore","category":"Uncategorized","description":"<p>This post describes a new discouragement attack which can reduce attestation and sync committee rewards of a targeted actor. This attack can theoretically be used to reduce a concentrated actor’s attestation and sync committee participation and reduces their rewards almost directly proportional to the number of validators participating in the attack.</p>\n<p>Of the options looked at, this attack was the one with the highest likelihood to achieve a finalized chain state with the following properties:</p>\n<ul>\n<li>reduced concentrated actor(CA) validator share</li>\n<li>reduced CA rewards</li>\n<li>minimal/nonexistent penalty to participating validators</li>\n<li>still Ethereum (aka not a minority fork)</li>\n</ul>\n<p><em>back to the start - identifying validators</em></p>\n<p>The first step to targeting a validator(s) is figuring out how to identify them. Ethereum PoS validators are not identified by address but by validator index. So rather than target validators set by public key, we must map their address to a valid Index. Since every validator is assigned a validator index upon depositing, we can create a map of validator indices by looking at deposit events in the beacon contract. [1]</p>\n<p>Note that for some CA’s, finding their addresses may be difficult (e.g. a list of validators run by a CEX). Fortunately though, LST’s and restaking protocols are much more transparent in their inner workings, so the indices are relatively easy to gather. Also note that LST’s could simply upgrade to obfuscate this or hide; but this isn’t actually too bad. An LST or CEX that has the ability to hide from the social layer is also hiding from would-be regulators or attackers looking to bribe/influence the party.</p>\n<p>A simple example script for finding Lido validator indexes (as of Feb 2024) <a href=\"https://github.com/danflo27/LidoValidators\" rel=\"noopener nofollow ugc\">can be found here</a>.</p>\n<p><em>midwest discouragement attacks</em></p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/27b832436de0e0d44604db4d9d19c7a3feaf217d.jpeg\" data-download-href=\"https://ethresear.ch/uploads/default/27b832436de0e0d44604db4d9d19c7a3feaf217d\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/27b832436de0e0d44604db4d9d19c7a3feaf217d_2_225x449.jpeg\" alt=\"\" data-base62-sha1=\"5Fng8ailCHGwGOD3NvCdLBW80TH\" width=\"225\" height=\"449\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/27b832436de0e0d44604db4d9d19c7a3feaf217d_2_225x449.jpeg, https://ethresear.ch/uploads/default/optimized/2X/2/27b832436de0e0d44604db4d9d19c7a3feaf217d_2_337x673.jpeg 1.5x, https://ethresear.ch/uploads/default/optimized/2X/2/27b832436de0e0d44604db4d9d19c7a3feaf217d_2_450x898.jpeg 2x\" data-dominant-color=\"F3F3F4\"></a></div><p></p>\n<blockquote>\n<p>“Every slot a new committee becomes active and is expected to provide attestations. 440k validators / 64 committees = ~17k validators/committee. 17k validators poses a problem; it’s both too much network chatter and too many signatures to aggregate all at once. Fortunately, we’ve already split committees into 64 subnets. Each subnet consists of ~250 validators, of which 16 are designated as aggregators. As validators review blocks, they broadcast their attestations to their subnet. All 16 aggregators are attempting to build the same aggregate signatures, but network conditions often make perfection possible.”[2]</p>\n</blockquote>\n<p>Validators send attestations to committee subnet aggregators who then create an aggregated attestation that will be included in each block. To explain further, validators are partitioned into committees in each epoch, with one committee per slot. In each slot, one validator from the designated committee proposes a block. Then, all the members of that committee will attest to the newly proposed block and its position in the chain.[3] The goal of our modification is to make it so that when our validators are the subnet committee aggregators, they ignore CA attestations. Couple this with a selection rule that says when we are proposer, we only choose the aggregation that does not include CA validator attestations.</p>\n<p><em>more background</em></p>\n<p>There is a substantial overhead associated with passing attestation data around the network for every validator. Therefore, the attestations from individual validators are aggregated within subnets before being broadcast more widely.[4]</p>\n<p>During epochs where we have participating validators as the proposer AND aggregator, we can exclude a portion of attestations from CA validators in our blacklist set. Participating proposer clients will be modified such that rather than selecting the aggregation with the most attestations, they will choose the one with the most attestations and no CA attestations (a list of validator indices created from our participating aggregator). The probability for a given committee of having at least one of the aggregators and the proposer is as follows:</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/8/87907f11b34acec350a6b0c980871d1736f682d3.png\" data-download-href=\"https://ethresear.ch/uploads/default/87907f11b34acec350a6b0c980871d1736f682d3\" title=\"Chart\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/8/87907f11b34acec350a6b0c980871d1736f682d3_2_568x351.png\" alt=\"\" title=\"Chart\" data-base62-sha1=\"jlg2vQnAEgIzc0zumb8P8SKKOk3\" width=\"568\" height=\"351\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/8/87907f11b34acec350a6b0c980871d1736f682d3_2_568x351.png, https://ethresear.ch/uploads/default/optimized/2X/8/87907f11b34acec350a6b0c980871d1736f682d3_2_852x526.png 1.5x, https://ethresear.ch/uploads/default/optimized/2X/8/87907f11b34acec350a6b0c980871d1736f682d3_2_1136x702.png 2x\" data-dominant-color=\"FDFDFE\"></a></div><p></p>\n<p>A nice feature of this discouragement attack is that it scales almost identically with validator participation. What this means is that if you get 20% of the validators participating, you should be able to reduce CA attestation rewards by about 20%.[5]</p>\n<p>The downside for proposers here is that they would lose out on some attestation rewards as ⅛ of an attestation reward goes to the proposer. There is an argument to be made that participating validators will be open to losing this small amount as the CA (competing validators) will lose 7x the amount they amount will, thus making themselves more competitive and protecting the chain from centralization.</p>\n<p>The case where we have only the proposer (and no aggregator in a given committee) was also looked at. A participating validator could drop all aggregations with CA signatures (so have no attestations for a given committee), but then you would punish non-CA validators as well as CA validators if they were in the same subcommittee. Not to mention, the participating validator would lose more rewards, rewards which would not be offset necessarily by a decreased CA reward. For these reasons, this action is something that we will avoid, however we will need to look further into how to best include/exclude if target CA lists do match up perfectly (e.g. if you drop one honest validator is it ok if you’re still dropping 20 CA indices?).</p>\n<p><em>aftermath</em></p>\n<p><strong>consequences to the CA</strong>: Missing an attestation means missing rewards, about 84.4% of base rewards to be specific (see <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attestations/#rewards\" rel=\"noopener nofollow ugc\">here</a> for the exact rewards structure). Depending on block space, they could try to get attached to subsequent blocks for partial rewards, but from my understanding, it rarely happens and they would likely lose out on most attestation rewards as laid out in the analysis.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/2/24b123b146940a78f99d6b9428d93a92ce2b253b.png\" data-download-href=\"https://ethresear.ch/uploads/default/24b123b146940a78f99d6b9428d93a92ce2b253b\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/2/24b123b146940a78f99d6b9428d93a92ce2b253b_2_565x481.png\" alt=\"\" data-base62-sha1=\"5eAHV5QVarqiXBHknWWDf7ygX1h\" width=\"565\" height=\"481\" role=\"presentation\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/2/24b123b146940a78f99d6b9428d93a92ce2b253b_2_565x481.png, https://ethresear.ch/uploads/default/optimized/2X/2/24b123b146940a78f99d6b9428d93a92ce2b253b_2_847x721.png 1.5x, https://ethresear.ch/uploads/default/original/2X/2/24b123b146940a78f99d6b9428d93a92ce2b253b.png 2x\" data-dominant-color=\"F9F9F9\"></a></div><p></p>\n<p>Overall, any significant percentage of validators participating could be devastating to the CA with regard to staking competitively.</p>\n<p><strong>consequences to participating validators</strong>: Committee aggregators and proposers are incentivized to include as many valid attestations as they can see in their Aggregated Attestation. For every attestation the aggregator excludes, the reward decreases (see <a href=\"https://eth2book.info/capella/part2/incentives/rewards/#rewards-scale-with-participation\" rel=\"noopener nofollow ugc\">Rewards scale with participation</a>). In general, the rule for ETH2.0 is that “7/8 of rewards go to validators performing duties and 1/8 to the proposers including the evidence in blocks.” The aggregator and proposer both therefore would lose out like all ETH validators in the sense that total attestation rewards scale with participation as well, but there would be no direct punishment that would make the aggregator less competitive.[6,7]</p>\n<p><strong>consequences to the protocol</strong>: Of all discouragement attack options analyzed, excluding a limited number of attestations from certain parties seems to be the option with the lightest footprint. More research should be done on how this could affect fork-choice-rule, however theoretically it shouldn’t affect it (all else equal). One consideration to note is relative to the size of the CA. If the CA is &gt;33% of the validator set, you cannot ignore all their attestations, as it would affect block finality. Therefore you would need to limit the number of attestations ignored to only those greater than some threshold for finality.</p>\n<p><em>dousing the beacon - ignore sync committee messages</em></p>\n<p>In addition to attestations, we can reduce up to another 3.1% of CA rewards by doing a similar aggregation censoring in the sync committee. To briefly explain, Validators are rewarded for correctly participating in sync committee signatures (each day, 512 are chosen, so very rare), which are of use to light clients. This option may even be a preferable first step versus the attestation censorship, as the sync committee is not part of internal fork choice or even required for the main protocol at all.</p>\n<p>The same “rewards scale with participation” concept is present here, however the big difference is that we have no issues with finality, forks, or even chain issues at all, as the sync committee is for use in other protocols and not within Ethereum. That said, several light client bridge implementations take advantage of the sync committee to finalize transactions and would be affected if a large portion of the sync committee is owned by the blacklisted CA. Overall though, it seems a relatively light touch on the system, but the big downside is that the rewards here are relatively small and may not be enough to deter a CA. It might be useful to try out as a first step in testing support/ implementation issues.</p>\n<p><em>the journey is just beginning</em></p>\n<p>Other options should still be on table for addressing systemic risks, however this should be a great starting place for continuing discussions with stakeholders and developers in the Ethereum ecosystem as to the best path forward. I’m optimistic that just talking publicly about these options can be enough to deter a CA from growing any larger or maintaining threatening levels of control.</p>\n<p><strong>references</strong><br>\n[1] <a href=\"https://github.com/ethereum/annotated-spec/blob/master/phase0/beacon-chain.md\" rel=\"noopener nofollow ugc\">https://github.com/ethereum/annotated-spec/blob/master/phase0/beacon-chain.md</a><br>\n[2] <a href=\"https://inevitableeth.com/home/ethereum/network/consensus/pos\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Proof of Stake | Inevitable Ethereum</a><br>\n[3] <a href=\"https://arxiv.org/pdf/2003.03052.pdf\" rel=\"noopener nofollow ugc\">https://arxiv.org/pdf/2003.03052.pdf</a><br>\n[4] <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attestations/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Attestations | ethereum.org</a><br>\n[5] <a href=\"https://docs.google.com/spreadsheets/d/1H3Mux2noz2NfKC3A63VX3ZBH4q_KP0MMk3OQM4Ysxpc/edit#gid=1960537153\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Aggregator selection - Google Sheets</a><br>\n[6]<a href=\"https://eth2book.info/capella/part2/incentives/rewards/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Upgrading Ethereum | 2.8.4 Rewards</a><br>\n[7] <a href=\"https://eth2book.info/capella/part3/transition/block/#def_process_attestation\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Upgrading Ethereum | 3.5.3 Block processing</a></p>\n<p><strong>further reading</strong></p>\n<p>I’ve done a few other articles on social values / systemic risks too. The first article<a href=\"https://medium.com/@nfett/why-values-matter-social-flexing-in-crypto-f971b23167e2\" rel=\"noopener nofollow ugc\"> is here</a>, the second is <a href=\"https://medium.com/@nfett/social-flex-2-dangers-d4701f525d28\" rel=\"noopener nofollow ugc\">here</a>, and the third is <a href=\"https://medium.com/@nfett/social-flex-3-options-3788c3dd4b7a\" rel=\"noopener nofollow ugc\">here</a>.</p>\n<ul>\n<li>Vitalik’s Discouragement attacks: <a href=\"https://github.com/ethereum/research/blob/master/papers/discouragement/discouragement.pdf\" rel=\"noopener nofollow ugc\">https://github.com/ethereum/research/blob/master/papers/discouragement/discouragement.pdf</a></li>\n<li>Aggregation process:\n<ul>\n<li><a href=\"https://github.com/ethereum/consensus-specs/blob/dev/specs/phase0/validator.md#construct-aggregate\" rel=\"noopener nofollow ugc\">https://github.com/ethereum/consensus-specs/blob/dev/specs/phase0/validator.md#construct-aggregate</a></li>\n<li><a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attestations/#aggregated-attestation\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Attestations | ethereum.org</a></li>\n<li><a href=\"https://notes.ethereum.org/@hww/aggregation\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">A note on Ethereum 2.0 attestation aggregation strategies - HackMD</a></li>\n</ul>\n</li>\n<li>Sync protocol spec: <a href=\"https://github.com/ethereum/consensus-specs/blob/dev/specs/altair/light-client/sync-protocol.md\" rel=\"noopener nofollow ugc\">https://github.com/ethereum/consensus-specs/blob/dev/specs/altair/light-client/sync-protocol.md</a></li>\n<li>Rewards: <a href=\"https://eth2book.info/capella/part2/incentives/rewards/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Upgrading Ethereum | 2.8.4 Rewards</a></li>\n<li>Gasper paper: <a href=\"https://arxiv.org/pdf/2003.03052.pdf\" rel=\"noopener nofollow ugc\">https://arxiv.org/pdf/2003.03052.pdf</a></li>\n<li>Understanding the <a href=\"https://notes.ethereum.org/@vbuterin/serenity_design_rationale?type=view#LMD-GHOST-fork-choice-rule\" rel=\"noopener nofollow ugc\">fork choice rule</a></li>\n<li>Inactivity Leak: <a href=\"https://notes.ethereum.org/@vbuterin/serenity_design_rationale?type=view#Inactivity-leak\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Serenity Design Rationale - HackMD</a></li>\n<li>Ethereum PoS Attack and Defense: <a href=\"https://mirror.xyz/jmcook.eth/YqHargbVWVNRQqQpVpzrqEQ8IqwNUJDIpwRP7SS5FXs\" rel=\"noopener nofollow ugc\">https://mirror.xyz/jmcook.eth/YqHargbVWVNRQqQpVpzrqEQ8IqwNUJDIpwRP7SS5FXs</a></li>\n<li>Shout to Banteg for ideas: <a href=\"https://twitter.com/bantg/status/1561177300741283842\" rel=\"noopener nofollow ugc\">https://twitter.com/bantg/status/1561177300741283842</a></li>\n<li>Proof-of-Stake overview: <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Proof-of-stake (PoS) | ethereum.org</a></li>\n<li>Vitalik on Lex Friedman on the Social Layer: <a href=\"https://www.youtube.com/watch?v=3yrqBG-7EVE\" rel=\"noopener nofollow ugc\">https://www.youtube.com/watch?v=3yrqBG-7EVE</a></li>\n<li>Can nodes go against the protocol: <a href=\"https://hackmd.io/@prysmaticlabs/finality#Can-nodes-go-against-the-protocol\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">What Happens After Finality in ETH2? - HackMD</a></li>\n<li>Consensus and Execution client connections: <a href=\"https://ethereum.org/en/developers/docs/networking-layer/#connecting-clients\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Networking layer | ethereum.org</a></li>\n<li>Mitigating attacks in PoS <a href=\"https://ethresear.ch/t/change-fork-choice-rule-to-mitigate-balancing-and-reorging-attacks/11127\" class=\"inline-onebox\">Change fork choice rule to mitigate balancing and reorging attacks</a></li>\n<li>Cool Epoch and Slot Visualization: <a href=\"https://beaconcha.in/charts/slotviz\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Charts - Open Source Ethereum Blockchain Explorer - beaconcha.in - 2024</a></li>\n<li>Censorship in the PBS Stack: <a href=\"https://www.youtube.com/watch?v=WcJlseuhbX8\" rel=\"noopener nofollow ugc\">https://www.youtube.com/watch?v=WcJlseuhbX8</a></li>\n</ul>\n            <p><small>9 posts - 3 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/addressing-systemic-risks-discouragement-attacks-against-centralized-validator-sets/19067\">Read full topic</a></p>","link":"https://ethresear.ch/t/addressing-systemic-risks-discouragement-attacks-against-centralized-validator-sets/19067","pubDate":"Thu, 21 Mar 2024 13:41:02 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19067"},"source":{"@url":"https://ethresear.ch/t/addressing-systemic-risks-discouragement-attacks-against-centralized-validator-sets/19067.rss","#text":"Addressing systemic risks – discouragement attacks against centralized validator sets"}},{"title":"Public Projects with Preferences and Predictions","dc:creator":"bowaggoner","category":"Economics","description":"<p>A few years ago, I posted <a href=\"https://ethresear.ch/t/governance-mixing-auctions-and-futarchy/10772\">Governance mixing auctions and futarchy</a> here. Also relevant are <a href=\"https://ethresear.ch/t/practical-futarchy-setup/10339\">Practical Futarchy Setup</a> and <a href=\"https://ethresear.ch/t/votes-as-buy-orders-a-new-type-of-hybrid-coin-voting-futarchy/10305\">Votes as Buy Orders</a>. My post/question eventually led to research funding from the Ethereum Foundation and now my collaborator and I have a paper proposing a new governance mechanism: <a href=\"https://arxiv.org/abs/2403.01042\" rel=\"noopener nofollow ugc\"><strong>Public Projects with Preferences and Predictions</strong></a>. I hope you find it interesting and I would love to hear your feedback and thoughts! Here is a summary.</p>\n<hr>\n<p><strong>Problem:</strong> A group, such as members of a DAO, need to decide between one of several alternatives, such as which project to pursue (they must pick exactly one). I want to focus on two aspects of this problem:</p>\n<ul>\n<li>They want to base the decision on an aggregation of both <strong>preferences</strong> and <strong>information</strong>. For example, one way is to first hold discussions and conduct research in order to aggregate information. Then, if consensus is not reached, hold a vote to aggregate preferences into a final decision.</li>\n<li>A primary problem of any organization is to <strong>avoid capture</strong>. In particular, the individual preferences of the members are generally not perfectly aligned with the mission of the organization. The above “discuss-then-vote” approach doesn’t solve this. A decisionmaking mechanism should somehow be biased by a <em>credible</em> estimate of the impact on the organization’s mission.</li>\n</ul>\n<hr>\n<p><strong>Formalizing it:</strong> A group of agents must pick one of <span class=\"math\">m</span> alternatives. The group’s mission is quantified by what we call an “external welfare impact” of the decision. The goal is to maximize total welfare: the sum of the external welfare impact, plus the utilities of all the agents in the group. The group first wants to aggregate information, in particular about the external welfare impacts of each alternative choice it could make. We model information as predictions about the future, i.e. the group first wants to estimate the external welfare impact <span class=\"math\">B_k</span> of each alternative <span class=\"math\">k=1,\\dots,m</span>. After obtaining the estimates, the group will hold a vote. We suppose that each agent <span class=\"math\">i</span> has a preference over the alternatives, modeled as a value <span class=\"math\">v_k^i</span> for each alternative <span class=\"math\">k</span>. The group will use some sort of voting mechanism to combine the preferences as well as the external welfare impacts into a final decision.</p>\n<p>For example, consider a DAO whose charter requires consideration of climate impacts of its decisions. The external welfare impact <span class=\"math\">B_k</span> of an alternative <span class=\"math\">k</span> could be measured by the amount of extra tons of CO2 produced if that alternative is chosen. The DAO may still choose an alternative that produces more CO2 if the members as a whole strongly prefer that alternative.</p>\n<hr>\n<p><strong>Proposal:</strong> We propose it the <strong>Synthetic players QUAdratic transfers mechanism with Predictions (SQUAP)</strong>, and it works like this:</p>\n<ol>\n<li>We use an information-aggregation oracle to obtain an estimate of the external welfare impact <span class=\"math\">B_i</span> of each alternative. The oracle can be implemented in many possible ways, but in particular we consider using “decision markets” (i.e. sets of conditional prediction markets, as in futarchy).</li>\n<li>We use Quadratic Voting, specifically the Quadratic Transfers Mechanism studied by <a href=\"https://arxiv.org/abs/2301.06206\" rel=\"noopener nofollow ugc\">Eguia et al.</a> However, the mechanism casts “extra” votes based on <span class=\"math\">B_1,\\dots,B_m</span>.</li>\n</ol>\n<p>The extra votes are not simply the numbers <span class=\"math\">B_1,\\dots,B_m</span> for each alternative. Instead, they are the votes that “synthetic players” would cast in equilibrium of Quadratic Voting, if their total values for each alternative were <span class=\"math\">B_1,\\dots,B_m</span>. This is based on an analysis of the equilibrium, extending results of Eguia et al.</p>\n<hr>\n<p><strong>About the prediction markets:</strong> We need to suppose that the external welfare impact can be predicted before the fact and measured afterward. You can think of lots of ways to use proxies and estimates for quantities that are hard to measure or have long time horizons. For simplicity, in the paper we assume that if we take any decision <span class=\"math\">k</span>, then <span class=\"math\">B_k</span> will be directly observable and measurable. So we will set up <span class=\"math\">m</span> prediction markets, predicting for each alternative <span class=\"math\">k</span> the eventual impact <span class=\"math\">B_k</span> conditioned on making decision <span class=\"math\">k</span>. When we eventually make some decision <span class=\"math\">k</span>, we cancel all the trades in every market except the market for <span class=\"math\">k</span>. But we do eventually observe <span class=\"math\">B_k</span> for that chosen alternative and we resolve the market payoffs accordingly.</p>\n<p>The Quadratic Transfer Mechanism picks an alternative from a probability distribution, where the probability of taking decision <span class=\"math\">k</span> is <span class=\"math\">e^{A_k} / \\sum_{\\ell} e^{A_{\\ell}}</span> and <span class=\"math\">A_k</span> is total the number of votes cast for decision <span class=\"math\">k</span>. There is a nonzero probability of picking each alternative. That may sound odd, but it actually helps address a well-known problem with futarchy and decision markets – bad incentives around predictions about decisions that won’t actually be taken.</p>\n<hr>\n<p><strong>Formal results:</strong> Unfortunately, we can’t quite prove (yet) good results about SQUAP itself. However, we can analyze an “Impractical Variant” that is not practical because it requires some extra knowledge by the mechanism designer. Essentially, instead of calculating our synthetic votes based on what the real players vote for, we have to first commit to our synthetic votes based just on knowing <span class=\"math\">B_1,\\dots,B_m</span>, before we see what the players do. This is impractical to calculate without good estimates of what the players will do, but it’s not totally ridiculous. In any case, we can prove something:</p>\n<blockquote>\n<p><strong>Main Theorem.</strong> In the 2-alternative case, in Nash equilibrium, the Impractical Variant of SQUAP satisfies Social Welfare <span class=\"math\">\\to</span> Optimal as the “size” of the group grows large relative to the preferences of any one individual.</p>\n</blockquote>\n<p>The interesting and non-obvious part of all this is that the mechanism “works” in theory even though there are apparently bad incentives across the two stages. Someone with really strong preferences about the decision could try to manipulate the prediction market prices in order to manipulate the synthetic votes. And someone who bet a lot of money in the prediction market could try to cast really outsized votes in the Quadratic Voting stage in order to make their prediction-market payoffs come good. So the interesting part is in proving that these things don’t happen, or rather, they can happen a little but not enough to influence the outcome significantly … as long as each individual’s preferences are small compared to the group total.</p>\n<p>Our theorem quantifies the rate at which the social welfare approaches the optimal, and it’s reasonably fast as the size of the group grows large. But this post is too long already. I’ll just clarify that Social Welfare is formalized by the sum of the values of the participants in the group, plus the external welfare impact, of whatever the mechanism chooses.</p>\n            <p><small>2 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/public-projects-with-preferences-and-predictions/19024\">Read full topic</a></p>","link":"https://ethresear.ch/t/public-projects-with-preferences-and-predictions/19024","pubDate":"Sun, 17 Mar 2024 05:55:17 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19024"},"source":{"@url":"https://ethresear.ch/t/public-projects-with-preferences-and-predictions/19024.rss","#text":"Public Projects with Preferences and Predictions"}},{"title":"Fractal Scaling on Ethereum (Layer 3 Rollups)","dc:creator":"purpleshadow2000","category":"ZK Rollup","description":"<h2><a name=\"abstract-1\" class=\"anchor\" href=\"https://ethresear.ch#abstract-1\"></a><strong>ABSTRACT</strong></h2>\n<p>In this article, we are going to review how current solutions in the public and private blockchain ecosystem look like when it comes to scalability and real-world utility. We are going to discuss the possible and effective transition of blockchain becoming the value layer of the new Internet. In order to achieve the goal which Ethereum community and blockchain technology started with “Becoming a decentralized, scalable and programmable layer of the Internet”, we are going to discuss the problems which needs to be solved and propose some of the probable solutions which might help the community as a whole achieve its goal. of becoming the data and financial layer of the world.</p>\n<h1><a name=\"the-beginnings-2\" class=\"anchor\" href=\"https://ethresear.ch#the-beginnings-2\"></a>The Beginnings</h1>\n<p>It all started with Bitcoin, a decentralized peer to peer transfer of value (tokens) over a distributed ledger technology (DLT). Although it was revolutionary at the time, it missed some of the functionalities which could be implemented to put the underlying DLT technology to better use as a wider scope for the world. In order to bring programmability to the DLT termed Blockchain technology, many new research and projects came by. Among all, Ethereum came out to be “THE” programmability layer of the new decentralized Internet that brought the best of blockchain technology in form of immutable “smart contracts”.</p>\n<p>But with time and increasing adoption by the day, the community realized it lacked many of the important factors to be considered for adoption by the masses. Over the years, most of the problems have been solved with major upgrades in the Ethereum beacon chain. However, with regards to this thesis, we would be focusing on solving three major problems:</p>\n<ul>\n<li>Hyper-Scalability</li>\n<li>Privacy</li>\n<li>Utility and Composability</li>\n</ul>\n<h2><a name=\"introduction-3\" class=\"anchor\" href=\"https://ethresear.ch#introduction-3\"></a>Introduction</h2>\n<p>With limited block size of Ethereum beacon chain, it limits the TPS i.e., number of transactions to be processed on the chain. This restricts Ethereum beacon chain from processing millions of transactions while maintaining its security. Therefore, Ethereum’s Rollup centric roadmap promotes creation of various types of rollups or supporting chains which execute and process their own transactions on their customized blockchains and only pass on proofs of execution and settlement on Layer 1 chain. This creates a separate layer for developers to build their applications with outsourced security of another blockchain and only use Ethereum for finality and data availability of the transactions processed on the rollup.</p>\n<p><strong>Join Pioneer Labs’ <a href=\"https://discord.gg/xPtF8jWk\" rel=\"noopener nofollow ugc\">Discord Community</a></strong></p>\n<p><strong>Follow us on <a href=\"https://twitter.com/labs_pioneer\" rel=\"noopener nofollow ugc\">Twitter</a></strong></p>\n<h3><a name=\"types-of-scaling-solutions-4\" class=\"anchor\" href=\"https://ethresear.ch#types-of-scaling-solutions-4\"></a>Types of Scaling Solutions</h3>\n<p><strong>Side Chains:</strong> A sidechain is a separate blockchain that runs independent of Ethereum and is connected to Ethereum Mainnet by a two-way bridge. Sidechains can have separate block parameters and <a href=\"https://ethereum.org/en/developers/docs/consensus-mechanisms/\" rel=\"noopener nofollow ugc\">consensus algorithms</a>, which are often designed for efficient processing of transactions.</p>\n<p><strong>Validiums:</strong> Validium is a <a href=\"https://ethereum.org/en/developers/docs/scaling/\" rel=\"noopener nofollow ugc\">scaling solution</a> that enforces integrity of transactions using validity proofs like ZK-rollups, but doesn’t store transaction data on the Ethereum Mainnet.</p>\n<p><strong>Optimistic Rollups:</strong> Optimistic rollups are layer 2 (L2) protocols designed to extend the throughput of Ethereum’s base layer. They reduce computation on the main Ethereum chain by processing transactions off-chain, offering significant improvements in processing speeds.</p>\n<p><strong><a href=\"https://ethereum.org/en/developers/docs/scaling/zk-rollups/\" rel=\"noopener nofollow ugc\">ZK Rollups</a>:</strong> Zero-knowledge rollups (ZK-rollups) are <a href=\"https://ethereum.org/en/developers/docs/scaling/\" rel=\"noopener nofollow ugc\">layer 2 scaling solutions</a> that increase throughput on Ethereum Mainnet by moving computation and state-storage off-chain. ZK-rollups can process thousands of transactions in a batch and then only post some minimal summary data to Mainnet. This summary data defines the changes that should be made to the Ethereum state and some cryptographic proof that those changes are correct.</p>\n<h2><a name=\"problems-with-current-frameworks-5\" class=\"anchor\" href=\"https://ethresear.ch#problems-with-current-frameworks-5\"></a>Problems with Current Frameworks</h2>\n<h3><a name=\"scalability-trilemma-6\" class=\"anchor\" href=\"https://ethresear.ch#scalability-trilemma-6\"></a>Scalability Trilemma</h3>\n<p>The scalability trilemma is a concept in blockchain technology that states that it is impossible for a blockchain system to achieve all three of the following properties simultaneously:</p>\n<ul>\n<li>Security</li>\n<li>Decentralization</li>\n<li>Scalability</li>\n</ul>\n<p>In the case of Ethereum, this means that the current proof-of-work consensus the algorithm is secure and decentralized, but it cannot scale to meet the needs of a truly global financial system. This is because the more transactions the network processes, the more difficult it becomes to maintain decentralization, as the network requires more and more computational power to process all of the transactions in a timely manner.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/d/d92b30c0ae257bdeb4e5c003c373e99a75981cb9.png\" data-download-href=\"https://ethresear.ch/uploads/default/d92b30c0ae257bdeb4e5c003c373e99a75981cb9\" title=\"Scalability Trilemma\"><img src=\"https://ethresear.ch/uploads/default/optimized/2X/d/d92b30c0ae257bdeb4e5c003c373e99a75981cb9_2_614x500.png\" alt=\"Scalability Trilemma\" data-base62-sha1=\"uZa93UqX3nXvNjQlXjzOgAySqP7\" width=\"614\" height=\"500\" srcset=\"https://ethresear.ch/uploads/default/optimized/2X/d/d92b30c0ae257bdeb4e5c003c373e99a75981cb9_2_614x500.png, https://ethresear.ch/uploads/default/original/2X/d/d92b30c0ae257bdeb4e5c003c373e99a75981cb9.png 1.5x, https://ethresear.ch/uploads/default/original/2X/d/d92b30c0ae257bdeb4e5c003c373e99a75981cb9.png 2x\" data-dominant-color=\"ECF1F7\"></a></div><p></p>\n<p>Scalability Trilemma</p>\n<p>In order to solve the scalability trilemma, Ethereum focused towards the Rollup Centric Roadmap, however, the overall motive to achieve scalability has been unsuccessful during events of network clogging. For example, in the meme-coin season of $PEPE, gas fee on Ethereum L1 rose up to $100 and Optimistic L2s up to $8 making it infeasible to use by enterprises and protocols with wider use cases and network requirements</p>\n<p>Therefore, in order to make the Ethereum network the utility chain for the Internet which includes business solutions, private enterprise solutions, public solutions, defi, etc. the network needs to achieve hyper-scalability while maintaining a certain level of trust and security of Ethereum Virtual Machine.</p>\n<h3><a name=\"fragmentation-vs-adoption-7\" class=\"anchor\" href=\"https://ethresear.ch#fragmentation-vs-adoption-7\"></a>Fragmentation vs Adoption</h3>\n<p>With many new types and forms of rollups being developed, the blockchain community is getting more and more fragmented, developers must learn new tech stack, understand new concepts and build new architectures to make their applications compatible with each new type of chains. This not only hinders the goal for simplicity and improvement of User experience but also complicates the developer experience on the new chains.</p>\n<p></p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ethresear.ch/uploads/default/original/2X/6/65c5c10864b4b0c8c9cb1a6e68805f2f06bc340b.png\" data-download-href=\"https://ethresear.ch/uploads/default/65c5c10864b4b0c8c9cb1a6e68805f2f06bc340b\" title=\"\"><img src=\"https://ethresear.ch/uploads/default/original/2X/6/65c5c10864b4b0c8c9cb1a6e68805f2f06bc340b.png\" alt=\"\" data-base62-sha1=\"ewjUsgG8MOyscOoj5sqtTHLcSrV\" width=\"690\" height=\"389\" role=\"presentation\" data-dominant-color=\"E1E1E1\"></a></div><p></p>\n<p>With each new rollup framework, the community keeps on getting fragmented with no single form of framework being adopted across the market. With the creation of each new rollup, the team must bootstrap the entire community and create real value for the developers and businesses to build on their blockchain. This creates additional costs for adoption not only by developers but by enterprise. This creates very limited utilities for enterprises to adopt public blockchains for building their internal or external solutions for their businesses.</p>\n<h3><a name=\"siloed-ecosystem-vs-interoperability-8\" class=\"anchor\" href=\"https://ethresear.ch#siloed-ecosystem-vs-interoperability-8\"></a>Siloed Ecosystem vs Interoperability</h3>\n<p>With sidechains, plasma chains, Layer 2 Rollups, ZK Rollups each having separate execution environments, settlement layers, sequencers, proof generations, etc. This creates the major issue of cross- chain trustless messaging creating security issues for users for transferring assets from one chain to another through third parties such as bridges. Each blockchain and rollup have their siloed ecosystem and technical architecture creating it very difficult for developers to adapt to each architecture and develop their application compatible with all architectures.</p>\n<p>If multiple Layer 3 chains as well as app-chains are developed using the similar EVM equivalent framework without having to transition to other technologies or going through multiple developer education programs, it will make the development and deployment of trustless solutions not only faster but cheaper. This would allow multiple publics, private as well as enterprise chains to share security as well as arbitrary message passing creating trustless interoperability among rollups.</p>\n<h2><a name=\"proposed-solution-9\" class=\"anchor\" href=\"https://ethresear.ch#proposed-solution-9\"></a>Proposed Solution</h2>\n<p>For our research purposes, we’ll only be focusing on ZK-rollups for now i.e., we’ll be exploring solutions particularly on zk-EVMs and avoiding other frameworks for mainly two reasons:</p>\n<ol>\n<li>L3s cannot be effectively deployed on Optimistic rollups due to the 7-day fraud proof period. For deploying a Layer 3 chain, the execution of the chains from middleware to Layer 2 VM will become very complicated in terms of generating proofs. Not only the solution becomes complicated but not many optimistic rollups support the framework for fractal scaling.</li>\n<li>We’ll not be focusing on using an EVM sidechain or an EVM-compatible Layer 1 Chain for our thesis due to the adoption and security dilemma. Due to pre-existing community adoption of Ethereum by hundreds of millions and Ethereum beacon chain secured by tens of billions of dollars, it becomes difficult for any network to get the level of security and finality as Ethereum beacon chain.</li>\n</ol>\n<p>Our solution will focus on building the tech stack allowing developers and enterprises to create their own Layer 3 scaling solution(rollups) on Type 2.5 and/or Type 3 zk-EVMs using Ethereum equivalent Virtual Machine with ZK-SNARKS (Zero-Knowledge Succinct Non-Interactive Argument of Knowledge).</p>\n<h3><a name=\"why-zk-snarks-10\" class=\"anchor\" href=\"https://ethresear.ch#why-zk-snarks-10\"></a>Why Zk-SNARKS?</h3>\n<p>The solution would be built with ZK-Rollups since the time involved with fraud proof generation and the 7 day challenge period would make proof generation and validation of L3 rollups very complicated and the security with transaction finality would be weak to order-flow hacks. Why we chose <a href=\"https://scroll.io/blog/architecture\" rel=\"noopener nofollow ugc\">ZK-SNARKS</a> over STARKS is due to:</p>\n<ul>\n<li><strong>Efficiency and Scalability:</strong> ZK-SNARKs provide more efficient proofs compared to ZK-STARKs. They generate smaller proof sizes, which reduces the computational and storage requirements for validating transactions and executing smart contracts. This efficiency is particularly crucial in the context of fractal scaling, where aggregating multiple transactions into a single proof is essential for achieving scalability.</li>\n<li><strong>Ecosystem Maturity:</strong> The ecosystem around <a href=\"https://zcash.github.io/halo2/concepts/chips.html\" rel=\"noopener nofollow ugc\">ZK-SNARKs</a> is more mature and has seen wider adoption compared to ZK-STARKs. This maturity translates into more available tools, libraries, and expertise for implementing and utilizing ZK- SNARKs. The larger developer community and existing infrastructure make it easier to integrate ZK-SNARKs into Layer 3 rollups on the Ethereum blockchain.</li>\n</ul>\n<h3><a name=\"why-type-3-zk-evms-should-be-preferred-for-layer-3s-11\" class=\"anchor\" href=\"https://ethresear.ch#why-type-3-zk-evms-should-be-preferred-for-layer-3s-11\"></a>Why Type 3 ZK-EVMs should be preferred for Layer 3s</h3>\n<p>Type 2.5 or <a href=\"https://vitalik.ca/general/2022/08/04/zkevm.html\" rel=\"noopener nofollow ugc\">Type 3 ZK-EVMs</a> are more preferred than Type 4 ZK-EVMs for fractal scaling solutions:</p>\n<ul>\n<li><strong>Efficiency and Proof Size:</strong> Type 3 ZK-EVMs typically offer more efficient proofs compared to Type 4 <a href=\"https://hackmd.io/@yezhang/S1_KMMbGt\" rel=\"noopener nofollow ugc\">ZK-EVMs</a>. Fractal scaling heavily relies on aggregating multiple transactions into a single proof, and smaller proof sizes are desirable for improved efficiency. Type 3 ZK-EVMs are generally designed with succinct proof generation in mind, optimizing the proof size and reducing computational and storage overhead.</li>\n<li><strong>Interoperability:</strong> Type 3 <a href=\"https://privacy-scaling-explorations.github.io/zkevm-docs/introduction.html\" rel=\"noopener nofollow ugc\">ZK-EVMs</a> typically maintain a high level of interoperability and byte-code compatibility with existing Ethereum infrastructure. They are designed to be compatible with Ethereum’s EVM (Ethereum Virtual Machine), enabling seamless integration with smart contracts and existing decentralized applications (dApps). This [interoperability](<a href=\"https://polymerlabs.medium.com/developing-the-most-truly-decentralized-interoperability-solution-\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Medium</a> polymer-zk-ibc-f0287ea84a2b) is crucial for frictionless adoption and leveraging the robust ecosystem of Ethereum. Type 3 ZK-EVMs have byte-code level compatibility with EVM making the transitioning and network shifting much easier for developers and applications unlike Type 4 ZK-EVMs like CairoVM or VyperVM which use high level language ZK-Proofs which cannot be computed by Type 1 ZK-EVM.</li>\n</ul>\n<h3><a name=\"why-layer-3s-12\" class=\"anchor\" href=\"https://ethresear.ch#why-layer-3s-12\"></a>Why Layer 3s?</h3>\n<p>This would be most effective on Layer solutions due to hyper scalability and middleware. With the existence of Layer 2 middleware between app-chains and Ethereum beacon chains. When it comes to scaling solutions, privacy and customized scaling, <a href=\"https://vitalik.ca/general/2022/09/17/layer_3.html\" rel=\"noopener nofollow ugc\">Layer 3 rollups</a> have significant benefits over sovereign app-chains and Layer 2 app specific rollups.</p>\n<ul>\n<li><strong>Interoperability and Network Effects:</strong> Layer 3 rollups are designed to be fully compatible with the Ethereum network. They inherit Ethereum’s smart contract functionality and benefit from the existing ecosystem of decentralized applications (dApps), wallets, and tools. This interoperability allows for seamless integration with existing Ethereum applications and maximizes network effects. Sovereign app-chains, being separate chains, may lack the same level of interoperability and may require building a new ecosystem from scratch, potentially hindering adoption.</li>\n<li><strong>Security and Finality:</strong> Layer 3 rollups provide strong security guarantees through the finality of transactions. Once a transaction is included in a Layer 3 rollup, it is considered final and cannot be reversed or tampered with. Sovereign app-chains may have different security models, and the finality of transactions may depend on their specific consensus mechanism. The security and finality guarantee of Layer 3 roll ups provide users and developers with a higher degree of confidence.</li>\n<li><strong>Recursive Composition:</strong> Fractal scaling leverages recursive composition, enabling the aggregation of transactions at multiple levels. This recursive approach allows for more efficient proofs, as transactions can be grouped hierarchically and processed collectively. It provides a higher level of scalability compared to Layer 2 ZK-rollups, which typically focus on aggregating transactions within a single layer.</li>\n<li><strong>Flexibility and Granularity:</strong> Fractal scaling offers greater flexibility and granularity in scaling solutions. It allows for different layers of aggregation and enables selective inclusion or exclusion of transactions based on specific criteria or requirements. This flexibility allows developers to optimize the scaling solution based on their application’s needs. In contrast, Layer 2 ZK-rollups may have predefined structures and aggregation mechanisms, limiting the level of customization and fine-tuning.</li>\n<li><strong>Layer Composition:</strong> Fractal scaling supports the composition of multiple layers, each providing its own level of scalability. This hierarchical composition allows for a more modular and flexible approach to scaling, where different layers can be added or removed depending on network demands. Layer 2 ZK-rollups, while providing scalability within a specific layer, may not offer the same seamless composition of multiple layers.</li>\n</ul>\n<h2><a name=\"background-13\" class=\"anchor\" href=\"https://ethresear.ch#background-13\"></a>Background</h2>\n<h3><a name=\"app-chain-thesis-14\" class=\"anchor\" href=\"https://ethresear.ch#app-chain-thesis-14\"></a>App-Chain Thesis</h3>\n<p>The app chain thesis proposes that every application should have its own rollup over Ethereum. This would create a separate layer for developers to build their applications with outsourced security of another blockchain and only use Ethereum for finality and data availability of the transactions processed on the rollup. The idea behind this thesis is to solve the problem of fragmentation in the blockchain community.</p>\n<p>With many new types and forms of rollups being developed, developers have to learn new tech stacks, understand new concepts, and build new architectures to make their applications compatible with each new type of chain. By creating a separate rollup for each application, developers can build their applications on customized blockchains, allowing for greater flexibility and innovation while maintaining the security and finality of the Ethereum network.</p>\n<p>With Layer 3 scaling solutions, Ethereum can be aligned with the app-chain thesis. As mentioned above, it would be more beneficial for applications and enterprises to launch their app-chains with interoperability and shared security. With shared execution environments and shared settlement layers, thousands of app-chains would be able to operate in a shared environment and focus on developing their business logic instead of bootstrapping security or community as compared to other chains.</p>\n<h3><a name=\"mev-capture-15\" class=\"anchor\" href=\"https://ethresear.ch#mev-capture-15\"></a>MEV Capture</h3>\n<p>MEV, or miner extractable value, refers to the value that miners can capture by reordering or censoring transactions on a blockchain. App-chains and Layer 3 rollups can capture their own MEV by creating their own customized blockchains that enable them to process and settle transactions off-chain. This allows them to capture the full value of the transactions they process, rather than letting other blockchains capture the MEV of their users. By building customized blockchains, app-chains and Layer 3 rollups can also achieve greater scalability and efficiency, enabling them to process more transactions at a lower cost than other blockchains.</p>\n<h3><a name=\"modular-architecture-and-hyper-scalability-16\" class=\"anchor\" href=\"https://ethresear.ch#modular-architecture-and-hyper-scalability-16\"></a>Modular Architecture and Hyper-Scalability</h3>\n<p>Rollups would be built with <a href=\"https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding\" rel=\"noopener nofollow ugc\">modular architecture</a> with customized data availability solutions. Unlike monolithic blockchain architecture where Ethereum blockchain is used for data availability instead of acting as a layer just for proof generation and transaction finality. This creates unnecessary data storage of Ethereum chain resulting in clogging of data and high gas fee for users of beacon chain as well as rollups. In order to achieve hyper-scalability, rollups need to adopt modular architecture where they use off-chain data availability solutions such as validiums, data availability committees, honest DAC minority, etc. Modular architecture will not only reduce gas costs and allow more transactions into a single batch but also help all Layer 3 rollups achieve customized privacy and scaling.</p>\n<h2><a name=\"existing-zk-rollup-framework-17\" class=\"anchor\" href=\"https://ethresear.ch#existing-zk-rollup-framework-17\"></a>Existing ZK-Rollup Framework</h2>\n<p>ZK Rollups are a layer 2 scaling solution that uses cryptographic validity proofs to scale computation: each batch of transactions comes with a cryptographic proof (SNARK) that is verified by an Ethereum smart contract. This way every single transaction is fully verified by all Ethereum full nodes before a block is finalized. Zero-knowledge rollups (ZK-rollups) are layer 2 scaling solutions that move computation and state storage off-chain to increase throughput on Ethereum Mainnet. ZK-rollups can process thousands of transactions in a batch and then only post some minimal summary data to Mainnet. This summary data defines the changes that should be made to the Ethereum state and some cryptographic proof that those changes are correct.</p>\n<p>ZK-rollups use zero-knowledge proofs to verify the validity of transactions and state transitions without revealing any of the transaction details, thereby maintaining privacy. These proofs are verified by a smart contract on Ethereum Mainnet, allowing the network to confirm the validity of the rollup’s state transitions without having to verify each transaction individually. This reduces the computational load on Ethereum Mainnet, allowing it to process significantly more transactions per second.</p>\n<h2><a name=\"utilities-of-a-fractal-scaling-solution-18\" class=\"anchor\" href=\"https://ethresear.ch#utilities-of-a-fractal-scaling-solution-18\"></a>Utilities of a Fractal Scaling Solution</h2>\n<p><strong>L2 is for Scaling, L3s are for customized Scaling:</strong> Layer 3 rollups offer significant benefits for customized scaling on the Ethereum blockchain. Their customizability, specialized features, enhanced scalability, independent governance, ecosystem integration, security, and reliability make them a compelling choice for developers seeking tailored scaling solutions that align closely with their application’s requirements and objectives. L3s can be used for application specific rollups where developers can build their custom solutions with their business logic on their customized Layer 3 rollup.</p>\n<p><strong>Privacy in blockchains:</strong> Layer 3 rollups can improve privacy in blockchain networks through various mechanisms and techniques.</p>\n<ul>\n<li>Zero-Knowledge Proofs: Layer 3 rollups can utilize zero-knowledge proofs (ZKPs) to provide privacy guarantees. ZKPs allow for the verification of certain properties or computations without revealing the underlying data. This enables users to prove the validity of their transactions or the correctness of certain operations without disclosing sensitive information.</li>\n<li>Trusted/Private Data Availability: Developers and Enterprises who want to utilize the security of Ethereum in a trusted environment while keeping their data private in a trusted environment can create their custom validium data availability models for their Layer 3 rollups.</li>\n</ul>\n<p><strong>Utilities for Enterprises:</strong> Enterprises can utilize Layer 3 rollups for their custom use cases to build their solutions by utilizing the security and ecosystem of Ethereum in their trusted environment. Layer 3 customized enterprise specific rollups can be utilized best for these solutions:</p>\n<ul>\n<li>High Volume Transaction Systems</li>\n<li>Tokenization of Real-World Assets</li>\n<li>Customized Financial Solutions</li>\n<li>Privacy-Focused Applications</li>\n<li>Supply Chain and Logistics Solutions</li>\n<li>Gaming and NFT Utility Applications</li>\n</ul>\n<h2><a name=\"conclusion-19\" class=\"anchor\" href=\"https://ethresear.ch#conclusion-19\"></a>Conclusion</h2>\n<p>In conclusion, the integration of a fractal scaling solution over Type 3 ZK-EVM using Halo2 presents a significant advancement in the scalability and privacy of blockchain networks. By combining the power of fractal scaling, which enables recursive composition of computation, and the privacy-preserving properties of the ZK-EVM protocol, this solution offers a promising path forward for addressing the limitations of existing blockchain systems.</p>\n<p>Fractal scaling allows for the efficient aggregation of multiple transactions into a single proof, reducing the computational and storage overhead associated with processing and validating transactions. This recursive composition enables a higher throughput of transactions, thereby significantly improving the scalability of blockchain networks. By leveraging this approach, the Type 3 ZK-EVM protocol can benefit from enhanced scalability while preserving the security guarantees and decentralized nature of the underlying blockchain.</p>\n<p>The utilization of the Halo2 protocol further enhances the privacy aspects of the system. Halo2 leverages zero-knowledge proofs to enable secure computation and verification without revealing any sensitive information. By employing this protocol within the fractal scaling solution, users can conduct transactions with confidentiality, ensuring that their personal and financial information remains private while still benefiting from the scalability improvements. With this integration, blockchain systems can handle a significantly higher transaction volume while maintaining the security, decentralization, and privacy that users expect. As this technology continues to mature, it has the potential to unlock new possibilities and drive widespread adoption of blockchain technology across various industries and use cases.</p>\n            <p><small>2 posts - 2 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/fractal-scaling-on-ethereum-layer-3-rollups/19022\">Read full topic</a></p>","link":"https://ethresear.ch/t/fractal-scaling-on-ethereum-layer-3-rollups/19022","pubDate":"Sat, 16 Mar 2024 11:30:55 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19022"},"source":{"@url":"https://ethresear.ch/t/fractal-scaling-on-ethereum-layer-3-rollups/19022.rss","#text":"Fractal Scaling on Ethereum (Layer 3 Rollups)"}},{"title":"Minimal fully recursive zkDA rollup with sharded storage","dc:creator":"snjax","category":"ZK Rollup","description":"<h2><a name=\"current-zk-rollup-state-1\" class=\"anchor\" href=\"https://ethresear.ch#current-zk-rollup-state-1\"></a>Current zk rollup state</h2>\n<p>zkRollups scale execution efficiently, but publish all blocks at L1. This is not scalable for storage and forbids recursive rollups: if we deploy a rollup on a rollup, we need to publish all the blocks of the inner rollup on the outer rollup, and the outer rollup will publish all its blocks on L1.</p>\n<p><img src=\"https://ethresear.ch/uploads/default/original/2X/e/e04f5c7f84d40add7840afa6a1f5fdc05bbc30af.svg\" alt=\"native rollup\" data-base62-sha1=\"w0kZ1mEUZhJvjC0uhtXPS5jQqGH\" width=\"401\" height=\"445\"></p>\n<p>There were some attempts to solve this problem, like validiums, but they are weak on both decentralization and security (2 of 3 in Vitalik’s trilemma).</p>\n<h2><a name=\"existing-improvements-in-unlocking-data-availability-and-decentralized-storage-2\" class=\"anchor\" href=\"https://ethresear.ch#existing-improvements-in-unlocking-data-availability-and-decentralized-storage-2\"></a>Existing improvements in unlocking data availability and decentralized storage</h2>\n<h3><a name=\"chia-3\" class=\"anchor\" href=\"https://ethresear.ch#chia-3\"></a>Chia</h3>\n<p>Chia introduced a novel consensus algorithm called Proof of Space and Time (PoST), which provides a more decentralized and energy-efficient alternative to Proof of Work (PoW): Proof of Space-Time (PoST). PoST is a consensus algorithm that uses storage space as a resource to secure the network.<br>\nThe current capacity of Chia Network is 33 EiB.</p>\n<h3><a name=\"ethstorage-4\" class=\"anchor\" href=\"https://ethresear.ch#ethstorage-4\"></a>EthStorage</h3>\n<p>Ethstorage is replication-based DA and storage, managed by a smart contract.</p>\n<h2><a name=\"our-results-5\" class=\"anchor\" href=\"https://ethresear.ch#our-results-5\"></a>Our results</h2>\n<p>In our <a href=\"https://ethresear.ch/t/blockchain-sharded-storage-web2-costs-and-web3-security-with-shamir-secret-sharing/18881\">research draft</a> we propose a solution for storage and data availability, friendly to zk rollups and unlocking new scalability opportunities.</p>\n<h3><a name=\"sharding-instead-of-replication-6\" class=\"anchor\" href=\"https://ethresear.ch#sharding-instead-of-replication-6\"></a>Sharding instead of replication</h3>\n<p>It is proposed to use <span class=\"math\">k</span> of <span class=\"math\">n</span> threshold data representation. So, any <span class=\"math\">k</span> numbers from the source file are transformed into <span class=\"math\">n</span> numbers. And any <span class=\"math\">k</span> of these <span class=\"math\">n</span> numbers can restore the source <span class=\"math\">k</span> numbers. This is called Shamir’s Secret Sharing.</p>\n<p>This approach allows us to utilize storage 10-20 times more efficiently than the replication-based approach, according to our modeling.</p>\n<p>Also, it gives us better protection from physical-level attacks, like target node destruction.</p>\n<h3><a name=\"unlimited-horizontal-scalability-7\" class=\"anchor\" href=\"https://ethresear.ch#unlimited-horizontal-scalability-7\"></a>Unlimited horizontal scalability</h3>\n<p>We propose to use a 2-level nested rollup structure (below we will describe, why it is possible). The top-level rollup manages participants of low-level rollups and mixes them to prevent the accumulation of malicious participants in one low-level rollup. Low-level rollups manages the data, stored in the nodes.</p>\n<h3><a name=\"polynomial-commitments-everywhere-8\" class=\"anchor\" href=\"https://ethresear.ch#polynomial-commitments-everywhere-8\"></a>Polynomial commitments everywhere</h3>\n<p>We propose to use Merkle trees on the top level of database. However, the minimal structure is a polynomial commitment to a cluster of data. So, it is very friendly to rollups, because we can use the same polynomial commitment to represent the rollup’s block.</p>\n<p>Also, out of the box we have data availability oracle (just provide random polynomial lookup on the commitment) and all linear algebra we needed for sharding.</p>\n<h3><a name=\"data-mining-9\" class=\"anchor\" href=\"https://ethresear.ch#data-mining-9\"></a>Data mining</h3>\n<p>Nodes can use the data for mining, like in Chia. And the result of mining is zero-knowledge proof of data availability.</p>\n<p>The complexity of storage is leveled, so it is the same complexity to store random data or zeros.</p>\n<p>Nodes can join to network with trustless zk proof of their capacity.</p>\n<h2><a name=\"bring-it-all-together-10\" class=\"anchor\" href=\"https://ethresear.ch#bring-it-all-together-10\"></a>Bring it all together</h2>\n<p>ZK Rollups usually publish on-chain proof of execution and data of the block.<br>\nBut our data availability and proof of storage are zk. So, we can merge it all together and publish the proof of execution and data availability and storage in one single ZK proof.</p>\n<p>It unlocks the deployment of rollups on rollups, and the rollups on rollups on rollups, and so on. And way to transform Web2 into Web3.</p>\n<p>Also, we can prevent the bloating of the blockchain: if we publish the snapshot state of the rollup, previous history could be removed.</p>\n<p><img src=\"https://ethresear.ch/uploads/default/original/2X/e/e3e434b0992b133f32c8c4a33bcf390e04e571b6.svg\" alt=\"zkDA rollup\" data-base62-sha1=\"ww1juXvygtiVCbaiMwK42atJbEO\" width=\"482\" height=\"500\"></p>\n<h2><a name=\"some-economics-11\" class=\"anchor\" href=\"https://ethresear.ch#some-economics-11\"></a>Some economics</h2>\n<p>On 1st Jan 2024 cost of storage, 1GiB was:</p>\n<ul>\n<li>Ethereum $1.8M</li>\n<li>EthStorage $10k</li>\n<li>Celestia $300</li>\n<li>Near $10</li>\n</ul>\n<p>Based on <a href=\"https://www.hetzner.com/dedicated-rootserver/sx294/\" rel=\"noopener nofollow ugc\">Hetzner sx294</a> with 8 blowup factor (what we need for &gt;100 bits of security), the annual cost of storage 1GB is $0.15 usd.</p>\n<p>The cost will be lower on specialized rigs.</p>\n<h2><a name=\"call-for-discussion-and-feedback-12\" class=\"anchor\" href=\"https://ethresear.ch#call-for-discussion-and-feedback-12\"></a>Call for discussion and feedback</h2>\n<p>We believe our proposed solution has the potential to significantly improve the scalability and efficiency of zk rollups and upgrade Web2 to Web3. However, we acknowledge that this is still a research draft and there may be challenges or considerations we haven’t fully addressed.</p>\n<p>We welcome discussion, feedback, and constructive criticism from the community. If you have insights, ideas, or see potential issues with our approach, please share them.</p>\n            <p><small>9 posts - 4 participants</small></p>\n            <p><a href=\"https://ethresear.ch/t/minimal-fully-recursive-zkda-rollup-with-sharded-storage/19020\">Read full topic</a></p>","link":"https://ethresear.ch/t/minimal-fully-recursive-zkda-rollup-with-sharded-storage/19020","pubDate":"Sat, 16 Mar 2024 09:05:24 +0000","discourse:topicPinned":"No","discourse:topicClosed":"No","discourse:topicArchived":"No","guid":{"@isPermaLink":"false","#text":"ethresear.ch-topic-19020"},"source":{"@url":"https://ethresear.ch/t/minimal-fully-recursive-zkda-rollup-with-sharded-storage/19020.rss","#text":"Minimal fully recursive zkDA rollup with sharded storage"}}]}}}